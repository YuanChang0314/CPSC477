{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0XfYhsk-gkl"
      },
      "source": [
        "# CPSC 477/577 Spring 2025 - Homework 3\n",
        "## Part 3- RAG and Information Retrieval\n",
        "\n",
        "Yale University  \n",
        "Spring 2025  \n",
        "Instructor: Arman Cohan\n",
        "\n",
        "In this homework, we will implement and evaluate a RAG-based retrieval system using the LitSearch dataset and Snowflake's Arctic Embeddings model.\n",
        "\n",
        "**Acknolwedgement**  The assignment is designed by TA Yilun Zhao with help and guidance from Arman Cohan.\n",
        "\n",
        "### Submission Instructions\n",
        "\n",
        "Submit the notebook as a .ipynb file through GradeScope.\n",
        "\n",
        "Make sure that the notebook is running without any errors before submission. Remove any unnecessary outputs or additional `print` or debugging statements that you put in the code before submission.\n",
        "\n",
        "### Write your name and NetID below.\n",
        "\n",
        "**Name:**    Yuan Chang\n",
        "\n",
        "**NetID:**   yc2238"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main tasks include:\n",
        "1. Building retrieval index using Arctic Embeddings\n",
        "2. Implementing retrieval functionality\n",
        "\n",
        "First, let's import the required packages:"
      ],
      "metadata": {
        "id": "UQx4VKFki-AT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "soEtg4Kz-gkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb19b08a-51f1-4919-8a14-628bde4f1ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, faiss-cpu, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 faiss-cpu-1.11.0 fsspec-2025.3.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers torch faiss-cpu tqdm\n",
        "\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import faiss\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrHRYdEs-gkn"
      },
      "source": [
        "## Data Loading and Preprocessing\n",
        "Load the LitSearch dataset which contains academic paper queries and corpus.\n",
        "The corpus includes paper titles, abstracts and other metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NOb7p7JU-gkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454,
          "referenced_widgets": [
            "886fac0b20ff43f8a5cbd1a93c04b784",
            "41faa1f09fd1483c965e60241911b3fd",
            "91db3fc5d28c429da41e7e5ee9386173",
            "21e14c142c5e4dba97d324c705935328",
            "ce2889bf4b1a4aa189c093f04dbcb902",
            "5c4c5a64015749a7ae6e8bb04c89cd16",
            "3c3f856d29534a07a5cbb90f71e737f1",
            "5ae70a7760de4d6eabf3c0ae9e37434e",
            "64b46a1be54b4603bbc4147245726d99",
            "703d0f1ee962441d942ff71070fb54ec",
            "0ae490d53b144740a3633a47067c74b2",
            "6c0312f016e0428f827d292bd5bdd24e",
            "903dc423b0a74aadba4f0876ef55962d",
            "e8eb4c25117d4018b333def96410b0d0",
            "1a5a83a6ade246d9b90e35109928b932",
            "790c5eac3b8b4ae48ac4770d71f567b8",
            "c0ef681a55ac4aceb011245fbb25b55d",
            "088807a268a44a288022c9b80e6b44d2",
            "1b4633afb64e424497bfad4ee9fc95a0",
            "2714233ef01847008e1ed94f4fdc2af9",
            "7060139b316f482c8a88132010ee4de2",
            "0db97938007c4e3ca6b77ee5d1743af9",
            "c07b39e3b8a244c98ba8f54ed2e8a773",
            "49e385a947464971a167ec5893b78d3d",
            "e5bce30fc9aa445ea1f9eff7fe3c8fa5",
            "70216732fe60473a8118a79ea0dc2809",
            "dd2c9297725449af900d1c86f1cc64e3",
            "b7ed77c2289443c28ae98f8dd0a0d95b",
            "3cb5580e7e36420cbd5583b27970d8c3",
            "3372f832d4684e5694186e07ee9f41db",
            "2cfd471131a9480ca2f6a1f03cc58b4b",
            "58e92c506a124fb0916d5247fb6cb3dc",
            "b5eabc6edad74232804292aa15c3a3e0",
            "f69abd2b846f4e8dbfc6ebd1e2e6c2f1",
            "e5b11d1f2675409b814f89447be1de0c",
            "ce5a877830c54adcaf7208a61208f5ce",
            "e350ee0ea4fc4578a69b66aa27b5815d",
            "01685039017f432c9cc2e998769a5590",
            "8ba3b110223142208d26e0c582296df0",
            "ad1ca6c6e258475f825e7324400ef753",
            "0a6ff8bf536a415f9a518286240996fc",
            "f1c26d6705a3414fb20be3d85f0a61bb",
            "c0070bd83ae147c9a5bf2d7085aa4264",
            "de2425ca8acd4eefb3f10eef0f7949b9",
            "db0e190e4605464fa519bc7d104bacc9",
            "6f9f95a4887e4b33916efd1dbc139990",
            "501db4bd5d0742b6bdfc419aeb3ac876",
            "826076e50ea2415dbbe4d72b64e75ce7",
            "5dc49e781c8c40bb8db59e1f7194cb82",
            "600fc74f7603423cad92a6828ef6c1cb",
            "65f738a262854af3b099bd24670ed6cb",
            "31a0fd3f486c46fb8a59c8bfab05ef07",
            "4b2239240b424226b4d78e929d56f48a",
            "8ad12db5383d445899837c8beb9b41df",
            "ce3d22f4dc7d49df9671f601a594d89d"
          ]
        },
        "outputId": "aa36288d-71c5-46cc-e429-4ad09f4e6f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "886fac0b20ff43f8a5cbd1a93c04b784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "full-00000-of-00001.parquet:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c0312f016e0428f827d292bd5bdd24e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating full split:   0%|          | 0/597 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c07b39e3b8a244c98ba8f54ed2e8a773"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "full-00000-of-00001.parquet:   0%|          | 0.00/139M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f69abd2b846f4e8dbfc6ebd1e2e6c2f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating full split:   0%|          | 0/6809 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db0e190e4605464fa519bc7d104bacc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query set size: 597\n",
            "Corpus size: 6809\n",
            "\n",
            "Query dataset columns: ['query_set', 'query', 'specificity', 'quality', 'corpusids']\n",
            "Sample query: {'query_set': 'inline_acl', 'query': 'Are there any research papers on methods to compress large-scale language models using task-agnostic knowledge distillation techniques?', 'specificity': 0, 'quality': 2, 'corpusids': [202719327]}\n",
            "\n",
            "Corpus dataset columns: ['corpusid', 'title', 'abstract', 'citations', 'full_paper']\n",
            "Sample corpus document: {'corpusid': 253523474, 'title': 'CHARACTERIZING THE SPECTRUM OF THE NTK VIA A POWER SERIES EXPANSION', 'abstract': 'Under mild conditions on the network initialization we derive a power series expansion for the Neural Tangent Kernel (NTK) of arbitrarily deep feedforward networks in the infinite width limit. We provide expressions for the coefficients of this power series which depend on both the Hermite coefficients of the activation function as well as the depth of the network. We observe faster decay of the Hermite coefficients leads to faster decay in the NTK coefficients and explore the role of depth. Using this series, first we relate the effective rank of the NTK to the effective rank of the inputdata Gram. Second, for data drawn uniformly on the sphere we study the eigenvalues of the NTK, analyzing the impact of the choice of activation function. Finally, for generic data and activation functions with sufficiently fast Hermite coefficient decay, we derive an asymptotic upper bound on the spectrum of the NTK.', 'citations': [2780493, 221836662, 245906072, 3708505, 222066778], 'full_paper': \"CHARACTERIZING THE SPECTRUM OF THE NTK VIA A POWER SERIES EXPANSION\\nMarch 2, 2023\\n\\nA Preprint \\nDepartment of Mathematics\\nUCLA\\nCAUSA\\n\\nMichael Murray [mmurray@math.ucla.edu \\nDepartment of Mathematics\\nUCLA\\nCAUSA\\n\\nHui Jin huijin@math.ucla.edu \\nDepartment of Mathematics\\nUCLA\\nCAUSA\\n\\nBenjamin Bowman benbowman314@math.ucla.edu \\nDepartment of Mathematics\\nUCLA\\nCAUSA\\n\\nDepartment of Statistics\\nUCLA\\nCAUSA\\n\\nMax Planck Institute for Mathematics in the Sciences\\nLeipzigGermany\\n\\nGuido Montufar montufar]@math.ucla.edu \\nCHARACTERIZING THE SPECTRUM OF THE NTK VIA A POWER SERIES EXPANSION\\nMarch 2, 2023* Equal contribution\\nUnder mild conditions on the network initialization we derive a power series expansion for the Neural Tangent Kernel (NTK) of arbitrarily deep feedforward networks in the infinite width limit. We provide expressions for the coefficients of this power series which depend on both the Hermite coefficients of the activation function as well as the depth of the network. We observe faster decay of the Hermite coefficients leads to faster decay in the NTK coefficients and explore the role of depth. Using this series, first we relate the effective rank of the NTK to the effective rank of the inputdata Gram. Second, for data drawn uniformly on the sphere we study the eigenvalues of the NTK, analyzing the impact of the choice of activation function. Finally, for generic data and activation functions with sufficiently fast Hermite coefficient decay, we derive an asymptotic upper bound on the spectrum of the NTK.\\n\\nIntroduction\\n\\nNeural networks currently dominate modern artificial intelligence, however, despite their empirical success establishing a principled theoretical foundation for them remains an active challenge. The key difficulties are that neural networks induce nonconvex optimization objectives (Sontag & Sussmann, 1989) and typically operate in an overparameterized regime which precludes classical statistical learning theory (Anthony & Bartlett, 2002). The persistent success of overparameterized models tuned via non-convex optimization suggests that the relationship between the parameterization, optimization, and generalization is more sophisticated than that which can be addressed using classical theory.\\n\\nA recent breakthrough on understanding the success of overparameterized networks was established through the Neural Tangent Kernel (NTK) (Jacot et al., 2018). In the infinite width limit the optimization dynamics are described entirely by the NTK and the parameterization behaves like a linear model . In this regime explicit guarantees for the optimization and generalization can be obtained (Du et al., 2019a,b;Arora et al., 2019a;Allen-Zhu et al., 2019;Zou et al., 2020). While one must be judicious when extrapolating insights from the NTK to finite width networks (Lee et al., 2020), the NTK remains one of the most promising avenues for understanding deep learning on a principled basis.\\n\\nThe spectrum of the NTK is fundamental to both the optimization and generalization of wide networks. In particular, bounding the smallest eigenvalue of the NTK Gram matrix is a staple technique for establishing convergence guarantees for the optimization (Du et al., 2019a,b;Oymak & Soltanolkotabi, 2020). Furthermore, the full spectrum of the NTK Gram matrix governs the dynamics of the empirical risk (Arora et al., 2019b), and the eigenvalues of the associated integral operator characterize the dynamics of the generalization error outside the training set (Bowman & Montufar, 2022;Bowman & Montúfar, 2022). Moreover, the decay rate of the generalization error for Gaussian process regression using the NTK can be characterized by the decay rate of the spectrum (Caponnetto & De Vito, 2007;Cui et al., 2021;Jin et al., 2022).\\n\\nThe importance of the spectrum of the NTK has led to a variety of efforts to characterize its structure via random matrix theory and other tools (Yang & Salman, 2019;Fan & Wang, 2020). There is a broader body of work studying the closely related Conjugate Kernel, Fisher Information Matrix, and Hessian (Poole et al., 2016;Pennington & Worah, 2017Louart et al., 2018;Karakida et al., 2020). These results often require complex random matrix theory or operate in a regime where the input dimension is sent to infinity. By contrast, using a just a power series expansion we are able to characterize a variety of attributes of the spectrum for fixed input dimension and recover key results from prior work.\\n\\n\\nContributions\\n\\nIn Theorem 3.1 we derive coefficients for the power series expansion of the NTK under unit variance initialization, see Assumption 2. Consequently we are able to derive insights into the NTK spectrum, notably concerning the outlier eigenvalues as well as the asymptotic decay.\\n\\n• In Theorem 4.1 and Observation 4.2 we demonstrate that the largest eigenvalue λ 1 (K) of the NTK takes up an Ω(1)\\n\\nproportion of the trace and that there are O(1) outlier eigenvalues of the same order as λ 1 (K).\\n\\n• In Theorem 4.3 and Theorem 4.5 we show that the effective rank T r(K)/λ 1 (K) of the NTK is upper bounded by a constant multiple of the effective rank T r(XX T )/λ 1 (XX T ) of the input data Gram matrix for both infinite and finite width networks.\\n\\n• In Corollary 4.7 and Theorem 4.8 we characterize the asymptotic behavior of the NTK spectrum for both uniform and nonuniform data distributions on the sphere.\\n\\n\\nRelated work\\n\\nNeural Tangent Kernel (NTK): the NTK was introduced by Jacot et al. (2018), who demonstrated that in the infinite width limit neural network optimization is described via a kernel gradient descent. As a consequence, when the network is polynomially wide in the number of samples, global convergence guarantees for gradient descent can be obtained (Du et al., 2019a,b;Allen-Zhu et al., 2019;Zou & Gu, 2019;Zou et al., 2020;Oymak & Soltanolkotabi, 2020;Nguyen & Mondelli, 2020;Nguyen, 2021). Furthermore, the connection between infinite width networks and Gaussian processes, which traces back to Neal (1996), has been reinvigorated in light of the NTK. Recent investigations include Lee et al. (2018); de G. Matthews et al. (2018); .\\n\\nAnalysis of NTK Spectrum: theoretical analysis of the NTK spectrum via random matrix theory was investigated by Yang & Salman (2019); Fan & Wang (2020) in the high dimensional limit. Velikanov & Yarotsky (2021) demonstrated that for ReLU networks the spectrum of the NTK integral operator asymptotically follows a power law, which is consistent with our results for the uniform data distribution. Basri et al. (2019) calculated the NTK spectrum for shallow ReLU networks under the uniform distribution, which was then expanded to the nonuniform case by Basri et al. (2020). Geifman et al. (2022) analyzed the spectrum of the conjugate kernel and NTK for convolutional networks with ReLU activations whose pixels are uniformly distributed on the sphere. Geifman et al. (2020); Bietti & Bach (2021); Chen & Xu (2021) analyzed the reproducing kernel Hilbert spaces of the NTK for ReLU networks and the Laplace kernel via the decay rate of the spectrum of the kernel. In contrast to previous works, we are able to address the spectrum in the finite dimensional setting and characterize the impact of different activation functions on it.\\n\\nHermite Expansion: Daniely et al. (2016) used Hermite expansion to the study the expressivity of the Conjugate Kernel. Simon et al. (2022) used this technique to demonstrate that any dot product kernel can be realized by the NTK or Conjugate Kernel of a shallow, zero bias network. Oymak & Soltanolkotabi (2020) use Hermite expansion to study the NTK and establish a quantitative bound on the smallest eigenvalue for shallow networks. This approach was incorporated by Nguyen & Mondelli (2020) to handle convergence for deep networks, with sharp bounds on the smallest NTK eigenvalue for deep ReLU networks provided by . The Hermite approach was utilized by Panigrahi et al. (2020) to analyze the smallest NTK eigenvalue of shallow networks under various activations. Finally, in a concurrent work Han et al. (2022) use Hermite expansions to develop a principled and efficient polynomial based approximation algorithm for the NTK and CNTK. In contrast to the aforementioned works, here we employ the Hermite expansion to characterize both the outlier and asymptotic portions of the spectrum for both shallow and deep networks under general activations.\\n\\n\\nPreliminaries\\n\\nFor our notation, lower case letters, e.g., x, y, denote scalars, lower case bold characters, e.g., x, y are for vectors, and upper case bold characters, e.g., X, Y, are for matrices. For natural numbers k 1 , k 2 ∈ N we let [k 1 ] = {1, . . . , k 1 } and [k 2 , k 1 ] = {k 2 , . . . , k 1 }. If k 2 > k 1 then [k 2 , k 1 ] is the empty set. We use · p to denote the p-norm of the matrix or vector in question and as default use · as the operator or 2-norm respectively. We use 1 m×n ∈ R m×n to denote the matrix with all entries equal to one. We define δ p=c to take the value 1 if p = c and be zero otherwise. We will frequently overload scalar functions φ : R → R by applying them elementwise to vectors and matrices. The entry in the ith row and jth column of a matrix we access using the notation [X] ij . The Hadamard or entrywise product of two matrices X, Y ∈ R m×n we denote X Y as is standard. The pth Hadamard power we denote X p and define it as the Hadamard product of X with itself p times,\\nX p := X X · · · X.\\nGiven a Hermitian or symmetric matrix X ∈ R n×n , we adopt the convention that λ i (X) denotes the ith largest eigenvalue, λ 1 (X) ≥ λ 2 (X) ≥ · · · ≥ λ n (X). Finally, for a square matrix X ∈ R n×n we let T r(X) = n i=1 [X] ii denote the trace.\\n\\n\\nHermite Expansion\\n\\nWe say that a function f : R → R is square integrable with respect to the standard Gaussian measure γ(z) = 1 √ 2π e −z 2 /2 if E X∼N (0,1) [f (X) 2 ] < ∞. We denote by L 2 (R, γ) the space of all such functions. The normalized probabilist's Hermite polynomials are defined as\\nh k (x) = (−1) k e x 2 /2 √ k! d k dx k e −x 2 /2 , k = 0, 1, . . .\\nand form a complete orthonormal basis in L 2 (R, γ) (O'Donnell, 2014, §11). The Hermite expansion of a function φ ∈ L 2 (R, γ) is given by\\nφ(x) = ∞ k=0 µ k (φ)h k (x), where µ k (φ) = E X∼N (0,1) [φ(X)h k (X)]\\nis the kth normalized probabilist's Hermite coefficient of φ.\\n\\n\\nNTK Parametrization\\n\\nIn what follows, for n, d ∈ N let X ∈ R n×d denote a matrix which stores n points in R d row-wise. Unless otherwise stated, we assume d ≤ n and denote the ith row of X n as x i . In this work we consider fully-connected neural networks of the form f (L+1) : R d → R with L ∈ N hidden layers and a linear output layer. For a given input vector x ∈ R d , the activation f (l) and preactivation g (l) at each layer l ∈ [L + 1] are defined via the following recurrence relations,\\ng (1) (x) = γ w W (1) x + γ b b (1) , f (1) (x) = φ g (1) (x) , g (l) (x) = σ w √ m l−1 W (l) f (l−1) (x) + σ b b (l) , f (l) (x) = φ g (l) (x) , ∀l ∈ [2, L], g (L+1) (x) = σ w √ m L W (L+1) f (L) (x), f (L+1) (x) = g (L+1) (x).(1)\\nThe parameters W (l) ∈ R m l ×m l−1 and b (l) ∈ R m l are the weight matrix and bias vector at the lth layer respectively, m 0 = d, m L+1 = 1, and φ : R → R is the activation function applied elementwise. The variables γ w , σ w ∈ R >0 and γ b , σ b ∈ R ≥0 correspond to weight and bias hyperparameters respectively. Let θ l ∈ R p denote a vector storing the network parameters (W (h) , b (h) ) l h=1 up to and including the lth layer. The Neural Tangent Kernel (Jacot et al., 2018) Θ (l) : R d × R d → R associated with f (l) at layer l ∈ [L + 1] is defined as Θ (l) (x, y) := ∇ θ l f (l) (x), ∇ θ l f (l) (y) .\\n\\n(2)\\n\\nWe will mostly study the NTK under the following standard assumptions. Assumption 1. NTK initialization.\\n\\n1. At initialization all network parameters are distributed as N (0, 1) and are mutually independent.\\n\\n2. The activation function satisfies φ ∈ L 2 (R, γ), is differentiable almost everywhere and its derivative, which we denote φ , also satisfies φ ∈ L 2 (R, γ).\\n\\n3. The widths are sent to infinity in sequence, m 1 → ∞, m 2 → ∞, . . . , m L → ∞.\\n\\nUnder Assumption 1, for any l ∈ [L + 1],Θ (l) (x, y) converges in probability to a deterministic limit Θ (l) : Jacot et al., 2018) and the network behaves like a kernelized linear predictor during training; see, e.g., Arora et al. (2019b); Woodworth et al. (2020). Given access to the rows (x i ) n i=1 of X the NTK matrix at layer l ∈ [L + 1], which we denote K l , is the n × n matrix with entries defined as\\nR d × R d → R ([K l ] ij = 1 n Θ (l) (x i , x j ), ∀(i, j) ∈ [n] × [n].(3)\\n3 Expressing the NTK as a power series\\n\\nThe following assumption allows us to study a power series for the NTK of deep networks and with general activation functions. We remark that power series for the NTK of deep networks with positive homogeneous activation functions, namely ReLU, have been studied in prior works Han et al. (2022); Chen & Xu (2021); Bietti & Bach (2021);Geifman et al. (2022). We further remark that while these works focus on the asymptotics of the NTK spectrum we also study the large eigenvalues. Assumption 2. The hyperparameters of the network satisfy γ 2\\nw + γ 2 b = 1, σ 2 w E Z∼N (0,1) [φ(Z) 2 ] ≤ 1 and σ 2 b = 1 − σ 2 w E Z∼N (0,1) [φ(Z) 2 ]. The data is normalized so that x i = 1 for all i ∈ [n].\\nRecall under Assumption 1 that the preactivations of the network are centered Gaussian processes (Neal, 1996;Lee et al., 2018). Assumption 2 ensures the preactivation of each neuron has unit variance and thus is reminiscent of the LeCun et al. (2012), Glorot & Bengio (2010) and He et al. (2015) initializations, which are designed to avoid vanishing and exploding gradients. We refer the reader to Appendix A.3 for a thorough discussion. Under Assumption 2 we will show it is possible to write the NTK not only as a dot-product kernel but also as an analytic power series on [−1, 1] and derive expressions for the coefficients. In order to state this result recall, given a function f ∈ L 2 (R, γ), that the pth normalized probabilist's Hermite coefficient of f is denoted µ p (f ), we refer the reader to Appendix A.4 for an overview of the Hermite polynomials and their properties. Furthermore, lettingā = (a j ) ∞ j=0 denote a sequence of real numbers, then for any p, k ∈ Z ≥0 we define\\nF (p, k,ā) = \\uf8f1 \\uf8f4 \\uf8f2 \\uf8f4 \\uf8f3 1,\\nk = 0 and p = 0, 0, k = 0 and p ≥ 1,\\n(ji)∈J (p,k) k i=1 a ji , k ≥ 1 and p ≥ 0,(4)\\nwhere\\nJ (p, k) := (j i ) i∈[k] : j i ≥ 0 ∀i ∈ [k], k i=1 j i = p for all p ∈ Z ≥0 , k ∈ N.\\nHere J (p, k) is the set of all k-tuples of nonnegative integers which sum to p and F (p, k,ā) is therefore the sum of all ordered products of k elements ofā whose indices sum to p. We are now ready to state the key result of this section, Theorem 3.1, whose proof is provided in Appendix B.1. Theorem 3.1. Under Assumptions 1 and 2, for all l ∈ [L + 1]\\nnK l = ∞ p=0 κ p,l XX T p .(5)\\nThe series for each entry n[K l ] ij converges absolutely and the coefficients κ p,l are nonnegative and can be evaluated using the recurrence relationships\\nκ p,l = δ p=0 γ 2 b + δ p=1 γ 2 w , l = 1, α p,l + p q=0 κ q,l−1 υ p−q,l , l ∈ [2, L + 1],(6)\\nwhere\\nα p,l = σ 2 w µ 2 p (φ) + δ p=0 σ 2 b , l = 2, ∞ k=0 α k,2 F (p, k,ᾱ l−1 ), l ≥ 3,(7)\\nand\\nυ p,l = σ 2 w µ 2 p (φ ), l = 2, ∞ k=0 υ k,2 F (p, k,ᾱ l−1 ), l ≥ 3,(8)\\nare likewise nonnegative for all p ∈ Z ≥0 and l ∈ [2, L + 1].\\n\\nAs already remarked, power series for the NTK have been studied in previous works, however, to the best of our knowledge Theorem 3.1 is the first to explicitly express the coefficients at a layer in terms of the coefficients of previous layers. To compute the coefficients of the NTK as per Theorem 3.1, the Hermite coefficients of both φ and φ are required. Under Assumption 3 below, which has minimal impact on the generality of our results, this calculation can be simplified. In short, under Assumption 3 υ p,2 = (p + 1)α p+1,2 and therefore only the Hermite coefficients of φ are required. We refer the reader to Lemma B.3 in Appendix B.2 for further details.\\n\\nAssumption 3. The activation function φ : R → R is absolutely continuous on [−a, a] for all a > 0, differentiable almost everywhere, and is polynomially bounded, i.e., |φ(x)| = O(|x| β ) for some β > 0. Further, the derivative φ : R → R satisfies φ ∈ L 2 (R, γ).\\n\\nWe remark that ReLU, Tanh, Sigmoid, Softplus and many other commonly used activation functions satisfy Assumption 3. In order to understand the relationship between the Hermite coefficients of the activation function and the coefficients of the NTK, we first consider the simple two-layer case with L = 1 hidden layers. From Theorem 3.1\\nκ p,2 = σ 2 w (1 + γ 2 w p)µ 2 p (φ) + σ 2 w γ 2 b (1 + p)µ 2 p+1 (φ) + δ p=0 σ 2 b .(9)\\nAs per Table 1, a general trend we observe across all activation functions is that the first few coefficients account for the large majority of the total NTK coefficient series.  \\nγ 2 w = 1, γ 2 b = 0, σ 2 w = 1 and σ 2 b = 1 − E[φ(Z) 2 ].1. if φ(z) = ReLU (z), then κ p,2 = δ (γ b >0)∪(p even) Θ(p −3/2 ), 2. if φ(z) = T anh(z), then κ p,2 = O exp − π √ p−1 2 , 3. if φ(z) = ω σ (z), then κ p,2 = δ (γ b >0)∪(p even) Θ(p 1/2 (σ 2 + 1) −p ).\\nThe trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as ω σ , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l ≥ 3 is challenging due to the calculation of F (p, k,ᾱ l−1 ) (4). In Appendix B.4 we provide preliminary results in this direction, upper bounding, in a very specific setting, the decay of the NTK coefficients for depths l ≥ 2. Finally, we briefly pause here to highlight the potential for using a truncation of (5) in order to perform efficient numerical approximation of the infinite width NTK. We remark that this idea is also addressed in a concurrent work by Han et al. (2022), albeit under a somewhat different set of assumptions 1 . As per our observations thus far that the coefficients of the NTK power series (5) typically decay quite rapidly, one might consider approximating Θ (l) by computing just the first few terms in each series of (5). Figure 2 in Appendix B.3 displays the absolute error between the truncated ReLU NTK and the analytical expression for the ReLU NTK, which is also defined in Appendix B.3. Letting ρ denote the input correlation then the key takeaway is that while for |ρ| close to one the approximation is poor, for |ρ| < 0.5, which is arguably more realistic for real-world data, with just 50 coefficients machine level precision can be achieved. We refer the interested reader to Appendix B.3 for a proper discussion.\\n\\n\\nAnalyzing the spectrum of the NTK via its power series\\n\\nIn this section, we consider a general kernel matrix power series of the form nK =\\n∞ p=0 c p (XX T ) p where {c p } ∞ p=0\\nare coefficients and X is the data matrix. According to Theorem 3.1, the coefficients of the NTK power series (5) are always nonnegative, thus we only consider the case where c p are nonnegative. We will also consider the kernel function power series, which we denote as K(x 1 , x 2 ) = ∞ p=0 c p x 1 , x 2 p . Later on we will analyze the spectrum of kernel matrix K and kernel function K.\\n\\n\\nAnalysis of the upper spectrum and effective rank\\n\\nIn this section we analyze the upper part of the spectrum of the NTK, corresponding to the large eigenvalues, using the power series given in Theorem 3.1. Our first result concerns the effective rank (Huang et al., 2022) of the NTK. Given a positive semidefinite matrix A ∈ R n×n we define the effective rank of A to be\\neff(A) = T r(A) λ 1 (A) .\\nThe effective rank quantifies how many eigenvalues are on the order of the largest eigenvalue. This follows from the Markov-like inequality |{p :\\nλ p (A) ≥ cλ 1 (A)}| ≤ c −1 eff(A)(10)\\nand the eigenvalue bound\\nλ p (A) λ 1 (A) ≤ eff(A) p .\\nOur first result is that the effective rank of the NTK can be bounded in terms of a ratio involving the power series coefficients. As we are assuming the data is normalized so that x i = 1 for all i ∈ [n], then observe by the linearity of the trace\\nT r(nK) = ∞ p=0 c p T r((XX T ) p ) = n ∞ p=0 c p ,\\nwhere we have used the fact that T r((XX T ) p ) = n for all p ∈ N. On the other hand,\\nλ 1 (nK) ≥ λ 1 (c 0 (XX T ) 0 ) = λ 1 (c 0 1 n×n ) = nc 0 .\\nCombining these two results we get the following theorem. Theorem 4.1. Assume that we have a kernel Gram matrix K of the form nK = ∞ p=0 c p (XX T ) p where c 0 = 0. Furthermore, assume the input data x i are normalized so that x i = 1 for all i ∈ [n]. Then\\neff(K) ≤ ∞ p=0 c p c 0 .\\nBy Theorem 3.1 c 0 = 0 provided the network has biases or the activation function has nonzero Gaussian expectation (i.e., µ 0 (φ) = 0). Thus we have that the effective rank of K is bounded by an O(1) quantity. In the case of ReLU for example, as evidenced by Table 1, the effective rank will be roughly 2.3 for a shallow network. By contrast, a well-conditioned matrix would have an effective rank that is Ω(n). Combining Theorem 4.1 and the Markov-type bound (10) we make the following important observation. Observation 4.2. The largest eigenvalue λ 1 (K) of the NTK takes up an Ω(1) fraction of the entire trace and there are O(1) eigenvalues on the same order of magnitude as λ 1 (K), where the O(1) and Ω(1) notation are with respect to the parameter n.\\n\\nWhile the constant term c 0 1 n×n in the kernel leads to a significant outlier in the spectrum of K, it is rather uninformative beyond this. What interests us is how the structure of the data X manifests in the spectrum of the kernel matrix K. For this reason we will examine the centered kernel matrix K := K − c0 n 1 n×n . By a very similar argument as before we get the following result. Theorem 4.3. Assume that we have a kernel Gram matrix K of the form nK = ∞ p=0 c p (XX T ) p where c 1 = 0. Furthermore, assume the input data x i are normalized so that x i = 1 for all i ∈ [n]. Then the centered kernel K := K − c0 n 1 n×n satisfies\\neff( K) ≤ eff(XX T ) ∞ p=1 c p c 1 .\\nThus we have that the effective rank of the centered kernel K is upper bounded by a constant multiple of the effective rank of the input data Gram XX T . Furthermore, we can take the ratio ∞ p=1 cp c1 as a measure of how much the NTK inherits the behavior of the linear kernel XX T : in particular, if the input data gram has low effective rank and this ratio is moderate then we may conclude that the centered NTK must also have low effective rank. Again from Table 1, in the shallow setting we see that this ratio tends to be small for many of the common activations, for example, for ReLU it is roughly 1.3. To summarize then from Theorem 4.3 we make the important observation.\\n\\nObservation 4.4. Whenever the input data are approximately low rank, the centered kernel matrix K = K − c0 n 1 n×n is also approximately low rank.\\n\\nIt turns out that this phenomenon also holds for finite-width networks at initialization. Consider the shallow model\\nm =1 a φ( w , x ), where x ∈ R d and w ∈ R d , a ∈ R for all ∈ [m].\\nThe following theorem demonstrates that when the width m is linear in the number of samples n then eff(K) is upper bounded by a constant multiple of eff(XX T ).\\n\\nTheorem 4.5. Assume φ(x) = ReLU (x) and n ≥ d. Fix > 0 small. Suppose that w 1 , . . . , w m ∼ N (0, ν 2 1 I d ) i.i.d. and a 1 , . . . , a m ∼ N (0, ν 2 2 ). Set M = max i∈[n] x i 2 , and let\\nΣ := E w∼N (0,ν 2 1 I) [φ(Xw)φ(w T X T )].\\nThen\\nm = Ω max(λ 1 (Σ) −2 , 1) max(n, log(1/ )) , ν 1 = O(1/M √ m)\\nsuffices to ensure that, with probability at least 1 − over the sampling of the parameter initialization,\\neff(K) ≤ C · eff(XX T ),\\nwhere C > 0 is an absolute constant.  Li et al. (2020), andOymak &Soltanolkotabi (2020). In this setting we can reduce the dependence on the width m to only be logarithmic in the number of samples n, and we have an accompanying lower bound. See Theorem C.5 in the Appendix C.2.3 for details.\\n\\nIn Figure 1 we empirically validate our theory by computing the spectrum of the NTK on both Caltech101 (Li et al., 2022) and isotropic Gaussian data for feedforward networks. We use the functorch 2 module in PyTorch (Paszke et al., 2019) using an algorithmic approach inspired by Novak et al. (2022). As per Theorem 4.1 and Observation 4.2, we observe all network architectures exhibit a dominant outlier eigenvalue due to the nonzero constant coefficient in the power series. Furthermore, this dominant outlier becomes more pronounced with depth, as can be observed if one carries out the calculations described in Theorem 3.1. Additionally, this outlier is most pronounced for ReLU, as the combination of its Gaussian mean plus bias term is the largest out of the activations considered here. As predicted by Theorem 4.3, Observation 4.4 and Theorem 4.5, we observe real-world data, which has a skewed spectrum and hence a low effective rank, results in the spectrum of the NTK being skewed. By contrast, isotropic Gaussian data has a flat spectrum, and as a result beyond the outlier the decay of eigenvalues of the NTK is more gradual. These observations support the claim that the NTK inherits its spectral structure from the data. We also observe that the spectrum for Tanh is closer to the linear activation relative to ReLU: intuitively this should not be surprising as close to the origin Tanh is well approximated by the identity. Our theory provides a formal explanation for this observation, indeed, the power series coefficients for Tanh networks decay quickly relative to ReLU. We provide further experimental results in Appendix C.3, including for CNNs where we observe the same trends. We note that the effective rank has implications for the generalization error. The Rademacher complexity of a kernel method (and hence the NTK model) within a parameter ball is determined by its its trace (Bartlett & Mendelson, 2002). Since for the NTK λ 1 (K) = O(1), lower effective rank implies smaller trace and hence limited complexity. Figure 1: (Feedforward NTK Spectrum) We plot the normalized eigenvalues λ p /λ 1 of the NTK Gram matrix K and the data Gram matrix XX T for Caltech101 and isotropic Gaussian datasets. To compute the NTK we randomly initialize feedforward networks of depths 2 and 5 with width 500. We use the standard parameterization and Pytorch's default Kaiming uniform initialization in order to better connect our results with what is used in practice. We consider a batch size of n = 200 and plot the first 100 eigenvalues. The thick part of each curve corresponds to the mean across 10 trials, while the transparent part corresponds to the 95% confidence interval\\n\\n\\nAnalysis of the lower spectrum\\n\\nIn this section, we analyze the lower part of the spectrum using the power series. We first analyze the kernel function K which we recall is a dot-product kernel of the form K(x 1 , x 2 ) = ∞ p=0 c p x 1 , x 2 p . Assuming the training data is uniformly distributed on a hypersphere it was shown by Basri et al. (2019); Bietti & Mairal (2019) that the eigenfunctions of K are the spherical harmonics. Azevedo & Menegatto (2015) gave the eigenvalues of the kernel K in terms of the power series coefficients.\\n\\nTheorem 4.6. [Azevedo & Menegatto (2015)] Let Γ denote the gamma function. Suppose that the training data are uniformly sampled from the unit hypersphere S d , d ≥ 2. If the dot-product kernel function has the expansion K(x 1 , x 2 ) = ∞ p=0 c p x 1 , x 2 p where c p ≥ 0, then the eigenvalue of every spherical harmonic of frequency k is given by\\nλ k = π d/2 2 k−1 p≥k p−k is even c p Γ(p + 1)Γ( p−k+1 2 ) Γ(p − k + 1)Γ( p−k+1 2 + k + d/2) .\\nA proof of Theorem 4.6 is provided in Appendix C.4 for the reader's convenience. This theorem connects the coefficients c p of the kernel power series with the eigenvalues λ k of the kernel. In particular, given a specific decay rate for the coefficients c p one may derive the decay rate of λ k : for example, Scetbon & Harchaoui (2021) examined the decay rate of λ k if c p admits a polynomial decay or exponential decay. The following Corollary summarizes the decay rates of λ k corresponding to two layer networks with different activations.\\n\\nCorollary 4.7. Under the same setting as in Theorem 4.6,\\n1. if c p = Θ(p −a ) where a ≥ 1, then λ k = Θ(k −d−2a+2 ), 2. if c p = δ (p even) Θ(p −a ), then λ k = δ (k even) Θ(k −d−2a+2 ), 3. if c p = O exp −a √ p , then λ k = O k −d+1/2 exp −a √ k , 4. if c p = Θ(p 1/2 a −p ), then λ k = O k −d+1 a −k and λ k = Ω k −d/2+1 2 −k a −k .\\nIn addition to recovering existing results for ReLU networks Basri et al. (2019); Velikanov & Yarotsky (2021); Geifman et al. (2020); Bietti & Bach (2021), Corollary 4.7 also provides the decay rates for two-layer networks with Tanh and Gaussian activations. As faster eigenvalue decay implies a smaller RKHS Corollary 4.7 shows using ReLU results in a larger RKHS relative to Tanh or Gaussian activations. Numerics for Corollary 4.7 are provided in Figure 4 in Appendix C.3. Finally, in Theorem 4.8 we relate a kernel's power series to its spectral decay for arbitrary data distributions. Theorem 4.8 (Informal). Let the rows of X ∈ R n×d be arbitrary points on the unit sphere. Consider the kernel matrix nK = ∞ p=0 c p XX T p and let r(n) ≤ d denote the rank of XX T . Then\\n1. if c p = O(p −α ) with α > r(n) + 1 for all n ∈ Z ≥0 then λ n (K) = O n − α−1 r(n) , 2. if c p = O(e −α √ p ) then λ n (K) = O n 1 2r(n) exp −α n 1 2r(n) for any α < α2 −1/2r(n) , 3. if c p = O(e −αp ) then λ n (K) = O exp −α n 1 r(n)\\nfor any α < α2 −1/2r(n) .\\n\\nAlthough the presence of the factor 1/r(n) in the exponents of n in these bounds is a weakness, Theorem 4.8 still illustrates how, in a highly general setting, the asymptotic decay of the coefficients of the power series ensures a certain asymptotic decay in the eigenvalues of the kernel matrix. A formal version of this result is provided in Appendix C.5 along with further discussion.\\n\\n\\nConclusion\\n\\nUsing a power series expansion we derived a number of insights into both the outliers as well as the asymptotic decay of the spectrum of the NTK. We are able to perform our analysis without recourse to a high dimensional limit or the use of random matrix theory. Interesting avenues for future work include better characterizing the role of depth and performing the same analysis on networks with convolutional or residual layers.\\n\\n\\nReproducibility Statement\\n\\nTo ensure reproducibility, we make the code public at https://github.com/ bbowman223/data_ntk. An improved analysis of training over-parameterized deep neural networks.\\n\\nIn Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/ 6a61d423d02a1c56250dc23ae7ff12f3-Paper.pdf. Difan Zou, Yuan Cao, Dongruo Zhou, and Quanquan Gu. Gradient descent optimizes over-parameterized deep ReLU networks. Machine learning, 109 (3):467-492, 2020.\\n\\nThe appendix is organized as follows.\\n\\n• Appendix A gives background material on Gaussan kernels, NTK, unit variance intitialization, and Hermite polynomial expansions. • Appendix B provides details for Section 3.\\n\\n• Appendix C provides details for Section 4.\\n\\n\\nA Background material A.1 Gaussian kernel\\n\\nObserve by construction that the flattened collection of preactivations at the first layer (g (1) (x i )) n i=1 form a centered Gaussian process, with the covariance between the αth and βth neuron being described by\\nΣ (1) α β (x i , x j ) := E[g (1) α (x i )g (1) β (x j )] = δ α=β γ 2 w x T i x j + γ 2 b .\\nUnder the Assumption 1, the preactivations at each layer l ∈ [L + 1] converge also in distribution to centered Gaussian processes (Neal, 1996;Lee et al., 2018). We remark that the sequential width limit condition of Assumption 1 is not necessary for this behavior, for example the same result can be derived in the setting where the widths of the network are sent to infinity simultaneously under certain conditions on the activation function (de G. Matthews et al., 2018). However, as our interests lie in analyzing the limit rather than the conditions for convergence to said limit, for simplicity we consider only the sequential width limit. As per Lee et al. (2018, Eq. 4), the covariance between the preactivations of the αth and βth neurons at layer l ≥ 2 for any input pair x, y ∈ R are described by the following kernel,\\nΣ (l) α β (x, y) := E[g (l) α (x)g (l) β (y)] = δ α=β σ 2 w E g (l−1) ∼GP(0,Σ l−1 ) [φ(g (l−1) α (x))φ(g (l−1) β (y))] + σ 2 b .\\nWe refer to this kernel as the Gaussian kernel. As each neuron is identically distributed and the covariance between pairs of neurons is 0 unless α = β, moving forward we drop the subscript and discuss only the covariance between the preactivations of an arbitrary neuron given two inputs. As per the discussion by Lee et al. (2018, Section 2.3), the expectations involved in the computation of these Gaussian kernels can be computed with respect to a bivariate Gaussian distribution, whose covariance matrix has three distinct entries: the variance of a preactivation of x at the previous layer, Σ (l−1) (x, x), the variance of a preactivation of y at the previous layer, Σ (l) (y, y), and the covariance between preactivations of x and y, Σ (l−1) (x, y). Therefore the Gaussian kernel, or covariance function, and its derivative, which we will require later for our analysis of the NTK, can be computed via the the following recurrence relations, see for instance (Lee et al., 2018;Jacot et al., 2018;Arora et al., 2019b;,\\nΣ (1) (x, y) = γ 2 w x T x + γ 2 b , A (l) (x, y) = Σ (l−1) (x, x) Σ (l−1) (x, y) Σ (l−1) (y, x) Σ (l−1) (x, x) Σ (l) (x, y) = σ 2 w E (B1,B2)∼N (0,A (l) (x,y)) [φ(B 1 )φ(B 2 )] + σ 2 b , Σ (l) (x, y) = σ 2 w E (B1,B2)∼N (0,A (l) (x,y)) [φ (B 1 )φ (B 2 )] .(11)\\nA.2 Neural Tangent Kernel (NTK)\\n\\nAs discussed in the Section 1, under Assumption 1Θ (l) converges in probability to a deterministic limit, which we denote Θ (l) . This deterministic limit kernel can be expressed in terms of the Gaussian kernels and their derivatives from Section A.1 via the following recurrence relationships (Jacot et al., 2018, Theorem 1),\\nΘ (1) (x, y) = Σ (1) (x, y), Θ (l) (x, y) = Θ (l−1) (x, y)Σ (l) (x, y) + Σ (l) (x, y) = Σ (l) (x, y) + l−1 h=1 Σ (h) (x, y) l h =h+1Σ (h ) (x, y) ∀l ∈ [2, L + 1].(12)\\nA useful expression for the NTK matrix, which is a straightforward extension and generalization of Nguyen et al. (2021, Lemma 3.1), is provided in Lemma A.1 below. Lemma A.1. (Based on , Lemma 3.1) Under Assumption 1, a sequence of positive semidefinite matrices (G l ) L+1 l=1 in R n×n , and the related sequence (Ġ l ) L+1 l=2 also in R n×n , can be constructed via the following recurrence relationships,\\nG 1 = γ 2 w XX T + γ 2 b 1 n×n , G 2 = σ 2 w E w∼N (0,I d ) [φ(Xw)φ(Xw) T ] + σ 2 b 1 n×n , G 2 = σ 2 w E w∼N (0,In) [φ (Xw)φ (Xw) T ], G l = σ 2 w E w∼N (0,In) [φ( G l−1 w)φ( G l−1 w) T ] + σ 2 b 1 n×n , l ∈ [3, L + 1], G l = σ 2 w E w∼N (0,In) [φ ( G l−1 w)φ ( G l−1 w) T ], l ∈ [3, L + 1].(13)\\nThe sequence of NTK matrices (K l ) L+1 l=1 can in turn be written using the following recurrence relationship,\\nnK 1 = G 1 , nK l = G l + nK l−1 Ġ l = G l + l−1 i=1 G i l j=i+1Ġj .(14)\\nProof. For the sequence (G l ) L+1 l=1 it suffices to prove for any i, j ∈ [n] and l ∈\\n[L + 1] that [G l ] i,j = Σ (l) (x i , x j )\\nand G l is positive semi-definite. We proceed by induction, considering the base case l = 1 and comparing (13) with (11) then it is evident that\\n[G 1 ] i,j = Σ (1) (x i , x j ). In addition, G 1 is also clearly positive semi-definite as for any u ∈ R n u T G 1 u = γ 2 w X T u 2 + γ 2 b 1 T n u 2 ≥ 0.\\nWe now assume the induction hypothesis is true for G l−1 . We will need to distinguish slightly between two cases, l = 2 and l ∈ [3, L + 1]. The proof of the induction step in either case is identical. To this end, and for notational ease,\\nlet V = X, w ∼ N (0, I d ) when l = 2, and V = G l−1 , w ∼ N (0, I n ) for l ∈ [3, L + 1]. In either case we let v i denote the ith row of V. For any i, j ∈ [n] [G l ] ij = σ 2 w E w [φ(v T i w)φ(v T j w)] + σ 2 b . Now let B 1 = v T i w, B 2 = v T j w and observe for any α 1 , α 2 ∈ R that α 1 B 1 + α 2 B 2 = n k (α 1 v ik + α 2 v jk )w k ∼ N (0, α 1 v i + α 2 v j 2 )\\n. Therefore the joint distribution of (B 1 , B 2 ) is a mean 0 bivariate normal distribution. Denoting the covariance matrix of this distribution asÃ ∈ R 2×2 , then [G l ] ij can be expressed as (11). This follows by the induction hypothesis as\\n[G l ] ij = σ 2 w E (B1,B2)∼Ã [φ(B 1 )φ(B 2 )] + σ 2 b . To prove [G l ] i,j = Σ (l) it therefore suffices to show thatÃ = A (l) as perE[B 2 1 ] = v T i v i = [G l−1 ] ii = Σ (l−1) (x i , x i ), E[B 2 2 ] = v T j v j = [G l−1 ] jj = Σ (l−1) (x j , x j ), E[B 1 B 2 ] = v T i v j = [G l−1 ] ij = Σ (l−1) (x i , x j ). Finally, G l is positive semi-definite as long as E w [φ(Vw)φ(Vw) T ] is positive semi-definite. Let M (w) = φ(Vw) ∈ R n×n and observe for any w that M (w)M (w) T is positive semi-definite. Therefore E w [M (w)M (w) T ]\\nmust also be positive semi-definite. Thus the inductive step is complete and we may conclude for l ∈ [L + 1] that\\n[G l ] i,j = Σ (l) (x i , x j ).(15)\\nFor the proof of the expression for the sequence (Ġ l ) L+1 l=2 it suffices to prove for any i, j ∈ [n] and l ∈ [L + 1] that\\n[Ġ l ] i,j =Σ (l) (x i , x j ).\\nBy comparing (13) with (11) this follows immediately from (15). Therefore with (13) proven (14) follows from (12).\\n\\n\\nA.3 Unit variance initialization\\n\\nThe initialization scheme for a neural network, particularly a deep neural network, needs to be designed with some care in order to avoid either vanishing or exploding gradients during training Glorot & Bengio (2010) (2010) initialization, first model the preactivations of the network as Gaussian random variables and then select the network hyperparameters in order that the variance of these idealized preactivations is fixed at one. Under Assumption 1 this idealized model on the preactivations is actually realized and if we additionally assume the conditions of Assumption 2 hold then likewise the variance of the preactivations at every layer will be fixed at one. To this end, and as in Poole et al. (2016); Murray et al. (2022), consider the function V :\\nR ≥0 → R ≥0 defined as V (q) = σ 2 w E Z∼N (0,1) φ ( √ qZ) 2 + σ 2 b .(16)\\nNoting that V is another expression for Σ (l) (x, x), derived via a change of variables as per Poole et al. (2016), the sequence of variances (Σ (l) (x, x)) L l=2 can therefore be generated as follows,\\nΣ (l) (x, x) = V (Σ (l−1) (x, x)).(17)\\nThe linear correlation ρ (l) :\\nR d × R d → [−1, 1] between the preactivations of two inputs x, y ∈ R d we define as ρ (l) (x, y) = Σ (l) (x, y) Σ (l) (x, x)Σ (l) (y, y) .(18)\\nAssuming\\nΣ (l) (x, x) = Σ (l) (y, y) = 1 for all l ∈ [L + 1], then ρ (l) (x, y) = Σ (l) (x, y)\\n. Again as in Murray et al. (2022) and analogous to (16)\\n, with Z 1 , Z 2 ∼ N (0, 1) independent, U 1 := Z 1 , U 2 (ρ) := (ρZ 1 + 1 − ρ 2 Z 2 ) 3 we define the correlation function R : [−1, 1] → [−1, 1] as R(ρ) = σ 2 w E[φ(U 1 )φ(U 2 (ρ))] + σ 2 b .(19)\\nNoting under these assumptions that R is equivalent to Σ (l) (x, y), the sequence of correlations (ρ (l) (x, y)) L l=2 can thus be generated as ρ (l) (x, y) = R(ρ (l−1) (x, y)). \\n\\n\\nAs observed in\\nR (ρ) = σ 2 w E[φ (U 1 )φ (U 2 (ρ))].(20)\\nObserve that the expression forΣ (l) and R are equivalent via a change of variables (Poole et al., 2016), and therefore the sequence of correlation derivatives may be computed aṡ\\nΣ (l) (x, y) = R (ρ (l) (x, y)).\\nWith the relevant background material now in place we are in a position to prove Lemma A.2.\\n\\nLemma A.2. Under Assumptions 1 and 2 and defining\\nχ = σ 2 w E Z∼N (0,1) [φ (Z) 2 ] ∈ R >0 , then for all i, j ∈ [n], l ∈ [L + 1] • [G n,l ] ij ∈ [−1, 1] and [G n,l ] ii = 1, • [Ġ n,l ] ij ∈ [−χ, χ] and [Ġ n,l ] ii = χ.\\nFurthermore, the NTK is a dot product kernel, meaning Θ(x i , x j ) can be written as a function of the inner product between the two inputs, Θ(x T i x j ).\\n\\n\\nProof. Recall from Lemma A.1 and its proof that for any\\nl ∈ [L + 1], i, j ∈ [n] [G n,l ] ij = Σ (l) (x i , x j ) and [Ġ n,l ] ij =Σ (l) (x i , x j ). We first prove by induction Σ (l) (x i , x i ) = 1 for all l ∈ [L + 1]. The base case l = 1 follows as Σ (1) (x, x) = γ 2 w x T x + γ 2 b = γ 2 w + γ 2 b = 1.\\nAssume the induction hypothesis is true for layer l − 1. With Z ∼ N (0, 1), then from (16) and (17) \\nΣ (l) (x, x) = V (Σ (l−1) (x, x)) = σ 2 w E φ 2 Σ (l−1) (x, x)Z + σ 2 b = σ 2 w E φ 2 (Z) + σ 2 b = 1,\\nthus the inductive step is complete. As an immediate consequence it follows that [G l ] ii = 1. Also, for any i, j ∈ [n] and l ∈ [L + 1],\\nΣ (l) (x i , x j ) = ρ (l) (x i , x j ) = R(ρ (l−1) (x i , x j )) = R(...R(R(x T i x j ))\\n). Thus we can consider Σ (l) as a univariate function of the input correlation Σ :\\n[−1, 1] → [−1, 1] and also conclude that [G l ] ij ∈ [−1, 1]. Furthermore, Σ (l) (x i , x j ) = R (ρ (l) (x i , x j )) = R (R(...R(R(x T i x j )))),\\nwhich likewise impliesΣ is a dot product kernel. Recall now the random variables introduced to define R:\\nZ 1 , Z 2 ∼ N (0, 1) are independent and U 1 = Z 1 , U 2 = (ρZ 1 + 1 − ρ 2 Z 2 ). Observe U 1 , U 2 are dependent but identically distributed as U 1 , U 2 ∼ N (0, 1).\\nFor any ρ ∈ [−1, 1] then applying the Cauchy-Schwarz inequality gives\\n|R (ρ)| 2 = σ 4 w |E[φ (U 1 )φ (U 2 )]| 2 ≤ σ 4 w E[φ (U 1 ) 2 ]E[φ (U 2 ) 2 ] = σ 4 w E[φ (U 1 ) 2 ] 2 = |R (1)| 2 .\\nAs a result, under the assumptions of the lemmaΣ (l) : χ] are dot product kernels, then from (12) the NTK must also be a dot product kernel and furthermore a univariate function of the pairwise correlation of its input arguments.\\n[−1, 1] → [−χ, χ] andΣ (l) (x i , x i ) = χ. From this it immediately follows that [Ġ l ] ij ∈ [−χ, χ] and [Ġ l ] ii = χ as claimed. Finally, as Σ : [−1, 1] → [−1, 1] anḋ Σ : [−1, 1] → [−χ,\\nThe following corollary, which follows immediately from Lemma A.2 and (14), characterizes the trace of the NTK matrix in terms of the trace of the input gram. Corollary A.3. Under the same conditions as Lemma A.2, suppose φ and σ 2 w are chosen such that χ = 1. Then T r(K n,l ) = l.\\n\\n(21)\\n\\n\\nA.4 Hermite Expansions\\n\\nWe say that a function f :\\nR → R is square integrable w.r.t. the standard Gaussian measure γ = e −x 2 /2 / √ 2π if E x∼N (0,1) [f (x) 2 ] < ∞.\\nWe denote by L 2 (R, γ) the space of all such functions. The probabilist's Hermite polynomials are given by\\nH k (x) = (−1) k e x 2 /2 d k dx k e −x 2 /2 , k = 0, 1, . . . .\\n\\nThe first three Hermite polynomials are\\nH 0 (x) = 1, H 1 (x) = x, H 2 (x) = (x 2 − 1). Let h k (x) = H k (x)\\n√ k! denote the normalized probabilist's Hermite polynomials. The normalized Hermite polynomials form a complete orthonormal basis in L 2 (R, γ) (O'Donnell, 2014, §11): in all that follows, whenever we reference the Hermite polynomials, we will be referring to the normalized Hermite polynomials. The Hermite expansion of a function φ ∈ L 2 (R, γ) is given by\\nφ(x) = ∞ k=0 µ k (φ)h k (x),(22)\\nwhere\\nµ k (φ) = E X∼N (0,1) [φ(X)h k (X)](23)\\nis the kth normalized probabilist's Hermite coefficient of φ. In what follows we shall make use of the following identities.\\n∀k ≥ 1, h k (x) = √ kh k−1 (x),(24)∀k ≥ 1, xh k (x) = √ k + 1h k+1 (x) + √ kh k−1 (x). (25) h k (0) = 0, if k is odd 1 √ k! (−1) k 2 (k − 1)!! if k is even , where k!! = 1, k ≤ 0 k · (k − 2) · · · 5 · 3 · 1, k > 0 odd k · (k − 2) · · · 6 · 4 · 2, k > 0 even .(26)\\nWe also remark that the more commonly encountered physicist's Hermite polynomials, which we denoteH k , are related to the normalized probablist's polynomials as follows,\\nh k (z) = 2 −k/2H k (z/ √ 2) √ k! .\\nThe Hermite expansion of the activation function deployed will play a key role in determining the coefficients of the NTK power series. In particular, the Hermite coefficients of ReLU are as follows. Lemma A.4. Daniely et al. (2016) For φ(z) = max{0, z} the Hermite coefficients are given by , we denote the ith row of A as a i , and further assume that a i = 1. Let φ : R → R satisfy φ ∈ L 2 (R, γ) and define\\nµ k (φ) = \\uf8f1 \\uf8f4 \\uf8f4 \\uf8f2 \\uf8f4 \\uf8f4 \\uf8f3 1/ √ 2π, k = 0, 1/2, k = 1, (k − 3)!!/ √ 2πk!, k even and k ≥ 2, 0, k odd and k > 3.(27M = E w∼N (0,In) [φ(Aw)φ(Aw) T ] ∈ R n×n .\\nThen the matrix series\\nS K = K k=0 µ 2 k (φ) AA T k converges uniformly to M as K → ∞.\\nThe proof of Lemma B.1 follows exactly as in (Nguyen & Mondelli, 2020, Lemma D.2), and is in fact slightly simpler due to the fact we assume the rows of A are unit length and w ∼ N (0, I d ) instead of √ d and w ∼ N (0, 1 d I d ) respectively. For the ease of the reader, we now recall the following definitions, which are also stated in Section 3. Lettingᾱ l := (α p,l ) ∞ p=0 denote a sequence of real coefficients, then \\n\\nwhere\\nJ (p, k) := {(j i ) i∈[k] : j i ≥ 0 ∀i ∈ [k], k i=1 j i = p} for all p ∈ Z ≥0 , k ∈ Z ≥1 .\\nWe are now ready to derive power series for elements of (G l )) L+1 l=1 and (Ġ l )) L+1 l=2 .\\n\\nLemma B.2. Under Assumptions 1 and 2, for all l ∈ [2, L + 1]\\nG l = ∞ k=0 α k,l (XX T ) k ,(29)\\nwhere the series for each element [G l ] ij converges absolutely and the coefficients α p,l are nonnegative. The coefficients of the series (29) for all p ∈ Z ≥0 can be expressed via the following recurrence relationship,\\nα p,l = σ 2 w µ 2 p (φ) + δ p=0 σ 2 b , l = 2, ∞ k=0 α k,2 F (p, k,ᾱ l−1 ), l ≥ 3.(30)Furthermore,Ġ l = ∞ k=0 υ k,l (XX T ) k ,(31)\\nwhere likewise the series for each entry [Ġ l ] ij converges absolutely and the coefficients υ p,l for all p ∈ Z ≥0 are nonnegative and can be expressed via the following recurrence relationship,\\nυ p,l = σ 2 w µ 2 p (φ ), l = 2, ∞ k=0 υ k,2 F (p, k,ᾱ l−1 ), l ≥ 3.(32)\\nProof. We start by proving (29) and (30). Proceeding by induction, consider the base case l = 2. From Lemma A.1\\nG 2 = σ 2 w E w∼N (0,I d ) [φ(Xw)φ(Xw) T ] + σ 2 b 1 n×n .\\nBy the assumptions of the lemma, the conditions of Lemma B.1 are satisfied and therefore\\nG 2 = σ 2 w ∞ k=0 µ 2 k (φ) XX T k + σ 2 b 1 n×n = α 0,2 1 n×n + ∞ k=1 α k,2 XX T k .\\nObserve the coefficients (α k,2 ) k∈Z ≥0 are nonnegative. Therefore, for any i, j ∈ [n] using Lemma A.2 the series for\\n[G l ] ij satisfies ∞ k=0 |α k,2 | x i , x j k ≤ ∞ k=0 α k,2 x i , x i k = [G l ] ii = 1(33)\\nand so must be absolutely convergent. With the base case proved we proceed to assume the inductive hypothesis holds for arbitrary G l with l ∈ [2, L]. Observe\\nG l+1 = σ 2 w E w∼N (0,In) [φ(Aw)φ(Aw) T ] + σ 2 b 1 n×n ,\\nwhere A is a matrix square root of G l , meaning G l = AA. Recall from Lemma A.1 that G l is also symmetric and positive semi-definite, therefore we may additionally assume, without loss of generality, that A ∈ R n×n is symmetric, which conveniently implies G n,l = AA T . Under the assumptions of the lemma the conditions for Lemma A.2 are satisfied and as a result [G n,l ] ii = a i = 1 for all i ∈ [n], where we recall a i denotes the ith row of A. Therefore we may again apply Lemma A.1,\\nG l+1 = σ 2 w ∞ k=0 µ 2 k (φ) AA T k + σ 2 b 1 n×n = (σ 2 w µ 2 0 (φ) + σ 2 b )1 n×n + σ 2 w ∞ k=1 µ 2 k (φ) (G n,l ) k = (σ 2 w µ 2 0 (φ) + σ 2 b )1 n×n + σ 2 w ∞ k=1 µ 2 k (φ) ∞ m=0 α m,l (XX T ) m k ,\\nwhere the final equality follows from the inductive hypothesis. For any pair of indices i, j ∈ [n]\\n[G l+1 ] ij = (σ 2 w µ 2 0 (φ) + σ 2 b ) + σ 2 w ∞ k=1 µ 2 k (φ) ∞ m=0 α m,l x i , x j m k .\\nBy the induction hypothesis, for any i, j ∈ [n] the series ∞ m=0 α m,l x i , x j m is absolutely convergent. Therefore, from the Cauchy product of power series and for any k ∈ Z ≥0 we have\\n∞ m=0 α m,l x i , x j m k = ∞ p=0 F (p, k,ᾱ l ) x i , x j p ,(34)\\nwhere F (p, k,ᾱ l ) is defined in (4). By definition, F (p, k,ᾱ l ) is a sum of products of positive coefficients, and therefore |F (p, k,ᾱ l )| = F (p, k,ᾱ l ). In addition, recall again by Assumption 2 and Lemma A.2 that [G l ] ii = 1. As a result, for any k ∈ Z ≥0 , as |\\nx i , x j | ≤ 1 ∞ p=0 |F (p, k,ᾱ l ) x i , x j p | ≤ ∞ m=0 α m,l k = [G n,l ] ii = 1(35)\\nand therefore the series ∞ p=0 F (p, k,ᾱ l ) x i , x j p converges absolutely. Recalling from the proof of the base case that the series ∞ p=1 α p,2 is absolutely convergent and has only nonnegative elements, we may therefore interchange the order of summation in the following,\\n[G l+1 ] ij = (σ 2 w µ 2 0 (φ) + σ 2 b ) + σ 2 w ∞ k=1 µ 2 k (φ) ∞ p=0 F (p, k,ᾱ l ) x i , x j p = α 0,2 + ∞ k=1 α k,2 ∞ p=0 F (p, k,ᾱ l ) x i , x j p = α 0,2 + ∞ p=0 ∞ k=1 α k,2 F (p, k,ᾱ l ) x i , x j p .\\nRecalling the definition of F (p, k, l) in (4), in particular F (0, 0,ᾱ l ) = 1 and F (p, 0,ᾱ l ) = 0 for p ∈ Z ≥1 , then\\n[G l+1 ] ij = α 0,2 + ∞ k=1 α k,2 F (0, k,ᾱ l ) x i , x j 0 + ∞ p=1 ∞ k=1 α k,2 F (p, k,ᾱ l ) x i , x j p = ∞ k=0 α k,2 F (0, k,ᾱ l ) x i , x j 0 + ∞ p=1 ∞ k=0 α k,2 F (p, k,ᾱ l ) x i , x j p = ∞ p=0 ∞ k=0 α k,2 F (p, k,ᾱ l ) x i , x j p = ∞ p=0 α p,l+1 x i , x j p .\\nAs the indices i, j ∈ [n] were arbitrary we conclude that\\nG l+1 = ∞ p=0\\nα p,l+1 XX T p as claimed. In addition, by inspection and using the induction hypothesis it is clear that the coefficients (α p,l+1 ) ∞ p=0 are nonnegative. Therefore, by an argument identical to (33), the series for each entry of [G l+1 ] ij is absolutely convergent. This concludes the proof of (29) and (30).\\n\\nWe now turn our attention to proving the (31) and (32). Under the assumptions of the lemma the conditions for Lemmas A.1 and B.1 are satisfied and therefore for the base case l = 2\\nG 2 = σ 2 w E w∼N (0,In) [φ (Xw)φ (Xw) T ] = σ 2 w ∞ k=0 µ 2 k (φ ) XX T k = ∞ k=0 υ k,2 XX T k .\\nBy inspection the coefficients (υ p,2 ) ∞ p=0 are nonnegative and as a result by an argument again identical to (33) the series for each entry of [Ġ 2 ] ij is absolutely convergent. For l ∈ [2, L], from (29) and its proof there is a matrix A ∈ R n×n such that G l = AA T . Again applying Lemma B.1\\nG n,l+1 = σ 2 w E w∼N (0,In) [φ (Aw)φ (Aw) T ] = σ 2 w ∞ k=0 µ 2 k (φ ) AA T k = ∞ k=0 υ k,2 (G n,l ) k = ∞ k=0 υ k,2 ∞ p=0 α p,l XX T p k\\nAnalyzing now an arbitrary entry [Ġ l+1 ] ij , by substituting in the power series expression for G l from (29) and using (34) we have\\n[Ġ l+1 ] ij = ∞ k=0 υ k,2 ∞ p=0 α p,l x i , x j p k = ∞ k=0 υ k,2 ∞ p=0 F (p, k,ᾱ l ) x i , x j p = ∞ p=0 ∞ k=0 υ k,2 F (p, k,ᾱ l ) x i , x j p = ∞ p=0 υ p,l+1 x i , x j p .\\nNote that exchanging the order of summation in the third equality above is justified as for any k ∈ Z ≥0 by (35) we have ∞ p=0 F (p, k,ᾱ l )| x i , x j | p ≤ 1 and therefore ∞ k=0 ∞ p=0 υ k,2 F (p, k,ᾱ l ) x i , x j p converges absolutely. As the indices i, j ∈ [n] were arbitrary we conclude thaṫ G l+1 = ∞ p=0 υ p,l+1 XX T p as claimed. Finally, by inspection the coefficients (υ p,l+1 ) ∞ p=0 are nonnegative, therefore, and again by an argument identical to (33), the series for each entry of [Ġ n,l+1 ] ij is absolutely convergent. This concludes the proof.\\n\\nWe are now prove the key result of Section 3. Theorem 3.1. Under Assumptions 1 and 2, for all l ∈ [L + 1]\\nnK l = ∞ p=0 κ p,l XX T p .(5)\\nThe series for each entry n[K l ] ij converges absolutely and the coefficients κ p,l are nonnegative and can be evaluated using the recurrence relationships\\nκ p,l = δ p=0 γ 2 b + δ p=1 γ 2 w , l = 1, α p,l + p q=0 κ q,l−1 υ p−q,l , l ∈ [2, L + 1],(6)\\nwhere\\nα p,l = σ 2 w µ 2 p (φ) + δ p=0 σ 2 b , l = 2, ∞ k=0 α k,2 F (p, k,ᾱ l−1 ), l ≥ 3,(7)\\nand\\nυ p,l = σ 2 w µ 2 p (φ ), l = 2, ∞ k=0 υ k,2 F (p, k,ᾱ l−1 ), l ≥ 3,(8)\\nare likewise nonnegative for all p ∈ Z ≥0 and l ∈ [2, L + 1].\\n\\nProof. We proceed by induction. The base case l = 1 follows trivially from Lemma A.1. We therefore assume the induction hypothesis holds for an arbitrary l − 1 ∈ [1, L]. From (14) and Lemma B.2\\nnK l = G l + nK l−1 Ġ l = ∞ p=0 α p,l XX T p + n ∞ q=0 κ q,l−1 XX T q ∞ w=0 υ w,l XX T w .\\nTherefore, for arbitrary i, j ∈ [n]\\n[nK l ] ij = ∞ p=0 α p,l x i , x j p + n ∞ q=0 κ q,l−1 x i , x j q ∞ w=0 υ w,l x i , x j w . Observe n ∞ q=0 κ q,l−1 x i , x j q = Θ (l−1) (x i , x j )\\nand therefore the series must converge due to the convergence of the NTK. Furthermore, ∞ w=0 υ w,l x i , x j w = [Ġ n,l ] ij and therefore is absolutely convergent by Lemma B.2. As a result, by Merten's Theorem the product of these two series is equal to their Cauchy product. Therefore\\n[nK l ] ij = ∞ p=0 α p,l x i , x j p + ∞ p=0 p q=0 κ q,l−1 υ p−q,l x i , x j p = ∞ p=0 α p,l + p q=0 κ q,l−1 υ p−q,l x i , x j p = ∞ p=0 κ p,l x i , x j p ,\\nfrom which the (5) immediately follows.\\n\\n\\nB.2 Analyzing the coefficients of the NTK power series\\n\\nIn this section we study the coefficients of the NTK power series stated in Theorem 3.1. Our first observation is that, under additional assumptions on the activation function φ, the recurrence relationship (6) can be simplified in order to depend only on the Hermite expansion of φ. Lemma B.3. Under Assumption 3 the Hermite coefficients of φ satisfy\\nµ k (φ ) = √ k + 1µ k+1 (φ) for all k ∈ Z ≥0 .\\nProof. Note for each n ∈ N as φ is absolutely continuous on [−n, n] it is differentiable a.e. on [−n, n]. It follows by the countable additivity of the Lebesgue measure that φ is differentiable a.e. on R. Furthermore, as φ is polynomially bounded we have φ ∈ L 2 (R, e −x 2 /2 / √ 2π). Fix a > 0. Since φ is absolutely continuous on [−a, a] it is of bounded variation on [−a, a]. Also note that h k (x)e −x 2 /2 is of bounded variation on [−a, a] due to having a bounded derivative. Thus we have by Lebesgue-Stieltjes integration-by-parts (see e.g. Folland 1999, Chapter 3)\\na −a φ (x)h k (x)e −x 2 /2 dx = φ(a)h k (a)e −a 2 /2 − φ(−a)h k (−a)e −a 2 /2 + a −a φ(x)[xh k (x) − h k (x)]e −x 2 /2 dx = φ(a)h k (a)e −a 2 /2 − φ(−a)h k (−a)e −a 2 /2 + a −a φ(x) √ k + 1h k+1 (x)e −x 2 /2 dx,\\nwhere in the last line above we have used the fact that (24) and (25) \\nimply that xh k (x) − h k (x) = √ k + 1h k+1 (x). Thus we have shown a −a φ (x)h k (x)e −x 2 /2 dx = φ(a)h k (a)e −a 2 /2 − φ(−a)h k (−a)e −a 2 /2 + a −a φ(x) √ k + 1h k+1 (x)e −x 2 /2 dx.\\nWe note that since |φ(x)h k (x)| = O(|x| β+k ) we have that as a → ∞ the first two terms above vanish. Thus by sending a → ∞ we have\\n∞ −∞ φ (x)h k (x)e −x 2 /2 dx = ∞ −∞ √ k + 1φ(x)h k+1 (x)e −x 2 /2 dx.\\nAfter dividing by √ 2π we get the desired result.\\n\\nIn particular, under Assumption 3, and as highlighted by Corollary B.4, which follows directly from Lemmas B.2 and B.3, the NTK coefficients can be computed only using the Hermite coefficients of φ. Corollary B.4. Under Assumptions 1, 2 and 3, for all p ∈ Z ≥0 υ p,l = (p + 1)α p+1,2 , l = 2, ∞ k=0 υ k,2 F (p, k,ᾱ l−1 ), l ≥ 3.\\n\\nWith these results in place we proceed to analyze the decay of the coefficients of the NTK for depth two networks. As stated in the main text, the decay of the NTK coefficients depends on the decay of the Hermite coefficients of the activation function deployed. This in turn is strongly influenced by the behavior of the tails of the activation function.\\n\\nTo this end we roughly group activation functions into three categories: growing tails, flat or constant tails and finally decaying tails. Analyzing each of these groups in full generality is beyond the scope of this paper, we therefore instead study the behavior of ReLU, Tanh and Gaussian activation functions, being prototypical and practically used examples of each of these three groups respectively. We remark that these three activation functions satisfy Assumption 3. For typographical ease we let ω σ (z) := (1/ √ 2πσ 2 ) exp −z 2 /(2σ 2 ) denote the Gaussian activation function with variance σ 2 . Lemma B.5. Under Assumptions 1 and 2,\\n1. if φ(z) = ReLU (z), then κ p,2 = δ (γ b >0)∪(p even) Θ(p −3/2 ), 2. if φ(z) = T anh(z), then κ p,2 = O exp − π √ p−1 2 , 3. if φ(z) = ω σ (z)\\n, then κ p,2 = δ (γ b >0)∪(p even) Θ(p 1/2 (σ 2 + 1) −p ).\\n\\nProof. Recall (9), κ p,2 = σ 2 w (1 + γ 2 w p)µ 2 p (φ) + σ 2 w γ 2 b (1 + p)µ 2 p+1 (φ) + δ p=0 σ 2 b . In order to bound κ p,2 we proceed by using Lemma A.4 to bound the square of the Hermite coefficients. We start with ReLU. Note Lemma A.4 actually provides precise expressions for the Hermite coefficients of ReLU, however, these are not immediately easy to interpret. Observe from Lemma A.4 that above index p = 2 all odd indexed Hermite coefficients are 0. It therefore suffices to bound the even indexed terms, given by\\nµ p (ReLU ) = 1 √ 2π (p − 3)!! √ p! .\\nObserve from (26) that for p even\\nh p (0) = (−1) p/2 (p − 1)!! √ p! , therefore µ p (ReLU ) = 1 √ 2π (p − 3)!! √ p! = 1 √ 2π |h p (0)| p − 1 .\\nAnalyzing now |h p (0)|,\\n(p − 1)!! √ p! = p/2 i=1 (2i − 1) p/2 i=1 (2i − 1)2i = p/2 i=1 (2i − 1) p/2 i=1 2i = (p − 1)!! p!! .\\nHere, the expression inside the square root is referred to in the literature as the Wallis ratio, for which the following lower and upper bounds are available Kazarinoff (1956),\\n1 π(p + 0.5) < (p − 1)!! p!! < 1 π(p + 0.25) .(37)\\nAs a result |h p (0)| = Θ(p −1/4 ) and therefore µ p (ReLU ) = Θ(p −5/4 ), p even, 0, p odd.\\n\\nAs (p + 1) −3/2 = Θ(p −3/2 ), then from (9) κ p,2 = Θ((pµ 2 p (ReLU ) + δ γ b >0 (p + 1)µ 2 p+1 (ReLU ))) = Θ((δ p even p −3/2 + δ (p odd)∩(γ b >0) (p + 1) −3/2 )) = Θ δ (p even)∪((p odd)∩(γ b >0)) p −3/2 = δ (p even)∪(γ b >0) Θ p −3/2 as claimed in item 1.\\n\\nWe now proceed to analyze φ(z) = T anh(z). From Panigrahi et al. (2020, Corollary F.7.1)\\nµ p (T anh ) = O exp − π √ p 4 .\\nAs Tanh satisfies the conditions of Lemma B.3\\nµ p (T anh) = p −1/2 µ p−1 (T anh ) = O p −1/2 exp − π √ p − 1 4 .\\nTherefore the result claimed in item 2. follows as\\nκ p,2 = O((pµ 2 p (T anh) + (p + 1)µ 2 p+1 (T anh))) = O exp − π √ p − 1 2 + exp − π √ p 2 = O exp − π √ p − 1 2 .\\nFinally, we now consider φ(z) = ω σ (z) where ω σ (z) is the density function of N (0, σ 2 ). Similar to ReLU, analytic expressions for the Hermite coefficients of ω σ (z) are known (see e.g., Davis, 2021, Theorem 2.9), µ 2 p (ω σ ) = p! ((p/2)!) 2 2 p 2π(σ 2 +1) p+1 , p even, 0, p odd.\\n\\nFor p even (p/2)! = p!!2 −p/2 .\\nTherefore p! (p/2)!(p/2)! = 2 p p! p!!p!! = 2 p (p − 1)!! p!! .\\nAs a result, for p even and using (37), it follows that\\nµ 2 p (ω σ ) = (σ 2 + 1) −(p+1) 2π (p − 1)!! p!! = Θ(p −1/2 (σ 2 + 1) −p ).\\nFinally, since (p + 1) 1/2 (σ 2 + 1) −p−1 = Θ(p 1/2 (σ 2 + 1) −p ), then from (9) κ p,2 = Θ((pµ 2 p (ω σ ) + δ γ b >0 (p + 1)µ 2 p+1 (ω σ ))) = Θ δ (p even)∪((p odd)∩(γ b >0)) p 1/2 (σ 2 + 1) −p = δ (p even)∪(γ b >0) Θ p 1/2 (σ 2 + 1) −p as claimed in item 3. Figure 2 Currently, computing the infinite width NTK requires either a) explicit evaluation of the Gaussian integrals highlighted in (13), b) numerical approximation of these same integrals such as in Lee et al. (2018), or c) approximation via a sufficiently wide yet still finite width network, see for instance Engel et al. (2022); Novak et al. (2022). These Gaussian integrals (13) can be solved solved analytically only for a minority of activation functions, notably ReLU as discussed for example by Arora et al. (2019b), while the numerical integration and finite width approximation approaches are relatively computationally expensive. The truncated NTK power series we define as analogous to (5) but with the series involved being computed only up to the T th element. Once the top T coefficients are computed, then for any input correlation the NTK can be approximated by evaluating the corresponding finite degree T polynomial.\\n\\n\\nB.3 Numerical approximation via a truncated NTK power series and interpretation of\\n\\nDefinition B.6. For an arbitrary pair x, y ∈ S d−1 let ρ = x T y denote their linear correlation. Under Assumptions 1, 2 and 3, for all l ∈ [2, L + 1] the T -truncated NTK power seriesΘ (l)\\nT : [−1, 1] → R is defined as Θ (l) T (ρ) = T p=0κ p,l ρ p .(38)\\nand whose coefficients are defined via the following recurrence relation,\\nκ p,l = δ p=0 γ 2 b + δ p=1 γ 2 w , l = 1, α p,l + p q=0κ q,l−1υp−q,l , l ∈ [2, L + 1].(39)\\nHere, withᾱ l−1 = (α p,l−1 ) T p=0 ,α p,l :=\\nσ 2 w µ 2 p (φ) + δ p=0 σ 2 b , l = 2, T k=0α k,2 F (p, k,ᾱ l−1 ), l ≥ 3(40)\\nandυ p,l := √ p + 1α p+1,2 , l = 2,\\nT k=0 √ k + 1α p+1,2 F (p, k,ᾱ l ), l ≥ 3.(41)\\nIn order to analyze the performance and potential of the truncated NTK for numerical approximation, we compute it for ReLU and compare it with its analytical expression Arora et al. (2019b). To recall this result, let\\nR(ρ) := 1 − ρ 2 + ρ · arcsin(ρ) π + ρ 2 , R (ρ) := arcsin(ρ) π + 1 2 .\\nUnder Assumptions 1 and 2, with φ(z) = ReLU (z), γ 2 w = 1, σ 2 w = 2, σ 2 b = γ 2 b = 0, x, y ∈ S d and ρ 1 := x T y, then Θ 1 (x, y) = ρ and for all l ∈ [2, L + 1]\\nρ l = R(ρ l−1 ), Θ l (x, y) = ρ l + ρ l−1 R (ρ l−1 ).(42)\\nTurning our attention to Figure 2, we observe particularly for input correlations |ρ| ≈ 0.5 and below then the truncated ReLU NTK power series achieves machine level precision. For |ρ| ≈ 1 higher order coefficients play a more significant role. As the truncated ReLU NTK power series approximates these coefficients less well the overall approximation of the ReLU NTK is worse. We remark also that negative correlations have a smaller absolute error as odd indexed terms cancel with even index terms: we emphasize again that in Figure 2 we plot the absolute not relative error. In addition, for L = 1 there is symmetry in the absolute error for positive and negative correlations as α p,2 = 0 for all odd p.\\n\\nOne also observes that approximation accuracy goes down with depth, which is due to the error in the coefficients at the previous layer contributing to the error in the coefficients at the next, thereby resulting in an accumulation of error with depth. Also, and certainly as one might expect, a larger truncation point T results in overall better approximation. Finally, as the decay in the Hermite coefficients for ReLU is relatively slow, see e.g., Table 1 and Lemma 3.2, we expect the truncated ReLU NTK power series to perform worse relative to the truncated NTK's for other activation functions. , for |ρ| ≤ 0.5, which we remark is more typical for real world data, T = 50 suffices for the truncated NTK to achieve machine level precision.\\n\\n\\nB.4 Characterizing NTK power series coefficient decay rates for deep networks\\n\\nIn general, Theorem 3.1 does not provide a straightforward path to analyzing the decay of the NTK power series coefficients for depths greater than two. This is at least in part due to the difficulty of analyzing F (p, k,ᾱ l−1 ), which recall is the sum of all ordered products of k elements ofᾱ l−1 whose indices sum to p, defined in (4). However, in the setting where the squares of the Hermite coefficients, and therefore the series (α p,2 ) ∞ p=0 , decay at an exponential rate, this quantity can be characterized and therefore an analysis, at least to a certain degree, of the impact of depth conducted. Although admittedly limited in scope, we highlight that this setting is relevant for the study of Gaussian activation functions and radial basis function (RBF) networks. We will also make the additional simplifying assumption that the activation function has zero Gaussian mean (which can be obtained by centering). Unfortunately this further reduces the applicability of the following results to activation functions commonly used in practice. We leave the study of relaxing this zero bias assumption, perhaps only enforcing exponential decay asymptotically, as well as a proper exploration of other decay patterns, to future work.\\n\\nThe following lemma precisely describes, in the specific setting considered here, the evolution of the coefficients of the Gaussian Process kernel with depth.\\n\\nLemma B.7. Let α 0,2 = 0 and α p,2 = C 2 η −p 2 for p ∈ Z ≥1 , where C 2 and η 2 are constants such that ∞ p=1 α p,2 = 1. Then for all l ≥ 2 and p ∈ Z ≥0\\nα p,l+1 = 0, p = 0, C l+1 η −p l+1 , p ≥ 1(43)\\nwhere the constants η l+1 and C l+1 are defined as\\nη l+1 = η l η 2 η 2 + C l , C l+1 = C l C 2 η 2 + C l .(44)\\nProof. Observe for l = 2, we have that α 0,l = 0 and α p,l = C l η −p l hold by assumption. Thus by induction it suffices to show that α 0,l = 0 and α p,l = C l η −p l implies (43) and (44) hold. Thus assume for some l ≥ 2 we have that α 0,l = 0 and α p,l = C l η −p l . Recall the definition of F from (4): as α 0,l = 0 then with p ≥ 1 and 1 ≤ k ≤ p\\nF (p, k,ᾱ l ) = (ji)∈J (p,k) k i=1 α ji,l = (ji)∈J+(p,k) k i=1 α ji,l , where J + (p, k) := (j i ) i∈[k] : j i ≥ 1 ∀i ∈ [k], k i=1 j i = p for all p ∈ Z ≥1 , k ∈ [p],\\nwhich is the set of all k-tuples of positive (instead of non-negative) integers which sum to p. Substituting α p,l = C l η −p\\nl then F (p, k,ᾱ l ) = (ji)∈J+(p,k) C k l η −p l = C k l η −p l |J + (p, k)| = C k l η −p l p − 1 k − 1 ,\\nwhere the final equality follows from a stars and bars argument. Now observe for k > p that at least one of the indices in (j i ) k i=1 must be 0 and therefore k i=1 α ji,2 = 0. As a result under the assumptions of the lemma\\nF (p, k,ᾱ l ) = \\uf8f1 \\uf8f2 \\uf8f3 1, k = 0 and p = 0, C k l η −p l p−1 k−1 , k ∈ [p] and p ≥ 1, 0, otherwise.(45)\\nSubstituting (45) into (7) it follows that\\nα 0,l+1 = ∞ k=0 α k,2 F (0, k,ᾱ l ) = α 0,2 = 0 and for p ≥ 1 α p,l+1 = ∞ k=0 α k,2 F (p, k,ᾱ l ) = C 2 η −p l p k=1 C l η 2 k p − 1 k − 1 = η −p l C l η −1 2 C 2 p−1 h=0 C l η 2 h p − 1 h = η −p l C l η −1 2 C 2 1 + C l η 2 p−1 = C l C 2 η 2 + C l η l η 2 η 2 + C l −p = C l+1 η −p l+1\\nas claimed.\\n\\nWe now analyze the coefficients of the derivative of the Gaussian Process kernel. Lemma B.8. In addition to the assumptions of Lemma B.7, assume also that φ satisfies Assumption 3. Then υ p,2 = C2 η2 (1 + p)η −p 2 . Furthermore, for all l ≥ 2 and p ∈ Z ≥0\\nυ p,l+1 = C 2 η −1 2 , p = 0, (V l+1 + V l+1 p)η −p l+1 , p ≥ 1,(46)\\nwhere the constants V l+1 and V l+1 are defined as\\nV l+1 := 2C 2 C l η 2 (C l + η 2 ) − C 2 C 2 l η 2 (C l + η 2 ) 2 , V l+1 := C 2 C 2 l η 2 (C l + η 2 ) 2(47)\\nand C l and η l are defined in (44).\\n\\nProof. Under Assumption 3 then for all p ∈ Z ≥0 we have\\nυ p,2 = σ 2 w µ 2 p (φ ) = σ 2 w (p + 1)µ p+1 (φ) 2 = (p + 1)α p+1,2 = C 2 η 2 (1 + p)η −p 2 .\\nFor l ≥ 2 and p = 0 it therefore follows that\\nυ 0,l+1 = ∞ k=0 (k + 1)α k+1,2 F (0, k,ᾱ l ) = α 1,2 = C 2 η −1 2 .\\nFor l ≥ 2 and p ≥ 1 then\\nυ p,l+1 = ∞ k=0 υ k,2 F (p, k,ᾱ l ) = ∞ k=0 (k + 1)α k+1,2 F (p, k,ᾱ l ) = ∞ h=1 hC 2 η −h 2 F (p, h − 1,ᾱ l ) = C 2 C l η −p l p+1 h=2 h C l η 2 h p − 1 h − 2 = C 2 C l η −p l p−1 r=0 (r + 2) C l η 2 r+2 p − 1 r = C 2 C l η 2 2 η −p l 2 p−1 r=0 C l η 2 r p − 1 r + p−1 r=0 r C l η 2 r p − 1 r = C 2 C l η 2 2 η −p l 2 1 + C l η 2 p−1 + C l η 2 (p − 1) 1 + C l η 2 p−2 = 2C 2 C l η 2 (C l + η 2 ) η l η 2 η 2 + C l −p + C 2 C 2 l η 2 (C l + η 2 ) 2 (p − 1) η l η 2 η 2 + C l −p = 2C 2 C l η 2 (C l + η 2 ) − C 2 C 2 l η 2 (C l + η 2 ) 2 η −p l+1 + C 2 C 2 l η 2 (C l + η 2 ) 2 pη −p l+1 = (V l+1 + V l+1 p)η −p l+1\\nas claimed.\\n\\nWith the coefficients of both the Gaussian Process kernel and its derivative characterized, we proceed to upper bound the decay of the NTK coefficients in the specific setting outlined in Lemma B.7 and B.8. Lemma B.9. Let the data, hyperparameters and activation function φ be such that Assumptions 1, 2 and 3 are satisfied along with the conditions of of Lemma B.7. Then for any l ≥ 2 there exist positive constants M l and K l such that for\\nall p ∈ Z ≥1 κ p,l ≤ (M l + K l p 2l−3 )η −p l (48) where η l is defined in Lemma B.7.\\nProof. We proceed by induction starting with the base case l = 2. Applying the results of Lemmas B.7 and B.8 to (6) then for p ∈ Z ≥1 κ p,2 = ((\\nC 2 + γ 2 b C 2 η −1 2 ) + (γ 2 b C 2 η −1 2 + γ 2 w C 2 )p)η −p 2 .(49)\\nIf we define M 2 := C 2 + γ 2 b C 2 η −1 2 and K 2 := γ 2 b C 2 η −1 2 + γ 2 w C 2 , which are clearly positive constants, then κ p,2 = (M 2 + K 2 p)η −p 2 and so for l = 2 the induction hypothesis clearly holds. We now assume the inductive hypothesis holds for some l ≥ 2. Observe from (46), with l ≥ 2 and p ∈ Z ≥0 that\\nυ p,l+1 ≤ (A l+1 + V l+1 p)η −p l+1 .(50)\\nwhere A l+1 := max{C 2 η −1 2 , V l+1 }. Substituting 50 and the inductive hypothesis inequality into (6) it follows for p ≥ 1 that\\nκ p,l+1 ≤ C l+1 η −p l+1 + η −p l+1 p q=0 (M l + K l q 2l−3 )η −q l (A l+1 + V l+1 (p − q))η q l+1 = C l+1 η −p l+1 + η −p l+1 p q=0 (M l + K l q 2l−3 )(A l+1 + V l+1 (p − q)) η 2 η 2 + C l q ≤ C l+1 η −p l+1 + η −p l+1 p q=0 (M l + K l q 2l−3 )(A l+1 + V l+1 (p − q)) ≤ C l+1 η −p l+1 + η −p l+1 p q=0 (M l + K l q 2l−3 )(A l+1 + V l+1 p) ≤ (C l+1 + M l A l+1 )η −p l+1 + M l V l+1 p + p q=1 (M l + K l q 2l−3 )(A l+1 + V l+1 p) η −p l+1 ≤ (C l+1 + M l A l+1 )η −p l+1 + M l V l+1 p + p(M l + K l p 2l−3 )(A l+1 + V l+1 p) η −p l+1 ≤ (C l+1 + M l A l+1 )η −p l+1 + p M l A l+1 + 2M l V l+1 p + K l A l+1 p 2l−3 + K l V l+1 p 2l−2 η −p l+1 ≤ (C l+1 + M l A l+1 ) + M l A l+1 + 2M l V l+1 + K l A l+1 + K l V l+1 p 2l−1 η −p l+1 Therefore there exist positive constants M l+1 = C l+1 +M l A l+1 and K l+1 = M l A l+1 +2M l V l+1 +K l A l+1 +K l V l+1 such that κ p,l+1 ≤ (M l+1 + K l+1 p 2(l+1)−3 )η −p l+1\\nas claimed. This completes the inductive step and therefore also the proof of the lemma. We consider a kernel Gram matrix K ∈ R n×n that has the following power series representation in terms of an input\\ngram matrix XX T nK = ∞ i=0 c i (XX T ) i .\\nWhenever c 0 = 0 the effective rank of K is O(1), as displayed in the following theorem. Theorem 4.1. Assume that we have a kernel Gram matrix K of the form nK = ∞ p=0 c p (XX T ) p where c 0 = 0. Furthermore, assume the input data x i are normalized so that x i = 1 for all i ∈ [n]. Then\\neff(K) ≤ ∞ p=0 c p c 0 .\\nProof. By linearity of trace we have that\\nT r(nK) = ∞ i=0 c i T r((XX T ) i ) = n ∞ i=0 c i\\nwhere we have used the fact that T r((XX T ) i ) = n for all i ∈ N. On the other hand λ 1 (nK) ≥ λ 1 (c 0 (XX T ) 0 ) = λ 1 (c 0 1 n×n ) = nc 0 .\\n\\nThus we have that\\neff(K) = T r(K) λ 1 (K) = T r(nK) λ 1 (nK) ≤ ∞ i=0 c i c 0 .\\nThe above theorem demonstrates that the constant term c 0 1 n×n in the kernel leads to a significant outlier in the spectrum of K. However this fails to capture how the structure of the input data X manifests in the spectrum of K.\\n\\nFor this we will examine the centered kernel matrix K := K − c0 n 11 T . Using a very similar argument as before we can demonstrate that the effective rank of K is controlled by the effective rank of the input data gram XX T . This is formalized in the following theorem. Theorem 4.3. Assume that we have a kernel Gram matrix K of the form nK = ∞ p=0 c p (XX T ) p where c 1 = 0. Furthermore, assume the input data x i are normalized so that x i = 1 for all i ∈ [n]. Then the centered kernel K := K − c0 n 1 n×n satisfies\\neff( K) ≤ eff(XX T ) ∞ p=1 c p c 1 .\\nProof. By the linearity of the trace we have that\\nT r(n K) = ∞ i=1 c i T r((XX T ) i ) = T r(XX T ) ∞ i=1 c i where we have used the fact that T r((XX T ) i ) = T r(XX T ) = n for all i ∈ [n]\\n. On the other hand we have that\\nλ 1 (n K) ≥ λ 1 (c 1 XX T ) = c 1 λ 1 (XX T ).\\nThus we conclude\\neff( K) = T r( K) λ 1 ( K) = T r(n K) λ 1 (n K) ≤ T r(XX T ) λ 1 (XX T ) ∞ i=1 c i c 1 .\\nC.2 Effective rank of the NTK for finite width networks\\n\\n\\nC.2.1 Notation and definitions\\n\\nWe will let [k] := {1, 2, . . . , k}. We consider a neural network\\nm =1 a φ( w , x )\\nwhere x ∈ R d and w ∈ R d , a ∈ R for all ∈ [m] and φ is a scalar valued activation function. The network we present here does not have any bias values in the inner-layer, however the results we will prove later apply to the nonzero bias case by replacing x with [x T , 1] T . We let W ∈ R m×d be the matrix whose -th row is equal to w and a ∈ R m be the vector whose -th entry is equal to a . We can then write the neural network in vector form\\nf (x; W, a) = a T φ(Wx)\\nwhere φ is understood to be applied entry-wise.\\n\\nSuppose we have n training data inputs x 1 , . . . , x n ∈ R d . We will let X ∈ R n×d be the matrix whose i-th row is equal to x i . Let θ inner = vec(W) denote the row-wise vectorization of the inner-layer weights. We consider the Jacobian of the neural networks predictions on the training data with respect to the inner layer weights:\\nJ T inner = ∂f (x 1 ) ∂θ inner , ∂f (x 2 ) ∂θ inner , . . . , ∂f (x n ) ∂θ inner\\nSimilarly we can look at the analagous quantity for the outer layer weights\\nJ T outer = ∂f (x 1 ) ∂a , ∂f (x 2 ) ∂a , . . . , ∂f (x n ) ∂a = φ WX T .\\nOur first observation is that the per-example gradients for the inner layer weights have a nice Kronecker product representation\\n∂f (x) ∂θ inner = \\uf8ee \\uf8ef \\uf8f0 a 1 φ ( w 1 , x ) a 2 φ ( w 2 , x ) · · · a m φ ( w m , x ) \\uf8f9 \\uf8fa \\uf8fb ⊗ x.\\nFor convenience we will let\\nY i := \\uf8ee \\uf8ef \\uf8f0 a 1 φ ( w 1 , x i ) a 2 φ ( w 2 , x i ) · · · a m φ ( w m , x i ) \\uf8f9 \\uf8fa \\uf8fb .\\nwhere the dependence of Y i on the parameters W and a is suppressed (formally Y i = Y i (W, a)). This way we may write\\n\\n∂f\\n(x i ) ∂θ inner = Y i ⊗ x i .\\nWe will study the NTK with respect to the inner-layer weights K inner = J inner J T inner and the same quantity for the outer-layer weights\\nK outer = J outer J T outer .\\nFor a hermitian matrix A we will let λ i (A) denote the ith largest eigenvalue of A so that λ 1 (A) ≥ λ 2 (A) ≥ · · · ≥ λ n (A). Similarly for an arbitrary matrix A we will let σ i (A) to the ith largest singular value of A. For a matrix A ∈ R r×k we will let σ min (A) = σ min(r,k) .\\n\\n\\nC.2.2 Effective rank\\n\\nFor a positive semidefinite matrix A we define the effective rank (Huang et al., 2022) of A to be the quantity\\neff(A) := T r(A) λ 1 (A) .\\nThe effective rank quantifies how many eigenvalues are on the order of the largest eigenvalue. We have the Markov-like inequality\\n|{i : λ i (A) ≥ cλ 1 (A)}| ≤ c −1 T r(A) λ 1 (A)\\nand the eigenvalue bound\\nλ i (A) λ 1 (A) ≤ 1 i T r(A) λ 1 (A) .\\nLet A and B be positive semidefinite matrices. Then we have\\nT r(A + B) λ 1 (A + B) ≤ T r(A) + T r(B) max (λ 1 (A), λ 1 (B)) ≤ T r(A) λ 1 (A) + T r(B) λ 1 (B) .\\nThus the effective rank is subadditive for positive semidefinite matrices.\\n\\nWe will be interested in bounding the effective rank of the NTK. Let K = JJ T = J outer J T outer + J inner J T inner = K outer + K inner be the NTK matrix with respect to all the network parameters. Note that by subadditivity\\nT r(K) λ 1 (K) ≤ T r(K outer ) λ 1 (K outer ) + T r(K inner ) λ 1 (K inner ) .\\nIn this vein we will control the effective rank of K inner and K outer separately.\\n\\n\\nC.2.3 Effective rank of inner-layer NTK\\n\\nWe will show that the effective rank of inner-layer NTK is bounded by a multiple of the effective rank of the data input gram XX T . We introduce the following meta-theorem that we will use to prove various corollaries later Theorem C.1. Set α := sup b =1 min j∈[n] | Y j , b | . Assume α > 0. Then\\nmin i∈[n] Y i 2 2 T r(XX T ) max i∈[n] Y i 2 2 λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner ) ≤ max i∈[n] Y i 2 2 α 2 T r(XX T ) λ 1 (XX T )\\nProof. We will first prove the upper bound. We first observe that\\nT r(K inner ) = n i=1 ∂f (x i ) ∂θ inner 2 2 = n i=1 Y i ⊗ x i 2 2 = n i=1 Y i 2 2 x i 2 2 ≤ max j∈[n] Y j 2 2 n i=1 x i 2 2 = max j∈[n] Y j 2 2 T r(XX T ) Recall that λ 1 (K inner ) = λ 1 J inner J T inner = λ 1 J T inner J inner . Well J T inner J inner = n i=1 ∂f (x i ) ∂θ inner ∂f (x i ) ∂θ inner T = n i=1 [Y i ⊗ x i ] [Y i ⊗ x i ] T = n i=1 Y i Y T i ⊗ x i x T i\\nWell then we may use the fact that\\nλ 1 (J T inner J inner ) = max b 2 =1 b T J T inner J inner b\\nLet b 1 ∈ R m and b 2 ∈ R d be vectors that we will optimize later satisfying b 1 2 b 2 2 = 1. Then we have that b 1 ⊗ b 2 = 1 and\\n(b 1 ⊗ b 2 ) T J T inner J inner (b 1 ⊗ b 2 ) = n i=1 (b 1 ⊗ b 2 ) T Y i Y T i ⊗ x i x T i (b 1 ⊗ b 2 ) = n i=1 b T 1 Y i Y T i b 1 b T 2 x i x T i b 2 ≥ min j∈[n] b T 1 Y j Y T j b 1 n i=1 b T 2 x i x T i b 2 = min j∈[n] b T 1 Y j Y T j b 1 b T 2 n i=1 x i x T i b 2 = min j∈[n] b T 1 Y j Y T j b 1 b 2 X T Xb 2\\nPick b 2 so that b 2 = 1 and b 2 X T Xb 2 = λ 1 (X T X) = λ 1 (XX T ).\\n\\nThus for this choice of b 2 we have\\nλ 1 (J T inner J inner ) ≥ (b 1 ⊗ b 2 ) T J T inner J inner (b 1 ⊗ b 2 ) ≥ min j∈[n] b T 1 Y j Y T j b 1 b 2 X T Xb 2 = min j∈[n] b T 1 Y j Y T j b 1 λ 1 (XX T ) Now note that α 2 = sup b1 =1 min j∈[n] b T 1 Y j Y T j b 1 .\\nThus by taking the sup over b 1 in our previous bound we have λ 1 (K inner ) = λ 1 (J T inner J inner ) ≥ α 2 λ 1 (XX T ). Thus combined with our previous result we have\\nT r(K inner ) λ 1 (K inner ) ≤ max i∈[n] Y i 2 2 α 2 T r(XX T ) λ 1 (XX T ) .\\nWe now prove the lower bound.\\nT r(K inner ) = n i=1 ∂f (x i ) ∂θ inner 2 2 = n i=1 Y i ⊗ x i 2 2 = n i=1 Y i 2 2 x i 2 2 ≥ min j∈[n] Y j 2 2 n i=1 x i 2 2 = min j∈[n] Y j 2 2 T r(XX T )\\nLet Y ∈ R n×m be the matrix whose ith row is equal to Y i . Then observe that\\nK inner = [YY T ] [XX T ]\\nwhere denotes the entry-wise Hadamard product of two matrices. We now recall that if A and B are two positive semidefinite matrices we have (Oymak & Soltanolkotabi, 2020, Lemma 2)\\nλ 1 (A B) ≤ max i∈[n] A i,i λ 1 (B).\\nApplying this to K inner we get that\\nλ 1 (K inner ) ≤ max i∈[n] Y i 2 2 λ 1 (XX T )\\nCombining this with our previous result we get\\nmin i∈[n] Y i 2 2 T r(XX T ) max i∈[n] Y i 2 2 λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner )\\nWe can immediately get a useful corollary that applies to the ReLU activation function\\nCorollary C.2. Set α := sup b =1 min j∈[n] | Y j , b | and γ max := sup x∈R |φ (x)|. Assume α > 0 and γ max < ∞. Then α 2 γ 2 max a 2 2 T r(XX T ) λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner ) ≤ γ 2 max a 2 2 α 2 T r(XX T ) λ 1 (XX T )\\nProof. Note that the hypothesis on |φ | gives Y i 2 2 ≤ γ 2 max a 2 2 for all i ∈ [n]. Moreover by Cauchy-Schwarz we have that min i∈[n] Y i 2 ≥ α. Thus by theorem C.1 we get the desired result.\\n\\nIf φ is a leaky ReLU type activation (say like those used in Nguyen & Mondelli (2020)) Theorem C.1 translates into an even simpler bound\\nCorollary C.3. Suppose φ (x) ∈ [γ min , γ max ] for all x ∈ R where γ min > 0. Then γ 2 min T r(XX T ) γ 2 max λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner ) ≤ γ 2 max γ 2 min T r(XX T ) λ 1 (XX T )\\nProof. We will lower bound\\nα := sup b =1 min j∈[n] | Y j , b |\\nso that we can apply Corollary C.2. Set b = a/ a 2 . Then we have that\\nY j , b = m =1 a φ ( w , x j )a / a 2 ≥ γ min a 2 m =1 a 2 = γ min a 2\\nThus α ≥ γ min a 2 . The result then follows from Corollary C.2\\n\\nTo control α in Theorem C.1 when φ is the ReLU activation function requires a bit more work. To this end we introduce the following lemma.\\nLemma C.4. Assume φ(x) = ReLU (x). Let R min , R max > 0 and define τ = { ∈ [m] : |a | ∈ [R min , R max ]}. Set T = min i∈[n] ∈τ I [ x i , w ≥ 0]. Then α := sup b =1 min i∈[n] | Y i , b | ≥ R 2 min R max T |τ | 1/2\\nProof. Let a τ be the vector such that (a τ ) = a I[ ∈ τ ]. Then note that\\nY j , a τ / a τ 2 = 1 a τ ∈τ a 2 I[ w , x j ≥ 0] ≥ R 2 min a τ ∈τ I[ w , x j ≥ 0] ≥ R 2 min a τ 2 T ≥ R 2 min R max |τ | 1/2 T.\\nRoughly what Lemma C.4 says is that α is controlled when there is a set of inner-layer neurons that are active for each data point whose outer layer weights are similar in magnitude. Note that in Du et al. for some δ, ∈ (0, 1). Then with probability at least 1 − we have that\\n(1 − δ) 2 4 eff(XX T ) ≤ eff(K inner ) ≤ 4 (1 − δ) 2 eff(XX T ).\\nProof. Fix j ∈ [n]. Note by the assumption on the w 's we have that\\nI[ w 1 , x j ≥ 0], . . . , I[ w m , x j ≥ 0] are i.i.d.\\nBernouilli random variables taking the values 0 and 1 with probability 1/2. Thus by the Chernoff bound for Binomial random variables we have that\\nP m =1 I[ w , x j ≥ 0] ≤ m 2 (1 − δ) ≤ exp −δ 2 m 4 .\\nThus taking the union bound over every j ∈ [n] we get that if m ≥ 4 log(n/ )\\nδ 2 then min j∈[n] m =1 I[ w , x j ≥ 0] ≥ m 2 (1 − δ)\\nholds with probability at least 1 − . Now note that if we set R min = R max = R we have that τ = [m] where τ is defined as it is in Lemma C.4. In this case by our previous bound we have that T as defined in Lemma C.4 satisfies T ≥ m 2 (1 − δ) with probability at least 1 − . In this case the conclusion of Lemma C.4 gives us\\nα ≥ Rm 1/2 (1 − δ) 2 = a 2 (1 − δ) 2 .\\nThus by Corollary C.2 and the above bound for α we get the desired result.\\n\\nWe will now use Lemma C.4 to prove a bound in the case of Gaussian initialization. Lemma C.6. Assume φ(x) = ReLU (x). Suppose that a ∼ N (0, ν 2 ) for each ∈ [m] i.i.d. Furthermore suppose w 1 , . . . , w m are random vectors independent of each other and a such that w / w has the uniform distribution on the sphere for each ∈ [m]. Set p = P z∼N (0,1) (|z| ∈ [1/2, 1]) ≈ 0.3. Assume m ≥ 4 log(n/ ) δ 2 (1 − δ)p for some , δ ∈ (0, 1). Then with probability at least (1 − ) 2 we have that\\nα := sup b =1 min i∈[n] | Y i , b | ≥ ν 8 (1 − δ) 3/2 p 1/2 m 1/2\\nProof. Set R min = ν/2 and R max = ν. Now set\\np = P a∼N (0,ν 2 ) (|a| ∈ [R min , R max ]) = 2P z∼N (0,1) z ∈ R min ν , R max ν = 2P z∼N (0,1) (z ∈ [1/2, 1]) ≈ 0.3. Now define τ = { ∈ [m] : |a | ∈ [R min , R max ]}.\\nWe have by the Chernoff bound for binomial random variables\\nP (|τ | ≤ (1 − δ)mp) ≤ exp −δ 2 mp 2 .\\nThus if m ≥ log 1 2 pδ 2 (a weaker condition than the hypothesis on m) then we have that |τ | ≥ (1 − δ)mp with probability at least 1 − . From now on assume such a τ has been observed and view it as fixed so that the only remaining randomness is over the w 's. Now set T = min i∈ [n] ∈τ I [ x i , w ≥ 0]. By the Chernoff bound again we get that for fixed i ∈ [n]\\nP ∈τ I [ x i , w ≥ 0] ≤ (1 − δ) 2 |τ | ≤ exp −δ 2 |τ | 4 .\\nThus by taking the union bound over i ∈ [n] we get\\nP T ≤ (1 − δ) 2 |τ | ≤ n exp −δ 2 |τ | 4 ≤ n exp −δ 2 (1 − δ)mp 4\\nThus if we consider τ as fixed and m ≥ 4 log(n/ ) δ 2 (1−δ)p then with probability at least 1 − over the sampling of the w 's we have that\\nT ≥ (1 − δ) 2 |τ |\\nIn this case by lemma C.4 we have that\\nα := sup b =1 min i∈[n] | Y i , b | ≥ R 2 min R max T |τ | 1/2 ≥ ν 8 (1 − δ) 3/2 m 1/2 p 1/2 .\\nThus the above holds with probability at least (1 − ) 2 .\\n\\nThis lemma now allows us to bound the effective rank of K inner in the case of Gaussian initialization. Theorem C.7. Assume φ(x) = ReLU (x). Suppose that a ∼ N (0, ν 2 ) for each ∈ [m] i.i.d. Furthermore suppose w 1 , . . . , w m are random vectors independent of each other and a such that w / w has the uniform distribution on the sphere for each ∈ [m]. Set p = P z∼N (0,1) (|z| ∈ [1/2, 1]) ≈ 0.3. Let , δ ∈ (0, 1). Then there exists absolute constants c, K > 0 such that if m ≥ 4 log(n/ ) δ 2 (1 − δ)p then with probability at least 1 − 3 we have that\\n1 C T r(XX T ) λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner ) ≤ C T r(XX T ) λ 1 (XX T ) where C = 64 (1 − δ) 3 p 1 + max{c −1 K log(1/ ), mK} m .\\nProof. By Bernstein's inequality\\nP a/ν 2 2 − m ≥ t ≤ exp −c · min t 2 mK 2 , t K\\nwhere c is an absolute constant. Set t = max{c −1 K log(1/ ), mK} so that the right hand side of the above inequality is bounded by . Thus by Lemma C.6 and the union bound we can ensure that with probability at least\\n1 − − [1 − (1 − ) 2 ] = 1 − 3 + 2 ≥ 1 − 3\\nthat a/ν 2 2 ≤ m + t and the conclusion of Lemma C.6 hold simultaneously. In that case a 2 2\\nα 2 ≤ ν 2 [m + t] ν 2 64 (1 − δ) 3 mp = 64 (1 − δ) 3 p 1 + t m = C.\\nThus by Corollary C.2 we get the desired result.\\n\\nBy fixing δ > 0 in the previous theorem we get the immediate corollary Corollary C.8. Assume φ(x) = ReLU (x). Suppose that a ∼ N (0, ν 2 ) for each ∈ [m] i.i.d. Furthermore suppose w 1 , . . . , w m are random vectors independent of each other and a such that w / w has the uniform distribution on the sphere for each ∈ [m]. Then there exists an absolute constant C > 0 such that m = Ω(log(n/ )) ensures that with probability at least 1 − 1 C\\nT r(XX T ) λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner ) ≤ C T r(XX T ) λ 1 (XX T )\\n\\nC.2.4 Effective rank of outer-layer NTK\\n\\nThroughout this section φ(x) = ReLU (x). Our goal of this section, similar to before, is to bound the effective rank of K outer by the effective rank of the input data gram XX T . In this section we will use often make use of the basic identities\\nAB F ≤ A 2 B F AB F ≤ A F B 2 T r(AA T ) = T r(A T A) = A 2 F A 2 = A T 2 λ 1 (A T A) = λ 1 (AA T ) = A 2 2 .\\nTo begin bounding the effective rank of K outer , we prove the following lemma. Lemma C.9. Assume φ(x) = ReLU (x) and W is full rank with m ≥ d. Then\\nφ(WX T ) 2 F [ φ(WX T ) 2 + φ(−WX T ) 2 ] 2 ≤ W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T ) Proof. First note that φ(WX T ) 2 F ≤ WX T 2 F ≤ W 2 2 X T 2 F = W 2 2 T r(XX T )\\n. Pick b ∈ R d such that b 2 = 1 and Xb 2 = X 2 . Since W T is full rank we may set u = (W T ) † b so that W T u = b where u 2 ≤ σ min (W T ) −1 where σ min (W T ) is the smallest nonzero singular value of W T . Well then\\nX 2 = Xb 2 = XW T u 2 ≤ XW T 2 u 2 ≤ XW T 2 σ min (W T ) −1 = WX T 2 σ min (W) −1 Now using the fact that x = φ(x) − φ(−x) we have that WX T 2 = φ(WX T ) − φ(−WX T ) 2 ≤ φ(WX T ) 2 + φ(−WX T ) 2\\nThus combined with our previous results gives\\nX 2 ≤ σ min (W) −1 φ(WX T ) 2 + φ(−WX T ) 2 Therefore φ(WX T ) 2 F σ min (W) −2 [ φ(WX T ) 2 + φ(−WX T ) 2 ] 2 ≤ φ(WX T ) 2 F X 2 2 ≤ W 2 2 T r(XX T ) X 2 2 = W 2 2 T r(XX T ) λ 1 (XX T )\\nwhich gives us the desired result.\\n\\nCorollary C.10. Assume φ(x) = ReLU (x) and W is full rank with m ≥ d. Then\\nmax φ(WX T ) 2 F , φ(−WX T ) 2 F max φ(WX T ) 2 2 , φ(−WX T ) 2 2 ≤ 4 W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T ) .\\nProof. Using the fact that\\nφ(WX T ) 2 + φ(−WX T ) 2 ≤ 2 max φ(WX T ) 2 , φ(−WX T ) 2\\nand lemma C.9 we have that\\nφ(WX T ) 2 F 4 max φ(WX T ) 2 2 , φ(−WX T ) 2 2 ≤ W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T )\\nNote that the right hand side and the denominator of the left hand side do not change when you replace W with −W. Therefore by using the above bound for both W and −W as the weight matrix separately we can conclude\\nmax φ(WX T ) 2 F , φ(−WX T ) 2 F 4 max φ(WX T ) 2 2 , φ(−WX T ) 2 2 ≤ W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T ) .\\nCorollary C.11. Assume φ(x) = ReLU (x) and m ≥ d. Suppose W and −W have the same distribution. Then conditioned on W being full rank we have that with probability at least 1/2\\nT r(K outer ) λ 1 (K outer ) ≤ 4 W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T ) .\\nProof. Fix W where W is full rank. We have by corollary C.10 that either\\nφ(WX T ) 2 F φ(WX T ) 2 2 ≤ 4 W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T ) . holds or φ(−WX T ) 2 F φ(−WX T ) 2 2 ≤ 4 W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T )\\n(the first holds in the case where φ(WX T ) 2 2 ≥ φ(−WX T ) 2 2 and the second in the case φ(WX T ) 2 2 < φ(−WX T ) 2 2 ). Since W and −W have the same distribution, it follows that the first inequality must hold at least 1/2 of the time. From\\nT r(K outer ) λ 1 (K outer ) = J T outer 2 F J T outer 2 2 = φ(WX T ) 2 F φ(WX T ) 2 2\\nwe get the desired result.\\n\\nWe now note that when W is rectangular shaped and the entries of W are i.i.d. Gaussians that W is full rank with high probability and σ min (W) −2 W 2 2 is well behaved. We recall the result from Vershynin (2012) Theorem C.12. Let A be a N × n matrix whose entries are independent standard normal random variables. Then for every t ≥ 0, with probability at least 1 − 2 exp(−t 2 /2) one has\\n√ N − √ n − t ≤ σ min (A) ≤ σ 1 (A) ≤ √ N + √ n + t\\nCorollary C.11 gives us a bound that works at least half the time. However, we would like to derive a bound that holds with high probability. We will have that when m n we have sufficient concentration of the largest singular value of φ(WX T ) to prove such a bound. We recall the result from Vershynin (2012) (Remark 5.40) Theorem C.13. Assume that A is an N × n matrix whose rows A i are independent sub-gaussian random vectors in R n with second moment matrix Σ. Then for every t ≥ 0, the following inequality holds with probability at least\\n1 − 2 exp(−ct 2 ) 1 N A * A − Σ 2 ≤ max(δ, δ 2 ) where δ = C n N + t √ N where C = C K , c = c K > 0 depend only on K := max i A i ψ2 .\\nWe will use theorem C.13 in the following lemma. Lemma C.14. Assume φ(x) = ReLU (x). Let A = φ(WX T ) and M = max i∈ [n] x i 2 . Suppose that w 1 , . . . , w m ∼ N (0, ν 2 I d ) i.i.d. Set K = M ν √ n and define\\nΣ := E w∼N (0,ν 2 I) [φ(Xw)φ(w T X T )]\\nThen for every t ≥ 0 the following inequality holds with probability at least 1 − 2 exp(−c K t 2 )\\n1 m A T A − Σ 2 ≤ max(δ, δ 2 ) where δ = C K n m + t √ m ,\\nwhere c K , C K > 0 are absolute constants that depend only on K.\\n\\nProof. We will let A : denote the th row of A (considered as a column vector). Note that\\nA : = φ(Xw ).\\nWe immediately get that the rows of A are i.i.d. We will now bound A : ψ2 . Let b ∈ R n such that b 2 = 1. Then\\nφ(Xw ), b ψ2 = n i=1 φ( x i , w )b i ψ2 ≤ n i=1 |b i | φ( x i , w ) ψ2 ≤ n i=1 |b i | x i , w ψ2 ≤ n i=1 |b i |C x i 2 ν ≤ CM ν b 1 ≤ CM ν √ n\\nwhere C > 0 is an absolute constant. Set K := M ν √ n. Well then by theorem C.13 we have the following. For every t ≥ 0 the following inequality holds with probability at least 1 − 2 exp(−c K t 2 )\\n1 m A T A − Σ 2 ≤ max(δ, δ 2 ) where δ = C K n m + t √ m\\nWe are now ready to prove a high probability bound for the effective rank of K outer .\\nTheorem C.15. Assume φ(x) = ReLU (x) and m ≥ d. Let M = max i∈[n] x i 2 . Suppose that w 1 , . . . , w m ∼ N (0, ν 2 I d ) i.i.d. Set K = M ν √ n Σ := E w∼N (0,ν 2 I) [φ(Xw)φ(w T X T )] δ = C K n m + log(2/ ) m where > 0 is small. Now assume √ m > √ d + 2 log(2/ ) and max(δ, δ 2 ) ≤ 1 2 λ 1 (Σ)\\nThen with probability at least 1 − 3\\nT r(K outer ) λ 1 (K outer ) ≤ 12 √ m + √ d + t 1 √ m − √ d − t 1 2 T r(X T X) λ 1 (X T X)\\nProof. By theorem C.12 with t 1 = 2 log(2/ ) we have that with probability at least 1 − that\\n√ m − √ d − t 1 ≤ σ min (W/ν) ≤ σ 1 (W/ν) ≤ √ m + √ d + t 1(51)\\nThe above inequalities and the hypothesis on m imply that W is full rank.\\nLet A = φ(WX T ) andÃ = φ(−WX T ). Set t 2 = log(2/ ) c K\\nwhere c K is defined as in theorem C.14. Note that A andÃ are identical in distribution. Thus by theorem C.14 and the union bound we get that with probability at least\\n1 − 2 1 m A T A − Σ 2 , 1 mÃ TÃ − Σ 2 ≤ max(δ, δ 2 ) =: ρ (52) where δ = C K n m + t 2 √ m .\\nBy our previous results and the union bound we can ensure with probability at least 1 − 3 that the bounds (51) and (52) all hold simultaneously. In this case we have\\n1 mÃ TÃ 2 ≤ 1 m A T A 2 + 2ρ = 1 m A T A 2 1 + 2ρ 1 m A T A 2 ≤ 1 m A T A 2 1 + 2ρ λ 1 (Σ) − ρ\\nAssuming ρ ≤ λ 1 (Σ)/2 we have by the above bound\\n1 mÃ TÃ 2 ≤ 3 1 m A T A 2 .\\n\\nNow note that\\nA T A 2 = φ(WX T ) 2 2 Ã TÃ 2 = φ(−WX T ) 2 2\\nso that our previous bound implies\\nφ(−WX T ) 2 2 ≤ 3 φ(WX T ) 2 2\\nthen we have by corollary C.10 that\\nT r(K outer ) λ 1 (K outer ) = φ(WX T ) 2 F φ(WX T ) 2 2 ≤ 12 W 2 2 σ min (W) 2 T r(XX T ) λ 1 (XX T ) ≤ 12 √ m + √ d + t 1 √ m − √ d − t 1 2 T r(XX T ) λ 1 (XX T ) .\\nFrom the above theorem we get the following corollary.\\nCorollary C.16. Assume φ(x) = ReLU (x) and n ≥ d. Suppose that w 1 , . . . , w m ∼ N (0, ν 2 I d ) i.i.d. Fix > 0 small. Set M = max i∈[n] x i 2 .\\nThen m = Ω max(λ 1 (Σ) −2 , 1) max(n, log(1/ )) and\\nν = O(1/M √ m)\\nsuffices to ensure that with probability at least 1 −\\nT r(K outer ) λ 1 (K outer ) ≤ C T r(XX T ) λ 1 (XX T )\\nwhere C > 0 is an absolute constant.\\n\\n\\nC.2.5 Bound for the combined NTK\\n\\nBased on the results in the previous two sections, we can now bound the effective rank of the combined NTK gram matrix K = K inner + K outer . Theorem 4.5. Assume φ(x) = ReLU (x) and n ≥ d. Fix > 0 small. Suppose that w 1 , . . . , w m ∼ N (0, ν 2 1 I d ) i.i.d. and a 1 , . . . , a m ∼ N (0, ν 2 2 ). Set M = max i∈ [n] x i 2 , and let\\nΣ := E w∼N (0,ν 2 1 I) [φ(Xw)φ(w T X T )]. Then m = Ω max(λ 1 (Σ) −2 , 1) max(n, log(1/ )) , ν 1 = O(1/M √ m)\\nsuffices to ensure that, with probability at least 1 − over the sampling of the parameter initialization,\\neff(K) ≤ C · eff(XX T ),\\nwhere C > 0 is an absolute constant.\\n\\nProof. This follows from the union bound and Corollaries C.8 and C.16.\\n\\n\\nC.2.6 Magnitude of the spectrum\\n\\nBy our results in sections C.2.3 and C.2.4 we have that m n suffices to ensure that\\nT r(K) λ 1 (K) T r(XX T ) λ 1 (XX T ) ≤ d Well note that i λ i (K) λ 1 (K) ≤ T r(K) λ 1 (K) d If i d then λ i (K)/λ 1 (K) is small.\\nThus the NTK only has O(d) large eigenvalues. The smallest eigenvalue λ n (K) of the NTK has been of interest in proving convergence guarantees (Du et al., 2019a,b;Oymak & Soltanolkotabi, 2020). By our previous inequality λ n (K)\\nλ 1 (K) d n\\nThus in the setting where m n d we have that the smallest eigenvalue will be driven to zero relative to the largest eigenvalue. Alternatively we can view the above inequality as a lower bound on the condition number\\nλ 1 (K) λ n (K) n d\\nWe will first bound the analytical NTK in the setting when the outer layer weights have fixed constant magnitude. This Theorem C.17. Let φ(x) = ReLU (x) and assume X = 0. Let K ∞ inner ∈ R n×n be the analytical NTK, i.e.\\n(K ∞ inner ) i,j := x i , x j E w∼N (0,I d ) [φ ( x i , w )φ ( x j , w )] . Then 1 4 T r(XX T ) λ 1 (XX T ) ≤ T r(K ∞ inner ) λ 1 (K ∞ inner ) ≤ 4 T r(XX T ) λ 1 (XX T ) .\\nProof. We consider the setting where |a | = 1/ √ m for all ∈ [m] and w ∼ N (0, I d ) i.i.d.. As was shown by Jacot et al. (2018), Du et al. (2019b in this setting we have that if we fix the training data X and send m → ∞ we have that\\nK inner − K ∞\\ninner 2 → 0 in probability. Therefore by continuity of the effective rank we have that\\nT r(K inner ) λ 1 (K inner ) → T r(K ∞ inner ) λ 1 (K ∞ inner )\\nin probability. Let η > 0. Then there exists an M ∈ N such that m ≥ M implies that\\nT r(K inner ) λ 1 (K inner ) − T r(K ∞ inner ) λ 1 (K ∞ inner ) ≤ η(53)\\nwith probability greater than 1/2. Now fix δ ∈ (0, 1). On the other hand by Theorem C.5 with = 1/4 we have that if m ≥ 4 δ 2 log(4n) then with probability at least 3/4 that\\n(1 − δ) 2 4 T r(XX T ) λ 1 (XX T ) ≤ T r(K inner ) λ 1 (K inner ) ≤ 4 (1 − δ) 2 T r(XX T ) λ 1 (XX T ) .(54)\\nThus if we set m = max( 4 δ 2 log(4n), M ) we have with probability at least 3/4 − 1/2 = 1/4 that (53) and (54) hold simultaneously. In this case we have that\\n(1 − δ) 2 4 T r(XX T ) λ 1 (XX T ) − η ≤ T r(K ∞ inner ) λ 1 (K ∞ inner ) ≤ 4 (1 − δ) 2 T r(XX T ) λ 1 (XX T ) + η\\nNote that the above argument runs through for any η > 0 and δ ∈ (0, 1). Thus we may send η → 0 + and δ → 0 + in the above inequality to get 1 4\\nT r(XX T ) λ 1 (XX T ) ≤ T r(K ∞ inner ) λ 1 (K ∞ inner ) ≤ 4 T r(XX T ) λ 1 (XX T )\\nWe thus have the following corollary about the conditioning of the analytical NTK. Corollary C.18. Let φ(x) = ReLU (x) and assume X = 0. Let K ∞ inner ∈ R n×n be the analytical NTK, i.e.\\n(K ∞ inner ) i,j := x i , x j E w∼N (0,I d ) [φ ( x i , w )φ ( x j , w )] . Then λ n (K ∞ inner ) λ 1 (K ∞ inner )\\n≤ 4 d n .\\n\\n\\nC.3 Experimental validation of results on the NTK spectrum\\n\\nWe experimentally test the theory developed in Section 4.1 and its implications by analyzing the spectrum of the NTK for both fully connected neural network architectures (FCNNs), the results of which are displayed in Figure 1, and also convolutional neural network architectures (CNNs), shown in Figure 3. For the feedforward architectures we consider networks of depth 2 and 5 with the width of all layers being set at 500. With regard to the activation function we test linear, ReLU and Tanh, and in terms of initialization we use Kaiming uniform (He et al., 2015), which is very common in practice and is the default in PyTorch (Paszke et al., 2019). For the convolutional architectures we again consider depths 2 and 5, with each layer consisting of 100 channels with the filter size set to 5x5. In terms of data, we consider 40x40 patches from both real world images, generated by applying Pytorch's RandomResizedCrop transform to a random batch of Caltech101 images (Li et al., 2022), as well as synthetic images corresponding to isotropic Gaussian vectors. The batch sized is fixed at 200 and we plot only the first 100 normalized eigenvalues. Each experiment was repeated 10 times. Finally, to compute the NTK we use the functorch 4 module in PyTorch using an algorithmic approach inspired by Novak et al. (2022).\\n\\nThe results for convolutional neural networks show the same trends as observed in feedforward neural networks, which we discussed in Section 4.1. In particular, we again observe the dominant outlier eigenvalue, which increases with both depth and the size of the Gaussian mean of the activation. We also again see that the NTK spectrum inherits its structure from the data, i.e., is skewed for skewed data or relatively flat for isotropic Gaussian data. Finally, we also see that the spectrum for Tanh is closer to the spectrum for the linear activation when compared with the ReLU spectrum.\\n\\nIn terms of differences between the CNN and FCNN experiments, we observe that the spread of the 95% confidence interval is slightly larger for convolutional nets, implying a slightly larger variance between trials. We remark that this is likely attributable to the fact that there are only 100 channels in each layer and by increasing this quantity we would expect the variance to reduce. In summary, despite the fact that our analysis is concerned with FCNNs, it appears that the broad implications and trends also hold for CNNs. We leave a thorough study of the NTK spectrum for CNNs and other network architectures to future work. Figure 3: (NTK Spectrum for CNNs) We plot the normalized eigenvalues λ p /λ 1 of the NTK Gram matrix K and the data Gram matrix XX T for Caltech101 and isotropic Gaussian datasets. To compute the NTK, we randomly initialize convolutional neural networks of depth 2 and 5 with 100 channels per layer. We use the standard parameterization and Pytorch's default Kaiming uniform initialization in order to better connect our results with what is used in practice. We consider a batch size of n = 200 and plot the first 100 eigenvalues. The thick part of each curve corresponds to the mean across 10 trials while the transparent part corresponds to the 95% confidence interval. To test our theory in Section 4.2, we numerically plot the spectrum of NTK of two-layer feedforward networks with ReLU, Tanh, and Gaussian activations in Figure 4. The input data are uniformly drawn from S 2 . Notice that when d = 2, k = Θ( 1/2 ). Then Corollary 4.7 shows that for the ReLU activation λ = Θ( −3/2 ), for the Tanh activation λ = O −3/4 exp(− π 2 1/4 ) , and for the Gaussian activation λ = O( −1/2 2 − 1/2 ). These theoretical decay rates for the NTK spectrum are verified by the experimental results in Figure 4.\\n\\nC.4 Analysis of the lower spectrum: uniform data Theorem 4.6. [Azevedo & Menegatto (2015)] Let Γ denote the gamma function. Suppose that the training data are uniformly sampled from the unit hypersphere S d , d ≥ 2. If the dot-product kernel function has the expansion K(x 1 , x 2 ) = ∞ p=0 c p x 1 , x 2 p where c p ≥ 0, then the eigenvalue of every spherical harmonic of frequency k is given by\\nλ k = π d/2 2 k−1 p≥k p−k is even c p Γ(p + 1)Γ( p−k+1 2 ) Γ(p − k + 1)Γ( p−k+1 2 + k + d/2) .\\nProof. Let θ(t) = ∞ p=0 c p t p , then K(x 1 , x 2 ) = θ( x 1 , x 2 ) According to Funk Hecke theorem (Basri et al., 2019, Section 4.2), we have\\nλ k = Vol(S d−1 ) 1 −1 θ(t)P k,d (t)(1 − t 2 ) d−2 2 dt,(55)\\nwhere Vol(S d−1 ) = 2π d/2 Γ(d/2) is the volume of the hypersphere S d−1 , and P k,d (t) is the Gegenbauer polynomial, given by\\nP k,d (t) = (−1) k 2 k Γ(d/2) Γ(k + d/2) 1 (1 − t 2 ) (d−2)/2 d k dt k (1 − t 2 ) k+(d−2)/2 ,\\nand Γ is the gamma function.\\n\\nFrom (55) we have\\nλ k = Vol(S d−1 ) 1 −1 θ(t)P k,d (t)(1 − t 2 ) d−2 2 dt = 2π d/2 Γ(d/2) 1 −1 θ(t) (−1) k 2 k Γ(d/2) Γ(k + d/2) d k dt k (1 − t 2 ) k+(d−2)/2 dt = 2π d/2 Γ(d/2) (−1) k 2 k Γ(d/2) Γ(k + d/2) ∞ p=0 c p 1 −1 t p d k dt k (1 − t 2 ) k+(d−2)/2 dt.(56)\\nUsing integration by parts, we have\\n1 −1 t p d k dt k (1 − t 2 ) k+(d−2)/2 dt = t p d k−1 dt k−1 (1 − t 2 ) k+(d−2)/2 1 −1 − p 1 −1 t p−1 d k−1 dt k−1 (1 − t 2 ) k+(d−2)/2 dt = −p 1 −1 t p−1 d k−1 dt k−1 (1 − t 2 ) k+(d−2)/2 dt,(57)\\nwhere the last line in (57) holds because d k−1 dt k−1 (1 − t 2 ) k+(d−2)/2 = 0 when t = 1 or t = −1. When p < k, repeat the above procedure (57) p times, we get\\n1 −1 t p d k dt k (1 − t 2 ) k+(d−2)/2 dt = (−1) p p! 1 −1 d k−p dt k−p (1 − t 2 ) k+(d−2)/2 dt = (−1) p p! d k−p−1 dt k−p−1 (1 − t 2 ) k+(d−2)/2 1 −1 = 0.(58)\\nWhen p ≥ k, repeat the above procedure (57) k times, we get\\n1 −1 t p d k dt k (1 − t 2 ) k+(d−2)/2 dt = (−1) k p(p − 1) · · · (p − k + 1) 1 −1 t p−k (1 − t 2 ) k+(d−2)/2 dt.(59)\\nWhen p − k is odd, t p−k (1 − t 2 ) k+(d−2)/2 is an odd function, then\\n1 −1 t p−k (1 − t 2 ) k+(d−2)/2 dt = 0.(60)\\nWhen p − k is even,\\n1 −1 t p−k (1 − t 2 ) k+(d−2)/2 dt = 2 1 0 t p−k (1 − t 2 ) k+(d−2)/2 dt = 1 0 (t 2 ) (p−k−1)/2 (1 − t 2 ) k+(d−2)/2 dt 2 = B p − k + 1 2 , k + d/2 = Γ( p−k+1 2 )Γ(k + d/2) Γ( p−k+1 2 + k + d/2) ,(61)\\nwhere B is the beta function.\\n\\nPlugging (61) , (58) and (60) into (59), we get\\n1 −1 t p d k dt k (1 − t 2 ) k+(d−2)/2 dt = (−1) k p(p − 1) . . . (p − k + 1) Γ( p−k+1 2 )Γ(k+d/2) Γ( p−k+1 2 +k+d/2) , p − k is even and p ≥ k, 0, otherwise.(62)\\nPlugging (62) into (56), we get\\nλ k = 2π d/2 Γ(d/2) (−1) k 2 k Γ(d/2) Γ(k + d/2) p≥k p−k is even c p (−1) k p(p − 1) . . . (p − k + 1) Γ( p−k+1 2 )Γ(k + d/2) Γ( p−k+1 2 + k + d/2) = π d/2 2 k−1 p≥k p−k is even c p p(p − 1) . . . (p − k + 1)Γ( p−k+1 2 ) Γ( p−k+1 2 + k + d/2) = π d/2 2 k−1 p≥k p−k is even c p Γ(p + 1)Γ( p−k+1 2 ) Γ(p − k + 1)Γ( p−k+1 2 + k + d/2) .\\nwhen k is sufficiently large.\\n1 p≥k p−k is even f a (p) ≤ O \\uf8eb \\uf8ec \\uf8ec \\uf8ec \\uf8ed k≤p≤ k 2 d+24a p−k is even f a (p) + p≥ k 2 d+24a p−k is even f a (p) \\uf8f6 \\uf8f7 \\uf8f7 \\uf8f7 \\uf8f8 ≤ O \\uf8eb \\uf8ec \\uf8ec \\uf8ec \\uf8ed k 2 d + 24a − k + 1 f a k 2 d + 24a + p≥ k 2 d+24a p−k is even e 48a(d+24a) 2d p −a− d 2 \\uf8f6 \\uf8f7 \\uf8f7 \\uf8f7 \\uf8f8 ≤ O k 2 d + 24a − k + 1 e 48a(d+24a) 2d k 2 d + 24a −a− d 2 + e 48a(d+24a) 2d 1 a + d 2 − 1 k 2 d + 24a − 1 1−a− d 2 = O(k −d−2a+2 ).\\nNext we prove λ k = Ω(k −d−2a+2 ). Since c p are nonnegative and c p = Θ(p −a ), we have that c p ≥ C p −a for some constant C . Then we have\\nλ k ≥ π d/2 2 k−1 p≥k p−k is even C p −a Γ(p + 1)Γ( p−k+1 2 ) Γ(p − k + 1)Γ( p−k+1 2 + k + d/2) .(71)\\nAccording to Stirling's formula (63) and (64), using the similar argument as (65) we have\\nλ k ≥ π d/2 2 k−1 C 2 1 C 2 2 p≥k p−k is even C p −a 2π p+1 p+1 e p+1 2π p−k+1 2 p−k+1 2 e p−k+1 2 2π p−k+1 p−k+1 e p−k+1 2π p−k+1 2 +k+d/2 p−k+1 2 +k+d/2 e p−k+1 2 +k+d/2 (72) = 2π d/2 2 d 2 e d 2 C 2 1 C C 2 2 p≥k p−k is even p −a (p + 1) p+ 1 2 (p − k + 1) p−k+1 2 (p + k + 1 + d) p+k+d 2 (73) ≥ 2π d/2 2 d 2 e d 2 C 2 1 C C 2 2 p≥k 2 p−k is even f a (p),(74)\\nwhere f a (p) is defined in (66). When p ≥ k 2 , we have f a (p) = p −a (p + 1)\\np+ 1 2 (p − k + 1) p−k+1 2 (p + k + 1 + d) p+k+d 2 = p −a (p + 1) p+ 1 2 ((p + 1) 2 − k 2 + d(p − k + 1)) p−k+1 2 (p + k + 1 + d) 2k+d−1 2 ≥ (p + 1) −a− d 2 1 − k 2 −d(p−k+1) (p+1) 2 p−k+1 2 1 + k+d p+1 2k+d−1 2\\nFor sufficiently large k, k 2 − d(p − k + 1) < 0. Then for p ≥ k 2 , we have f a (p) ≥ e − d 2 − 3 2 (p + 1) −a− d 2 .\\n\\nFor the NTK of a two-layer ReLU network with γ b > 0, then according to Lemma 3.2 we have c p = κ p,2 = Θ(p −3/2 ) . Therefore using Corollary 4.7 λ k = Θ(k −d−1 ). Notice here that k refers to the frequency, and the number of spherical harmonics of frequency at most k is Θ(k d ). Therefore, for the th largest eigenvalue λ we have λ = Θ( −(d+1)/d ). This rate agrees with Basri et al. (2019) and Velikanov & Yarotsky (2021). For the NTK of a two-layer ReLU network with γ b = 0, the eigenvalues corresponding to the even frequencies are 0, which also agrees with Basri et al. (2019).\\n\\nCorollary 4.7 also shows the decay rates of eigenvalues for the NTK of two-layer networks with Tanh activation and Gaussian activation. We observe that when the coefficients of the kernel power series decay quickly then the eigenvalues of the kernel also decay quickly. As a faster decay of the eigenvalues of the kernel implies a smaller RKHS, Corollary 4.7 demonstrates that using ReLU results in a larger RKHS relative to using either Tanh or Gaussian activations. We numerically illustrate Corollary 4.7 in Figure 4, Appendix C.3.\\n\\nC.5 Analysis of the lower spectrum: non-uniform data\\n\\nThe purpose of this section is to prove a formal version of Theorem 4.8. In order to prove this result we first need the following lemma. Lemma C.20. Let the coefficients (c j ) ∞ j=0 with c j ∈ R ≥0 for all j ∈ Z ≥0 be such that the series ∞ j=0 c j ρ j converges for all ρ ∈ [−1, 1]. Given a data matrix X ∈ R n×d with x i = 1 for all i ∈ [n], define r := rank(X) ≥ 2 and the gram matrix G := XX T . Consider the kernel matrix\\nnK = ∞ j=0 c j G j .\\nFor arbitrary m ∈ Z ≥1 , let the eigenvalue index k satisfy n ≥ k > rank (H m ), where H m := m−1 j=0 c j G j . Then\\nλ k (K) ≤ G m n ∞ j=m c j .(99)\\nProof. We start our analysis by considering λ k (nK) for some arbitrary k ∈ N ≤n . Let Recall that a constant matrix is symmetric and positive semi-definite, furthermore, by the Schur product theorem, the Hadamard product of two positive semi-definite matrices is positive semi-definite. As a result, G j is symmetric and positive semi-definite for all j ∈ Z ≥0 and therefore H m and T m are also symmetric positive semi-definite matrices. From Weyl's inequality (Weyl, 1912, Satz 1) it follows that\\nnλ k (K) ≤ λ k (H m ) + λ 1 (T m ).(100)\\nIn order to upper bound λ 1 (T m ), observe, as T m is square, symmetric and positive semi-definite, that λ 1 (T m ) = T m . Using the non-negativity of the coefficients (c j ) ∞ j=0 and the triangle inequality we have\\nλ 1 (T m ) = ∞ j=m c j G j ≤ ∞ j=m c j G j\\nBy the assumptions of the lemma [G] ii = 1 and therefore [G] j ii = 1 for all j ∈ Z ≥0 . Furthermore, for any pair of positive semi-definite matrices A, B ∈ R n×n and k ∈ [n] λ 1 (A B) ≤ max i∈ [n] [A] ii λ 1 (B),\\n\\nSchur (1911). Therefore, as max i∈ [n] [G] ii = 1, G j = λ 1 (G j ) = λ 1 (G G (j−1) ) ≤ λ 1 (G (j−1) ) = G (j−1) for all j ∈ N. As a result\\nλ 1 (T m ) ≤ G m ∞ j=m c j .\\nFinally, we now turn our attention to the analysis of λ k (H m ). Upper bounding a small eigenvalue is typically challenging, however, the problem simplifies when and k exceeds the rank of H m , as is assumed here, as this trivially implies λ k (H m ) = 0. Therefore, for k > rank(H m )\\nλ k (K) ≤ G m n ∞ j=m c j\\nas claimed.\\n\\nIn order to use Lemma C.20 we require an upper bound on the rank of H m . To this end we provide Lemma C.21.\\n\\nLemma C.21. Let G ∈ R n×n be a symmetric, positive semi-definite matrix of rank 2 ≤ r ≤ d. Define H m ∈ R n×n as\\nH m = m−1 j=0 c j G j(102)\\nwhere (c j ) m−1 j=0 is a sequence of real coefficients. Then\\nrank (H m ) ≤1 + min{r − 1, m − 1}(2e) r−1 + max{0, m − r} 2e r − 1 r−1 (m − 1) r−1 .(103)\\nProof. As G is a symmetric and positive semi-definite matrix, its eigenvalues are real and non-negative and its eigenvectors are orthogonal. Let {v i } r i=1 be a set of orthogonal eigenvectors for G and γ i the eigenvalue associated with v i ∈ R n . Then G may be written as a sum of rank one matrices as follows,\\nG = r i=1 γ i v i v T i .\\nAs the Hadamard product is commutative, associative and distributive over addition, for any j ∈ Z ≥0 G j can also be expressed as a sum of rank 1 matrices,\\nG j = r i=1 γ i v i v T i j = r i1=1 γ i1 v i1 v T i1 r i2=1 γ i2 v i2 v T i2 · · · \\uf8eb \\uf8ed r ij =1 γ ij v ij v T ij \\uf8f6 \\uf8f8 = r i1,i2...ij =1 γ i1 γ i2 · · · γ ir v i1 v T i1 v i2 v T i2 · · · v ij v T ij = r i1,i2,...,ij =1 γ i1 γ i2 · · · γ ij v i1 v i2 · · · v ij v i1 v i2 · · · v ij T .\\nNote the fourth equality in the above follows from v i v T i = v i ⊗ v i and an application of the mixed-product property of the Hadamard product. As matrix rank is sub-additive, the rank of G j is less than or equal to the number of distinct rank-one matrix summands. This quantity in turn is equal to the number of vectors of the form v i1 v i2 · · · v ij , where i 1 , i 2 , . . . , i j ∈ [r]. This in turn is equivalent to computing the number of jcombinations with repetition from r objects. Via a stars and bars argument this is equal to r+j−1 j = r+j−1 r(n)−1 .\\n\\nIt therefore follows that rank(G j ) ≤ r + j − 1 r − 1 ≤ e(r + j − 1) r − 1 r−1 ≤ e r−1 1 + j r − 1 r−1 ≤ (2e) r−1 δ j≤r−1 + δ j>r−1 j r − 1 r−1 .\\n\\nThe rank of H m can therefore be bounded via subadditivity of the rank as \\n\\nAs our goal here is to characterize the small eigenvalues, then as n grows we need both k and therefore m to grow as well. As a result we will therefore be operating in the regime where m > r. To this end we provide the following corollary. Corollary C.22. Under the same conditions and setup as Lemma C.21 with m ≥ r ≥ 7 then rank(H m ) < 2m r .\\n\\nProof. If r ≥ 7 > 2e + 1 then r − 1 > 2e. As a result from Lemma C.21 rank(H m ) ≤ 1 + (r − 1)(2e) r−1 + (m − r) 2e r − 1 r−1 (m − 1) r−1 < r(2e) r−1 + (m − 1) r < 2m r as claimed.\\n\\nCorollary C.22 implies for any k ≥ 2m r , k ≤ n that we can apply Lemma C.20 to upper bound the size of the kth eigenvalue. Our goal is to upper bound the decay of the smallest eigenvalue. To this end, and in order to make our bounds as tight as possible, we therefore choose the truncation point m(n) = (n/2) 1/r , note this is the largest truncation which still satisfies 2m(n) r ≤ n. In order to state the next lemma, we introduce the following pieces of notation: with L :\\n= { : R ≥0 → R ≥0 } define U : L × Z ≥1 → R ≥0 as U ( , m) = ∞ m−1 (x)dx.\\nLemma C.23. Given a sequence of data points (x i ) i∈Z ≥1 with x i ∈ S d for all i ∈ Z ≥1 , construct a sequence of row-wise data matrices (X n ) n∈Z ≥1 , X n ∈ R n×d , with x i corresponding to the ith row of X n . The corresponding sequence of gram matrices we denote G n := X n X T n . Let m(n) := (n/2) 1/r(n) where r(n) := rank(X n ) and suppose for all sufficiently large n that m(n) ≥ r(n) ≥ 7. Let the coefficients (c j ) ∞ j=0 with c j ∈ R ≥0 for all j ∈ Z ≥0 be such that 1) the series ∞ j=0 c j ρ j converges for all ρ ∈ [−1, 1] and 2) (c j ) ∞ j=0 = O( (j)), where ∈ L satisfies U ( , m(n)) < ∞ for all n and is monotonically decreasing. Consider the sequence of kernel matrices indexed by n and defined as nK n = ∞ j=0 c j G j n .\\n\\nWith ν : Z ≥1 → Z ≥1 suppose G m(n) n = O(n −ν(n)+1 ), then λ n (K n ) = O(n −ν(n) U ( , m(n))).\\n\\n(105)\\n\\nProof. By the assumptions of the Lemma we may apply Lemma C.20 and Corollary C.22, which results in\\nλ n (K n ) ≤ G m(n) n n ∞ j=m(n) c j = O(n −ν(n) ) ∞ j=m(n) c j .\\nAdditionally, as (c j ) ∞ j=0 = O( (j)) then\\nλ n (K n ) = O \\uf8eb \\uf8ed n −ν(n) ∞ j=m(n) (j) \\uf8f6 \\uf8f8 = O n −ν(n) ∞ m(n)−1 (x)dx = O n −ν(n) U ( , m(n))\\nas claimed.\\n\\nBased on Lemma C.20 we provide Theorem C.24, which considers three specific scenarios for the decay of the power series coefficients inspired by Lemma 3.2. Theorem C.24. In the same setting, and also under the same assumptions as in Lemma C.23, then 1. if c p = O(p −α ) with α > r(n) + 1 for all n ∈ Z ≥0 then λ n (K n ) = O n − α−1 r(n)\\n\\n, 2. if c p = O(e −α √ p ), then λ n (K n ) = O n 1 2r(n) exp −α n 1 2r(n) for any α < α2 −1/2r(n) , 3. if c p = O(e −αp ), then λ n (K n ) = O exp −α n 1 r(n) for any α < α2 −1/2r(n) .\\n\\nProof. First, as [G n ] ij ≤ 1 then G m(n) n ≤ Trace(G m(n) ) n = 1.\\n\\nTherefore, to recover the three results listed we now apply Lemma C.23 with ν(n) = 0. First, to prove 1., under the assumption (x) = x −α with α > 0 then As a result λ n (K n ) = O n 1 2r(n) exp −α n 1 2r(n) for any α < α2 −1/2r(n) . Finally, to prove iii), under the assumption (x) = e −αx with α > 0 then ∞ m(n)−1 e −αx dx = exp(−α(m(n) − 1) α .\\n\\nTherefore λ n (K n ) = O exp −α n 1 r(n) again for any α < α2 −1/2r(n) .\\n\\nUnfortunately, the curse of dimensionality is clearly present in these results due to the 1/r(n) factor in the exponents of n. However, although perhaps somewhat loose we emphasize that these results are certainly far from trivial. In particular, while trivially we know that λ n (K n ) ≤ T r(K n )/n = O(n −1 ), in contrast, even the weakest result concerning the power law decay our result is a clear improvement as long as α > r(n) + 1. For the other settings, i.e., those specified in 2. and 3., our results are significantly stronger.\\n\\n\\nMany works consider the model where the outer layer weights are fixed and have constant magnitude and only the inner layer weights are trained. This is the setting considered by Xie et al. (2017), Arora et al. (2019a), Du et al. (2019b), Oymak et al. (2019),\\n\\n\\net al. (2012). Some of the most popular initialization strategies used in practice today, in particular LeCun et al. (2012) and Glorot & Bengio\\n\\n\\nPoole et al. (2016); Schoenholz et al. (2017), R(1) = V (1) = 1, hence ρ = 1 is a fixed point of R. We remark that as all preactivations are distributed as N (0, 1), then a correlation of one between preactivations implies they are equal. The stability of the fixed point ρ = 1 is of particular significance in the context of initializing deep neural networks successfully. Under mild conditions on the activation function one can compute the derivative of R, see e.g., Poole et al. (2016); Schoenholz et al. (2017); Murray et al. (2022), as follows,\\n\\nF\\n(ji,l k ≥ 1 and p ≥ 0,\\n\\nFigure 2 :\\n2(NTK Approximation via Truncation) Absolute error between the analytical ReLU NTK and the truncated ReLU NTK power series as a function of the input correlation ρ for two different values of the truncation point T and three different values for the depth L of the network. Although the truncated NTK achieves a uniform approximation error of only 10 −1 on [−1, 1]\\n\\nC\\nAnalyzing the spectrum of the NTK via its power series C.1 Effective rank of power series kernels Recall that for a positive semidefinite matrix A we define the effective rank Huang et al. (2022) via the following ratio eff(A) := T r(A) λ 1 (A) .\\n\\n\\n(2019b), Arora et al. (2019a), Oymak et al. (2019), Li et al. (2020), Xie et al. (2017) and Oymak & Soltanolkotabi (2020) the outer layer weights all have fixed constant magnitude. Thus in that case we can set R min = R max in Lemma C.4 so that τ = [m]. In this setting we have the following result. Theorem C.5. Assume φ(x) = ReLU (x). Suppose |a | = R > 0 for all ∈ [m]. Furthermore suppose w 1 , . . . , w m are independent random vectors such that w / w has the uniform distribution on the sphere for each ∈ [m]. Also assume m ≥ 4 log(n/ ) δ 2\\n\\n\\nis the setting considered by Xie et al. (2017), Arora et al. (2019a), Du et al. (2019b), Oymak et al. (2019), Li et al. (2020), and Oymak & Soltanolkotabi (2020).\\n\\nFigure 4 :\\n4(Asymptotic NTK Spectrum) NTK spectrum of two-layer fully connected networks with ReLU, Tanh and Gaussian activations under the NTK parameterization. The orange curve is the experimental eigenvalue. The blue curves in the left shows the regression fit for the experimental eigenvalues as a function of eigenvalue index in the form of λ = a −b where a and b are unknown parameters determined by regression. The blue curves in the middle shows the regression fit for the experimental eigenvalues in the form of λ = a −0.75 b −l 1/4. The blue curves in the right shows the regression fit for the experimental eigenvalues in the form of λ = a −0.5 b −l 1/2 .\\n\\n\\nm-head and m-tail of the Hermite expansion of nK: clearly nK = H m + T m for any m ∈ N.\\n\\n.\\nTo prove ii), under the assumption (x) = e −α √ x with α > 0 then ∞ m(n)−1 e −α √ x dx = 2 exp(−α( m(n) − 1)(α m(n) − 1 + 1) α 2 .\\n\\nTable 1 :\\n1Percentage of ∞ p=0 κ p,2 accounted for by the first T + 1 NTK coefficients assuming\\n\\n\\nHowever, the asymptotic rate of decay of the NTK coefficients varies significantly by activation function, due to the varying behavior of their tails. In Lemma 3.2 we choose ReLU, Tanh and Gaussian as prototypical examples of activations functions with growing, constant, and decaying tails respectively, and analyze the corresponding NTK coefficients in the two layer setting. For typographical ease we denote the zero mean Gaussian density function withT = \\n0 \\n1 \\n2 \\n3 \\n4 \\n5 \\nReLU \\n43.944 \\n77.277 \\n93.192 \\n93.192 \\n95.403 \\n95.403 \\nTanh \\n41.362 \\n91.468 \\n91.468 \\n97.487 \\n97.487 \\n99.090 \\nSigmoid \\n91.557 \\n99.729 \\n99.729 \\n99.977 \\n99.977 \\n99.997 \\nGaussian \\n95.834 \\n95.834 \\n98.729 \\n98.729 \\n99.634 \\n99.634 \\n\\nvariance σ 2 as ω σ (z) := (1/ \\n\\n√ \\n2πσ 2 ) exp −z 2 /(2σ 2 ) . \\n\\nLemma 3.2. Under Assumptions 1 and 2, \\n\\n\\n\\n\\nGENERAL-EXPRESSION-FOR-HERMITE-EXPANSIONS-WITH-APPLICATIONS.pdf. Alexander G. de G. Matthews, Jiri Hron, Mark Rowland, Richard E. Turner, and Zoubin Ghahramani. Paper.pdf. G. B. Folland. Real analysis: Modern techniques and their applications. Wiley, New York, 1999. Amnon Geifman, Abhay Yadav, Yoni Kasten, Meirav Galun, David Jacobs, and Basri Ronen. On the similarity between the Laplace and neural tangent kernels. In Advances in Neural Information Processing Systems, volume 33, pp. 1451-1461. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/ file/1006ff12c465532f8c574aeaa4461b16-Paper.pdf. Amnon Geifman, Meirav Galun, David Jacobs, and Ronen Basri. On the spectral bias of convolutional neural tangent and gaussian process kernels. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id= gthKzdymDu2. Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, volume 9 of Proceedings of Machine Learning Research, pp. 249-256. PMLR, 2010. URL https://proceedings.mlr. press/v9/glorot10a.html. Insu Han, Amir Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, and Amin Karbasi. Fast neural kernel embeddings for general activations. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id= yLilJ1vZgMe. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In 2015 IEEE International Conference on Computer Vision (ICCV), pp. 1026-1034, 2015. Ningyuan Teresa Huang, David W. Hogg, and Soledad Villar. Dimensionality reduction, regularization, and generalization in overparameterized regressions. SIAM J. Math. Paper.pdf. Hui Jin, Pradeep Kr. Banerjee, and Guido Montúfar. Learning curves for gaussian process regression with powerlaw priors and targets. In International Conference on Learning Representations, 2022. URL https:// openreview.net/forum?id=KeI9E-gsoB. Ryo Karakida, Shotaro Akaho, and Shun ichi Amari. Universal statistics of Fisher information in deep neural networks: Samet Oymak and Mahdi Soltanolkotabi. Toward moderate overparameterization: Global convergence guarantees for training shallow neural networks. IEEE Journal on Selected Areas in Information Theory, 1(1), 2020. URL https://par.nsf.gov/biblio/10200049. Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi. Generalization guarantees for neural networks via harnessing the low-rank structure of the Jacobian. CoRR, abs/1906.05392, 2019. URL http://arxiv.org/ abs/1906.05392. Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, and Surya Ganguli. Exponential expressivity in deep neural networks through transient chaos. In Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/ 148510031349642de5ca0c544f31b2ef-Paper.pdf. J. Schur. Bemerkungen zur Theorie der beschränkten Bilinearformen mit unendlich vielen Veränderlichen. Journal für die reine und angewandte Mathematik, 140:1-28, 1911. URL http://eudml.org/doc/149352. James Benjamin Simon, Sajant Anand, and Mike Deweese. Reverse engineering the neural tangent kernel. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 20215-20231. PMLR, 17-23 Jul 2022. URL https://proceedings.mlr.press/v162/simon22a. html. Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices, pp. 210-268. Cambridge University Press, 2012. Bo Xie, Yingyu Liang, and Le Song. Diverse Neural Network Learns True Target Functions. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research, pp. 1216-1224. PMLR, 2017. URL https://proceedings.mlr.press/v54/xie17a.html. Yang and Hadi Salman. A fine-grained spectral perspective on neural networks, 2019. URL https://arxiv. org/abs/1907.10599. Difan Zou and Quanquan Gu.Tom Davis. \\nA general expression for Hermite expansions with applications. \\n2021. \\ndoi: \\n10.13140/RG.2.2.30843.44325. \\nURL \\nhttps://www.researchgate.net/ \\nprofile/Tom-Davis-2/publication/352374514_A_GENERAL_EXPRESSION_FOR_ \\nHERMITE_EXPANSIONS_WITH_APPLICATIONS/links/60c873c5a6fdcc8267cf74d4/ \\nA-Gaussian \\nprocess behaviour in wide deep neural networks. In International Conference on Learning Representations, 2018. \\nURL https://openreview.net/forum?id=H1-nGgWC-. \\nSimon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent finds global minima of deep neural \\nnetworks. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings \\nof Machine Learning Research, pp. 1675-1685. PMLR, 2019a. URL https://proceedings.mlr.press/ \\nv97/du19c.html. \\nSimon S. Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh. Gradient descent provably optimizes over-\\nparameterized neural networks. In International Conference on Learning Representations, 2019b. URL https: \\n//openreview.net/forum?id=S1eK3i09YQ. \\nAndrew Engel, Zhichao Wang, Anand Sarwate, Sutanay Choudhury, and Tony Chiang. TorchNTK: A library for \\ncalculation of neural tangent kernels of PyTorch models. 2022. \\nZhou Fan and Zhichao Wang. Spectra of the conjugate kernel and neural tangent kernel for linear-width \\nneural networks. \\nIn Advances in Neural Information Processing Systems, volume 33, pp. 7710-7721. \\nCurran Associates, Inc., 2020. \\nURL https://proceedings.neurips.cc/paper/2020/file/ \\n572201a4497b0b9f02d4f279b09ec30d-Data Sci., 4(1):126-152, 2022. URL https: \\n//doi.org/10.1137/20m1387821. \\nArthur Jacot, Franck Gabriel, and Clement Hongler. \\nNeural tangent kernel: Convergence and gen-\\neralization in neural networks. \\nIn Advances in Neural Information Processing Systems, volume 31. \\nCurran Associates, Inc., 2018. \\nURL https://proceedings.neurips.cc/paper/2018/file/ \\n5a4be1fa34e62bb8a6ec6b91d2462f5a-mean field approach. Journal of Statistical Mechanics: Theory and Experiment, 2020(12):124005, 2020. URL \\nhttps://doi.org/10.1088/1742-5468/abc62e. \\nSamet Abhishek Panigrahi, Abhishek Shetty, and Navin Goyal. Effect of activation functions on the training of over-\\nparametrized neural nets. In International Conference on Learning Representations, 2020. URL https: \\n//openreview.net/forum?id=rkgfdeBYvH. \\n\\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming \\nLin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin \\nRaison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: \\nAn imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems \\n32, pp. 8024-8035. Curran Associates, Inc., 2019. \\n\\nJeffrey Pennington and Pratik Worah. Nonlinear random matrix theory for deep learning. In Advances in Neural \\nInformation Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings. \\nneurips.cc/paper/2017/file/0f3d014eead934bbdbacb62a01dc4831-Paper.pdf. \\n\\nJeffrey Pennington and Pratik Worah. \\nThe spectrum of the Fisher information matrix of a single-\\nhidden-layer neural network. \\nIn Advances in Neural Information Processing Systems, volume 31. \\nCurran Associates, Inc., 2018. \\nURL https://proceedings.neurips.cc/paper/2018/file/ \\n18bb68e2b38e4a8ce7cf4f6b2625768c-Paper.pdf. \\n\\nMeyer Scetbon and Zaid Harchaoui. A spectral analysis of dot-product kernels. In International conference on \\nartificial intelligence and statistics, pp. 3394-3402. PMLR, 2021. \\n\\nSamuel S. Schoenholz, Justin Gilmer, Surya Ganguli, and Jascha Sohl-Dickstein. Deep information propagation. \\nIn International Conference on Learning Representations (ICLR), 2017. URL https://openreview.net/ \\npdf?id=H1W1UN9gg. \\n\\nEduardo D. Sontag and Héctor J. Sussmann. Backpropagation can give rise to spurious local minima even for networks \\nwithout hidden layers. Complex Systems, 3:91-106, 1989. \\n\\nMaksim Velikanov and Dmitry Yarotsky. \\nExplicit loss asymptotics in the gradient descent training of \\nneural networks. \\nIn Advances in Neural Information Processing Systems, volume 34, pp. 2570-2582. \\nCurran Associates, Inc., 2021. \\nURL https://proceedings.neurips.cc/paper/2021/file/ \\n14faf969228fc18fcd4fcf59437b0c97-Paper.pdf. \\n\\nHermann Weyl. Das asymptotische Verteilungsgesetz der Eigenwerte linearer partieller Differentialgleichungen (mit \\neiner Anwendung auf die Theorie der Hohlraumstrahlung). Mathematische Annalen, 71(4):441-479, 1912. URL \\nhttps://doi.org/10.1007/BF01456804. \\n\\nBlake Woodworth, Suriya Gunasekar, Jason D. Lee, Edward Moroshko, Pedro Savarese, Itay Golan, Daniel Soudry, \\nand Nathan Srebro. Kernel and rich regimes in overparametrized models. In Proceedings of Thirty Third Conference \\non Learning Theory, volume 125 of Proceedings of Machine Learning Research, pp. 3635-3673. PMLR, 2020. \\nURL https://proceedings.mlr.press/v125/woodworth20a.html. \\nGreg \\n\\n\\n) For arbitrary n, d ∈ N, let A ∈ R n×d . For i ∈ [n]B Expressing the NTK as a power series \\n\\nB.1 Deriving a power series for the NTK \\n\\nWe will require the following minor adaptation of Nguyen & Mondelli (2020, Lemma D.2). We remark this result was \\nfirst stated for ReLU and Softplus activations in the work of Oymak & Soltanolkotabi (2020, Lemma H.2). \\nLemma B.1. \\n\\n\\nThen we havewhich is a constant independent of k. Also, for sufficiently large k, we have1 − \\nk 2 − d(p − k + 1) \\n(p + 1) 2 \\n\\np−k+1 \\n2 \\n\\n= 1 − \\nk 2 − d(p − k + 1) \\n(p + 1) 2 \\n\\n−(p+1) 2 \\n\\nk 2 −d(p−k+1) · \\n\\n−k 2 +d(p−k+1) \\n(p+1) 2 \\n\\n· p−k+1 \\n\\n2 \\n\\n≤ e \\n\\n−k 2 +d(p−k+1) \\n(p+1) 2 \\n\\n· p−k+1 \\n\\n2 \\n\\n≤ e \\n\\ndp 2 \\n\\n2p 2 = e \\n\\nd \\n2 \\n\\n1 + \\nk + d \\np + 1 \\n\\n2k+d−1 \\n2 \\n\\n= 1 + \\nk + d \\np + 1 \\n\\np+1 \\nk+d \\n\\nk+d \\np+1 \\n\\n2k+d−1 \\n2 \\n\\n≤ e \\n\\nk+d \\np+1 \\n\\n2k+d−1 \\n2 \\n\\n≤ e \\n\\n3k 2 \\n\\n2r = e \\n\\n3 \\n2 \\n\\n\\n In particular, in Han et al. (2022)  the authors focus on homogeneous activation functions and allow the data to lie off the sphere. By contrast, we require the data to lie on the sphere but can handle non-homogeneous activation functions in the deep setting.\\nhttps://pytorch.org/functorch/stable/notebooks/neural tangent kernels.html\\nWe remark that U1, U2 are dependent and identically distributed as U1, U2 ∼ N (0, 1).\\nhttps://pytorch.org/functorch/stable/notebooks/neural tangent kernels.html\\nAcknowledgements and Disclosure of FundingThis project has been supported by ERC Grant 757983 and NSF CAREER Grant DMS-2145630.AppendixCorollary C.19. Under the same setting as in Theorem 4.6, 1. if c p = Θ(p −a ) where a ≥ 1, then λ k = Θ(k −d−2a+2 ), 2. if c p = δ (p even) Θ(p −a ), then λ k = δ (k even) Θ(k −d−2a+2 ),4. if c p = Θ(p 1/2 a −p ), then λ k = O k −d+1 a −k and λ k = Ω k −d/2+1 2 −k a −k .Proof of Corollary C.4, part 1. We first prove λ k = O(k −d−2a+2 ). Suppose that c p ≤ Cp −a for some constant C, then according to Theorem 4.6 we haveAccording to Stirling's formula, we haveWe defineBy applying the chain rule to e log fa(p) , we have that the derivative of f a is f a (p) = (p + 1) p+ 1 2 p −a 2(p − k + 1)Then g a (p) and f a (p) have the same sign. Next we will show that g a (p) ≥ 0 for k ≤ p ≤ k 2 d+24a when k is large enough.First when p ≥ k andwhen k is sufficiently large.Second when p ≥ k and 0 ≤.when k is sufficiently large. Also we haveCombining all the arguments above, we conclude that g a (p) ≥ 0 and f a (p) ≥ 0 when k ≤ p ≤ k 2 d+24a . Then whenWhen p ≥ k 2 d+24a , we have f a (p) = p −a (p + 1)which is a constant independent of k. Then for p ≥ k 2 d+24a , we haveFinally we haveProof of Corollary C.4, part 4. Since c p = Θ(p 1/2 a −p ), we have that c p ≤ Cp 1/2 a −p for some constant C. Similar to (65), we haveUse the definition in (66) and let a = 0, we have f 0 (p) = (p + 1)Then according to(69)and(70), for sufficiently large k, we have f 0 (p) ≤ f 0Overall, for all p ≥ k, we haveThen we haveOn the other hand, since c p = Θ(p 1/2 a −p ), we have that c p ≥ C p 1/2 a −p for some constant C . Similar to (73), we havep≥k p−k is even p 1/2 a −p (p + 1)≥ 2π d/2 2 d 2 e d 2 C 2 1 C C 2 2 k 1/2 a −k (k + 1)= Ω k −d/2+1 a −k (k + 1)Since (k + 1) k = k k (1 + 1/k) k = Θ(k k ). Similarly, (k + k + 1 + d) k = Θ((2k) k ). Then we have= Ω k −d/2+1 a −k k k (2k) k= Ω k −d/2+1 2 −k a −k .\\nA convergence theory for deep learning via over-parameterization. Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song, PMLRProceedings of the 36th International Conference on Machine Learning. the 36th International Conference on Machine Learning97Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-parameterization. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Ma- chine Learning Research, pp. 242-252. PMLR, 2019. URL https://proceedings.mlr.press/v97/ allen-zhu19a.html.\\n\\nNeural Network Learning -Theoretical Foundations. Martin Anthony, Peter L Bartlett, Cambridge University PressMartin Anthony and Peter L. Bartlett. Neural Network Learning -Theoretical Foundations. Cambridge Univer- sity Press, 2002. URL http://www.cambridge.org/gb/knowledge/isbn/item1154061/?site_ locale=en_GB.\\n\\nFine-grained analysis of optimization and generalization for overparameterized two-layer neural networks. Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, Ruosong Wang, PMLRProceedings of the 36th International Conference on Machine Learning. the 36th International Conference on Machine Learning97Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of optimization and gener- alization for overparameterized two-layer neural networks. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 322-332. PMLR, 2019a. URL https://proceedings.mlr.press/v97/arora19a.html.\\n\\nOn exact computation with an infinitely wide neural net. Sanjeev Arora, S Simon, Wei Du, Zhiyuan Hu, Li, R Russ, Ruosong Salakhutdinov, Wang, Advances in Neural Information Processing Systems. Curran Associates, Inc32Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, Russ R Salakhutdinov, and Ruosong Wang. On exact com- putation with an infinitely wide neural net. In Advances in Neural Information Processing Systems, vol- ume 32. Curran Associates, Inc., 2019b. URL https://proceedings.neurips.cc/paper/2019/ file/dbc4d84bfcfe2284ba11beffb853a8c4-Paper.pdf.\\n\\nEigenvalues of dot-product kernels on the sphere. Douglas Azevedo, A Valdir, Menegatto, Proceeding Series of the Brazilian Society of Computational and Applied Mathematics. 31Douglas Azevedo and Valdir A Menegatto. Eigenvalues of dot-product kernels on the sphere. Proceeding Series of the Brazilian Society of Computational and Applied Mathematics, 3(1), 2015.\\n\\nRademacher and gaussian complexities: Risk bounds and structural results. L Peter, Shahar Bartlett, Mendelson, J. Mach. Learn. Res. 3Peter L. Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. J. Mach. Learn. Res., 3:463-482, 2002. URL http://dblp.uni-trier.de/db/journals/jmlr/jmlr3. html#BartlettM02.\\n\\nThe convergence rate of neural networks for learned functions of different frequencies. Ronen Basri, David W Jacobs, Yoni Kasten, Shira Kritchman, Advances in Neural Information Processing Systems. Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d'Alché-Buc, Emily B. Fox, and Roman Garnett32Ronen Basri, David W. Jacobs, Yoni Kasten, and Shira Kritchman. The convergence rate of neural networks for learned functions of different frequencies. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d'Alché-Buc, Emily B. Fox, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 4763-4772, 2019. URL https://proceedings.neurips.cc/paper/2019/hash/ 5ac8bb8a7d745102a978c5f8ccdb61b8-Abstract.html.\\n\\nFrequency bias in neural networks for input of non-uniform density. Ronen Basri, Meirav Galun, Amnon Geifman, David Jacobs, Yoni Kasten, Shira Kritchman, PMLRProceedings of the 37th International Conference on Machine Learning. the 37th International Conference on Machine Learning119Ronen Basri, Meirav Galun, Amnon Geifman, David Jacobs, Yoni Kasten, and Shira Kritchman. Frequency bias in neural networks for input of non-uniform density. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 685-694. PMLR, 2020. URL https://proceedings.mlr.press/v119/basri20a.html.\\n\\nDeep equals shallow for ReLU networks in kernel regimes. Alberto Bietti, Francis Bach, International Conference on Learning Representations. Alberto Bietti and Francis Bach. Deep equals shallow for ReLU networks in kernel regimes. In International Confer- ence on Learning Representations, 2021. URL https://openreview.net/forum?id=aDjoksTpXOP.\\n\\nOn the inductive bias of neural tangent kernels. Alberto Bietti, Julien Mairal, Advances in Neural Information Processing Systems. Curran Associates, Inc32Alberto Bietti and Julien Mairal. On the inductive bias of neural tangent kernels. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/ paper/2019/file/c4ef9c39b300931b69a36fb3dbb8d60e-Paper.pdf.\\n\\nImplicit bias of MSE gradient optimization in underparameterized neural networks. Benjamin Bowman, Guido Montúfar, International Conference on Learning Representations. Benjamin Bowman and Guido Montúfar. Implicit bias of MSE gradient optimization in underparameterized neural networks. In International Conference on Learning Representations, 2022. URL https://openreview.net/ forum?id=VLgmhQDVBV.\\n\\nSpectral bias outside the training set for deep networks in the kernel regime. Benjamin Bowman, Guido Montufar, Advances in Neural Information Processing Systems. Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun ChoBenjamin Bowman and Guido Montufar. Spectral bias outside the training set for deep networks in the kernel regime. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=a01PL2gb7W5.\\n\\nOptimal rates for the regularized least-squares algorithm. Andrea Caponnetto, Ernesto De Vito, Foundations of Computational Mathematics. 73Andrea Caponnetto and Ernesto De Vito. Optimal rates for the regularized least-squares algorithm. Foundations of Computational Mathematics, 7(3):331-368, 2007.\\n\\nDeep neural tangent kernel and laplace kernel have the same RKHS. Lin Chen, Sheng Xu, International Conference on Learning Representations. Lin Chen and Sheng Xu. Deep neural tangent kernel and laplace kernel have the same RKHS. In International Con- ference on Learning Representations, 2021. URL https://openreview.net/forum?id=vK9WrZ0QYQ.\\n\\nGeneralization error rates in kernel regression: The crossover from the noiseless to noisy regime. Hugo Cui, Bruno Loureiro, Florent Krzakala, Lenka Zdeborová, Advances in Neural Information Processing Systems. Hugo Cui, Bruno Loureiro, Florent Krzakala, and Lenka Zdeborová. Generalization error rates in kernel regression: The crossover from the noiseless to noisy regime. In Advances in Neural Information Processing Systems, 2021. URL https://openreview.net/forum?id=Da_EHrAcfwd.\\n\\nToward deeper understanding of neural networks: The power of initialization and a dual view on expressivity. Amit Daniely, Roy Frostig, Yoram Singer, Advances in Neural Information Processing Systems. Curran Associates, Inc29Amit Daniely, Roy Frostig, and Yoram Singer. Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity. In Advances in Neural Information Processing Systems, vol- ume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/ abea47ba24142ed16b7d8fbf2c740e0d-Paper.pdf.\\n\\nOn Wallis' formula. K Donat, Kazarinoff, Edinburgh Mathematical Notes. 40Donat K. Kazarinoff. On Wallis' formula. Edinburgh Mathematical Notes, 40:19-21, 1956.\\n\\n. A Yann, Léon Lecun, Genevieve B Bottou, Klaus-Robert Orr, Müller, 10.1007/978-3-642-35289-8_3SpringerBerlin Heidelberg; Berlin, HeidelbergEfficient BackPropYann A. LeCun, Léon Bottou, Genevieve B. Orr, and Klaus-Robert Müller. Efficient BackProp, pp. 9-48. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. URL https://doi.org/10.1007/978-3-642-35289-8_\\n\\nDeep neural networks as Gaussian processes. Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S Schoenholz, Jeffrey Pennington, Jascha Sohl-Dickstein, International Conference on Learning Representations. Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S. Schoenholz, Jeffrey Pennington, and Jascha Sohl-Dickstein. Deep neural networks as Gaussian processes. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=B1EA-M-0Z.\\n\\nWide neural networks of any depth evolve as linear models under gradient descent. Jaehoon Lee, Lechao Xiao, Samuel Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-Dickstein, Jeffrey Pennington, Advances in Neural Information Processing Systems. Curran Associates, Inc32Jaehoon Lee, Lechao Xiao, Samuel Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-Dickstein, and Jeffrey Pennington. Wide neural networks of any depth evolve as linear models under gradient descent. In Advances in Neu- ral Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings. neurips.cc/paper/2019/file/0d1a9651497a38d8b1c3871c84528bd4-Paper.pdf.\\n\\nFinite versus infinite neural networks: an empirical study. Jaehoon Lee, Samuel Schoenholz, Jeffrey Pennington, Ben Adlam, Lechao Xiao, Roman Novak, Jascha Sohl-Dickstein, Advances in Neural Information Processing Systems. Curran Associates, Inc33Jaehoon Lee, Samuel Schoenholz, Jeffrey Pennington, Ben Adlam, Lechao Xiao, Roman Novak, and Jascha Sohl- Dickstein. Finite versus infinite neural networks: an empirical study. In Advances in Neural Information Pro- cessing Systems, volume 33, pp. 15156-15172. Curran Associates, Inc., 2020. URL https://proceedings. neurips.cc/paper/2020/file/ad086f59924fffe0773f8d0ca22ea712-Paper.pdf.\\n\\n. Andreeto Li, Ranzato , Perona , Caltech. 101Li, Andreeto, Ranzato, and Perona. Caltech 101, Apr 2022.\\n\\nGradient descent with early stopping is provably robust to label noise for overparameterized neural networks. Mingchen Li, Mahdi Soltanolkotabi, Samet Oymak, PMLR, 2020Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics. the Twenty Third International Conference on Artificial Intelligence and Statistics108Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. Gradient descent with early stopping is provably robust to label noise for overparameterized neural networks. In Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pp. 4313-4324. PMLR, 2020. URL https://proceedings.mlr.press/v108/li20j.html.\\n\\nA random matrix approach to neural networks. Cosme Louart, Zhenyu Liao, Romain Couillet, The Annals of Applied Probability. 282Cosme Louart, Zhenyu Liao, and Romain Couillet. A random matrix approach to neural networks. The Annals of Applied Probability, 28(2):1190-1248, 2018. URL https://www.jstor.org/stable/26542333.\\n\\nAll you need is a good init. Dmytro Mishkin, Jiri Matas, 4th International Conference on Learning Representations, Conference Track Proceedings. Yoshua Bengio and Yann LeCunDmytro Mishkin and Jiri Matas. All you need is a good init. In Yoshua Bengio and Yann LeCun (eds.), 4th International Conference on Learning Representations, Conference Track Proceedings, 2016. URL http: //arxiv.org/abs/1511.06422.\\n\\nActivation function design for deep networks: linearity and effective initialisation. M Murray, V Abrol, J Tanner, Special Issue on Harmonic Analysis and Machine Learning. 59M. Murray, V. Abrol, and J. Tanner. Activation function design for deep networks: linearity and effective initialisation. Applied and Computational Harmonic Analysis, 59:117-154, 2022. URL https://www.sciencedirect. com/science/article/pii/S1063520321001111. Special Issue on Harmonic Analysis and Machine Learning.\\n\\nBayesian Learning for Neural Networks. M Radford, Neal, Springer-VerlagBerlin, HeidelbergRadford M. Neal. Bayesian Learning for Neural Networks. Springer-Verlag, Berlin, Heidelberg, 1996.\\n\\nOn the proof of global convergence of gradient descent for deep relu networks with linear widths. Quynh Nguyen, PMLRProceedings of the 38th International Conference on Machine Learning. the 38th International Conference on Machine Learning139Quynh Nguyen. On the proof of global convergence of gradient descent for deep relu networks with linear widths. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Ma- chine Learning Research, pp. 8056-8062. PMLR, 2021. URL https://proceedings.mlr.press/v139/ nguyen21a.html.\\n\\nGlobal convergence of deep networks with one wide layer followed by pyramidal topology. Quynh Nguyen, Marco Mondelli, Advances in Neural Information Processing Systems. Curran Associates, Inc33Quynh Nguyen and Marco Mondelli. Global convergence of deep networks with one wide layer followed by pyramidal topology. In Advances in Neural Information Processing Systems, volume 33, pp. 11961- 11972. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/ 8abfe8ac9ec214d68541fcb888c0b4c3-Paper.pdf.\\n\\nTight bounds on the smallest eigenvalue of the neural tangent kernel for deep ReLU networks. Quynh Nguyen, Marco Mondelli, Guido Montúfar, PMLRProceedings of the 38th International Conference on Machine Learning. the 38th International Conference on Machine Learning139Quynh Nguyen, Marco Mondelli, and Guido Montúfar. Tight bounds on the smallest eigenvalue of the neu- ral tangent kernel for deep ReLU networks. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 8119-8129. PMLR, 2021. URL https://proceedings.mlr.press/v139/nguyen21g.html.\\n\\nBayesian deep convolutional networks with many channels are Gaussian processes. Roman Novak, Lechao Xiao, Yasaman Bahri, Jaehoon Lee, Greg Yang, Jiri Hron, Daniel A Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein, 7th International Conference on Learning Representations. OpenReview.net. Roman Novak, Lechao Xiao, Yasaman Bahri, Jaehoon Lee, Greg Yang, Jiri Hron, Daniel A. Abolafia, Jeffrey Pennington, and Jascha Sohl-Dickstein. Bayesian deep convolutional networks with many channels are Gaus- sian processes. In 7th International Conference on Learning Representations. OpenReview.net, 2019. URL https://openreview.net/forum?id=B1g30j0qF7.\\n\\nFast finite width neural tangent kernel. Roman Novak, Jascha Sohl-Dickstein, Samuel S Schoenholz, PMLRProceedings of the 39th International Conference on Machine Learning. Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabatothe 39th International Conference on Machine Learning162Roman Novak, Jascha Sohl-Dickstein, and Samuel S Schoenholz. Fast finite width neural tangent kernel. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 17018-17044. PMLR, 17-23 Jul 2022. URL https://proceedings.mlr.press/v162/novak22a. html.\\n\\nAnalysis of Boolean functions. O&apos; Ryan, Donnell, Cambridge University PressRyan O'Donnell. Analysis of Boolean functions. Cambridge University Press, 2014.\"}\n"
          ]
        }
      ],
      "source": [
        "query_data = load_dataset(\"yale-nlp/LitSearch-NLP-Class\", \"query\", split=\"full\")\n",
        "corpus_data = load_dataset(\"yale-nlp/LitSearch-NLP-Class\", \"corpus_new\", split=\"full\")\n",
        "\n",
        "# Print dataset sizes to verify loading\n",
        "print(f\"Query set size: {len(query_data)}\")\n",
        "print(f\"Corpus size: {len(corpus_data)}\")\n",
        "\n",
        "# After loading datasets, add structure inspection\n",
        "print(\"\\nQuery dataset columns:\", list(query_data.features.keys()))\n",
        "print(\"Sample query:\", query_data[0])\n",
        "print(\"\\nCorpus dataset columns:\", list(corpus_data.features.keys()))\n",
        "print(\"Sample corpus document:\", corpus_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBgcq8or-gkn"
      },
      "source": [
        "## Task 1: Embed Documents Using the Arctic Embeddings Model (20 points)\n",
        "Initialize the Arctic Embeddings model (check usage example here: https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5#using-huggingface-transformers) which will be used to encode both queries and documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ydlcL_kG-gkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "0d70c454fe9a46e7b80d833aeb8b7f0e",
            "3e99192fc13149b2b5b9dada0c4849fa",
            "859dc71efe8849acb51b091de10e9805",
            "2f4fbcd61d484060bd8937998069b399",
            "02358bd7243246b3a0cfa285903aa5e9",
            "4384cc0312d74ce793bf1de884d06635",
            "b79477e76a1a44f3bab9b6c891404908",
            "3d5473f9165f4136ba676bc81a2a38d7",
            "9b20a956d9774f549677d512aa7a6dd9",
            "a89e2851a3624fa59897e7ae03e92c64",
            "b35ca3f53e744718b35fc0e2fbaa79c2",
            "e30009e0be0f404eb84a6d40c63b393e",
            "57928e9fffea47189efa6a7784b71f33",
            "d267252d469e4809bdeeb8f8d61d9ee2",
            "0fca6f4f3e47491aabcc62d32bb4f3dd",
            "43fcc3ed59ff4fe588b900f23f40a93f",
            "f726e131aab74cd4a90b89ef897d1eab",
            "47c26844c2c4454ebf023cf8f148f917",
            "12918d8dfe614a7789688927bb0e8af6",
            "a2220f10efe0431da07265b82efb1ac1",
            "9108e803ebf449d8b8d6d98cadb3f566",
            "36da8dc89a8649bca724876f2647e4f7",
            "fb8b316142ba42f7ac2b87d4dad2874d",
            "0343ce9951e642ec81d6098f622b3a9b",
            "d7e59042f83e41738ab2cbe3337f63f5",
            "41ae86e17c7c4df0b476400975b74afc",
            "ff2299f9da0d4367bbf891b0dadf6db8",
            "6de538346e24449ab69a24acf0762429",
            "69b920353f9a4e06905e10a989c8e442",
            "710ca86fc79a495393fc4e2066e90622",
            "e005087cd76c4d3f846dbfd4ec1e56d5",
            "d2006aae016e45268d8d3427ba662cee",
            "651a7a0242bf4a8d99e82a53e0351cc8",
            "6f2214864b2a4ea4b4033ae4f5723f37",
            "d522834ea7074fe59d9e0d394aaa9361",
            "05fb22912eec43f696e470ab495cf565",
            "0bfc424e7cb44a11b441d712350f2127",
            "181392c6abab4fa5b03cca7c668c53b3",
            "02399f13e84c4e38aabbeb5124ff0635",
            "6c8c7d5aa1774ab88df502a4005995d0",
            "118aeaf5ef2b4fee9b11b5a8103ddb3d",
            "4bfc4bb75cd643cfb3f00eb30fb01267",
            "630766a673734413b7f525c544b9fd61",
            "82174f3de69144c9913e4be3f29c1075",
            "e9c55dcaab0f428da74a096501d36f3b",
            "7c35c5508d054e0d8ebf5f9af4f12afb",
            "2e9047aaa9ab4b6e99101b4084d49cec",
            "9e25bda7b3934553a07e1fd52725ffde",
            "d203acf8d29244ceb4afb97e941f6e8e",
            "ae678fa439f44ff69d940f61a1508f6a",
            "388af9942abc46c99a4c63c046741046",
            "b9758054106445168a28ce3fc1da0faf",
            "65702fb60b71410a96829926168f6d59",
            "c912bbba6977417189d92836cc9e86e0",
            "a3e122e22b074eceac451d429261c1db",
            "cd6269d203444f1c9778e76556031696",
            "c175b38a5f7b4123a710a451aa5b07e4",
            "6a49a522b5da48c69ee7725d0d982528",
            "716c6840e54e4b6da5c4d14e35edc5de",
            "6bad71359a26408d91d4b096424da629",
            "607e584345024c2ba19e252119b04480",
            "dff6f145b72d47368617c655027ac566",
            "8dae130973664dbeaa54e88e8cf8371b",
            "4b9478d9ba92411295527777a38c3e39",
            "f3f8150bd00040e5a9c8eb5b2e0e85d7",
            "dd5986557aa0408e9bf959c07deb6589"
          ]
        },
        "outputId": "a166bec8-c306-4dce-f2bf-fbfdcade633b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d70c454fe9a46e7b80d833aeb8b7f0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e30009e0be0f404eb84a6d40c63b393e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb8b316142ba42f7ac2b87d4dad2874d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f2214864b2a4ea4b4033ae4f5723f37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c55dcaab0f428da74a096501d36f3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd6269d203444f1c9778e76556031696"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-m-v1.5 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'Snowflake/snowflake-arctic-embed-m-v1.5' and tokenizer loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Initialize Arctic Embeddings model\n",
        "# We will be using a lightweight yet capable embedding model called Arctic\n",
        "# TODO:\n",
        "# 1. Load tokenizer using AutoTokenizer.from_pretrained(model_name)\n",
        "# 2. Load model using AutoModel.from_pretrained(model_name)\n",
        "# 3. Move model to GPU using .to('cuda')\n",
        "from torch.nn.functional import normalize\n",
        "model_name = \"Snowflake/snowflake-arctic-embed-m-v1.5\" # check\n",
        "# tokenizer = None  # TODO: YOUR CODE HERE\n",
        "# model = None\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model     = AutoModel.from_pretrained(model_name)    # TODO: YOUR CODE HERE\n",
        "model.eval()\n",
        "\n",
        "if tokenizer is None or model is None:\n",
        "    raise NotImplementedError(\"tokenizer or model not loaded properly.\")\n",
        "\n",
        "print(f\"Model '{model_name}' and tokenizer loaded successfully.\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def get_embeddings(texts, batch_size=128, disable=False):\n",
        "    \"\"\"Get embedding vectors for input texts\n",
        "\n",
        "    TODO Implementation Steps:\n",
        "    1.  **Add Prefix**: Prepend the recommended prefix\n",
        "        `\"Represent this sentence for searching relevant passages: \"` to each text\n",
        "        in the input list. This is important for Arctic model performance.\n",
        "    2.  **Batch Processing**: Iterate through the prefixed texts in batches of size `batch_size`.\n",
        "    3.  **Tokenization**: For each batch:\n",
        "        - Tokenize the texts using the `tokenizer`. Ensure you add padding (`padding=True`),\n",
        "          truncate sequences (`truncation=True`), specify a `max_length` (e.g., 512),\n",
        "          and return PyTorch tensors (`return_tensors=\"pt\"`).\n",
        "        - Move the tokenized batch to the GPU (`.to('cuda')`).\n",
        "    4.  **Inference**: Within a `torch.inference_mode()` context:\n",
        "        - Pass the tokenized batch to the `model`.\n",
        "        - Extract the [CLS] token's embedding. This is typically the embedding of the\n",
        "          first token in the `last_hidden_state` (output[0][:, 0]).\n",
        "    5.  **Normalization**: Apply L2 normalization to the extracted [CLS] embeddings\n",
        "        Question: Why you would need to normalize?\n",
        "    6.  **Collection**: Store the normalized embeddings (moved back to CPU using `.cpu()`).\n",
        "    7.  **Concatenation**: After processing all batches, concatenate the collected\n",
        "        batch embeddings into a single tensor using `torch.cat()`.\n",
        "    8.  Return the final tensor.\n",
        "\n",
        "    Args:\n",
        "        texts: List of strings to encode\n",
        "        batch_size: Batch size for processing\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor of shape (len(texts), embedding_dim)\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "    prefix = \"Represent this sentence for searching relevant passages: \"\n",
        "\n",
        "    # --- TODO: Implement the embedding generation logic ---\n",
        "    # Follow the implementation steps described in the docstring above.\n",
        "    # Approximately 10-15 lines of code are expected.\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = [prefix + t for t in texts[i : i + batch_size]]\n",
        "\n",
        "        enc = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids      = enc.input_ids.to(device)\n",
        "        attention_mask = enc.attention_mask.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_emb = out.last_hidden_state[:, 0, :]  # shape (batch, dim)\n",
        "        cls_emb = normalize(cls_emb, p=2, dim=1)\n",
        "        all_embeddings.append(cls_emb.cpu()) #Move back to CPU and store\n",
        "\n",
        "    embeddings = torch.cat(all_embeddings, dim=0)\n",
        "\n",
        "    if embeddings.size(0) != len(texts):\n",
        "        raise RuntimeError(\"Expected embeddings for all texts\")\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "    # --- End TODO ---\n",
        "\n",
        "    if not all_embeddings:\n",
        "         raise NotImplementedError(\"TODO Embedding generation logic not implemented or returned empty list.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq3kaatH-gkn"
      },
      "source": [
        "## Task 2: Building Retrieval Index (10 points)\n",
        "Construct a FAISS index for efficient similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-emkU2SS-gko"
      },
      "outputs": [],
      "source": [
        "# Task 2: Build FAISS Index\n",
        "def build_faiss_index(corpus_data):\n",
        "    \"\"\"Build FAISS index for similarity search\n",
        "\n",
        "    TODO Implementation Steps:\n",
        "    1.  **Prepare Texts**: Create a list of strings (`corpus_texts`), where each string\n",
        "        is the concatenation of a document's \"title\" and \"abstract\".\n",
        "    2.  **Generate Embeddings**: Use the `get_embeddings` function implemented in Task 1\n",
        "        to generate embeddings for all `corpus_texts`.\n",
        "    3.  **Initialize Index**: Create a FAISS index suitable for dense vector similarity\n",
        "        search. `faiss.IndexFlatL2` is a good choice here. Make sure its dimension\n",
        "        matches the dimension of your generated embeddings.\n",
        "    4.  **Add Embeddings**: Add the generated corpus embeddings to the FAISS index.\n",
        "        Note: FAISS typically requires embeddings as a NumPy array (`.numpy()`).\n",
        "    5.  Return the populated FAISS index.\n",
        "\n",
        "    Args:\n",
        "        embeddings: torch.Tensor or numpy array of shape (N, dim)\n",
        "    Returns:\n",
        "        FAISS index\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Follow the implementation steps described in the docstring above.\n",
        "    # Approximately 5 lines of code are expected.\n",
        "\n",
        "    corpus_texts = [doc[\"title\"] + \" \" + doc[\"abstract\"]for doc in corpus_data]      # YOUR CODE HERE\n",
        "    corpus_embeddings = get_embeddings(corpus_texts)\n",
        "    dim = corpus_embeddings.size(1)\n",
        "    corpus_index = faiss.IndexFlatL2(dim)\n",
        "    corpus_index.add(corpus_embeddings)    # YOUR CODE HERE (Initialize IndexFlatL2 and add embeddings)\n",
        "\n",
        "    # --- End TODO ---\n",
        "\n",
        "    if corpus_index is None or corpus_index.ntotal == 0:\n",
        "        raise NotImplementedError(\"TODO 2.1: FAISS index not built or is empty.\")\n",
        "\n",
        "    return corpus_index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building FAISS index for the corpus...\")\n",
        "corpus_index = build_faiss_index(corpus_data)\n",
        "print(f\"FAISS index built successfully with {corpus_index.ntotal} documents.\")"
      ],
      "metadata": {
        "id": "e_qgX9YqEyYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9694b482-96cd-4473-b939-edb7a3036fb2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building FAISS index for the corpus...\n",
            "FAISS index built successfully with 6809 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdIfkBLR-gko"
      },
      "source": [
        "## Task 3: Implementing Retrieval  (10 points)\n",
        "Implement the retrieval function that:\n",
        "1. Encodes the input query\n",
        "2. Performs similarity search in the index\n",
        "3. Returns the top-k most relevant documents (default value of k is 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Task 3: Implementing Retrieval\n",
        "# Implement the retrieval function that uses the built index to find relevant documents for a given query.\n",
        "\n",
        "\n",
        "def retrieve(corpus_data, corpus_index, query, k=10):\n",
        "    \"\"\"\n",
        "    Retrieve the top-k most relevant documents for a given query using the FAISS index.\n",
        "\n",
        "    Args:\n",
        "        corpus_data (datasets.Dataset): The original corpus dataset.\n",
        "        corpus_index (faiss.Index): The FAISS index built from corpus embeddings.\n",
        "        query (str): The search query string.\n",
        "        k (int): The number of top documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: A list containing the top-k relevant document entries from `corpus_data`.\n",
        "\n",
        "    Implementation Guide/Steps:\n",
        "    High-level: You need to embed the query, then search the index, then retrieve and return\n",
        "\n",
        "    Steps:\n",
        "    1.  **Get Query Embedding**: Generate the embedding for the input `query` using the\n",
        "        `get_embeddings` function. Remember `get_embeddings` expects a list of texts.\n",
        "        Set `disable=True` to avoid nested progress bars.\n",
        "    2.  **Search Index**: Use the `corpus_index.search()` method to find the `k` nearest\n",
        "        neighbors to the query embedding. This returns distances (D) and indices (I).\n",
        "        FAISS search expects a NumPy array for the query embedding.\n",
        "    3.  **Retrieve Documents**: Get the indices of the top-k documents from the search\n",
        "        results (I[0]). Use these indices to retrieve the corresponding full document\n",
        "        entries from the original `corpus_data`.\n",
        "        Note: Ensure indices from FAISS (often numpy.int64) are converted to standard\n",
        "        Python `int` for indexing into the `datasets.Dataset`.\n",
        "    4.  Return the list of retrieved documents.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- TODO: Implement the retrieval logic ---\n",
        "    # Follow the implementation steps described in the docstring above.\n",
        "    # Approximately 3-4 lines of code are expected.\n",
        "    qurey_embeddings = get_embeddings([query], disable=True).cpu().numpy()\n",
        "    D, I   = corpus_index.search(qurey_embeddings, k)\n",
        "    retrieved_docs = [corpus_data[int(idx)] for idx in I[0]] # YOUR CODE HERE\n",
        "\n",
        "    # --- End TODO ---\n",
        "\n",
        "    if retrieved_docs is None:\n",
        "        raise NotImplementedError(\"TODO 3.1: Retrieval logic not implemented.\")\n",
        "\n",
        "    return retrieved_docs"
      ],
      "metadata": {
        "id": "Ck7ujZdmC_Fe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igL3MeXV-gko"
      },
      "source": [
        "## Evaluation Details\n",
        "\n",
        "We will evaluate the retrieval performance using Recall@10\n",
        "To receive full scores, the score should be > 0.78"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kMD0WkQc-gko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45658cfd-bea9-49ba-9f2e-9e2d369639a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Query: Transformer models for natural language processing\n",
            "\n",
            "Top 2 Retrieved Papers:\n",
            "\n",
            "0. Hierarchical Transformer for Task Oriented Dialog Systems\n",
            "Abstract: Generative models for dialog systems have gained much interest because of the recent success of RNN and Transformer based models in tasks like question answering and summarization. Although the task o...\n",
            "\n",
            "1. Pretrained Transformers for Text Ranking: BERT and Beyond\n",
            "Abstract: The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query for a particular task. Although the most common formulation of text ranking is search, i...\n"
          ]
        }
      ],
      "source": [
        "## Evaluation Section\n",
        "\n",
        "# This section contains code to evaluate your retrieval implementation using Recall@10.\n",
        "# **You do not need to modify the code below.** Run these cells after completing Tasks 1, 2, and 3 to check your work.\n",
        "\n",
        "# The target performance is **Recall@10 > 0.78**.\n",
        "\n",
        "# Example usage and visualization\n",
        "sample_query = \"Transformer models for natural language processing\"\n",
        "results = retrieve(corpus_data, corpus_index, sample_query)\n",
        "gold_titles = [\"Hierarchical Transformer for Task Oriented Dialog Systems\", \"Pretrained Transformers for Text Ranking: BERT and Beyond\"]\n",
        "\n",
        "print(\"Sample Query:\", sample_query)\n",
        "print(\"\\nTop 2 Retrieved Papers:\")\n",
        "for i, doc in enumerate(results[:2], 0):\n",
        "    assert doc[\"title\"] == gold_titles[i]\n",
        "    print(f\"\\n{i}. {doc['title']}\")\n",
        "    print(f\"Abstract: {doc['abstract'][:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZuYwWGbj-gko"
      },
      "outputs": [],
      "source": [
        "def evaluate(corpus_index, queries, relevants, k=10):\n",
        "    \"\"\"\n",
        "    Evaluate retrieval performance using Recall at k.\n",
        "\n",
        "    Args:\n",
        "        corpus_index: Your corpus or index structure.\n",
        "        queries (list): List of query strings.\n",
        "        relevants (list): List of lists, where each sublist contains\n",
        "                          the relevant document IDs for the corresponding query.\n",
        "        k (int): Number of documents to retrieve for each query.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing average Recall@k and a simple \"Passed\" flag.\n",
        "    \"\"\"\n",
        "    recall_sum = 0.0\n",
        "    n_queries = len(queries)\n",
        "\n",
        "    for query, rel_docs in zip(queries, relevants):\n",
        "        results = retrieve(corpus_data, corpus_index, query, k)  # Retrieve top-k docs\n",
        "        retrieved_ids = [doc['corpusid'] for doc in results]  # or 'paper_id' if needed\n",
        "\n",
        "        # Count how many relevant docs were retrieved\n",
        "        relevant_retrieved = sum(1 for doc_id in retrieved_ids if doc_id in rel_docs)\n",
        "\n",
        "        # Compute recall for this query (handle edge case if no relevant docs exist)\n",
        "        recall_sum += relevant_retrieved / len(rel_docs)\n",
        "\n",
        "    # Average recall over all queries\n",
        "    recall = recall_sum / n_queries\n",
        "\n",
        "    # A sample \"passing\" criterion\n",
        "    passed = recall > 0.78  # Threshold can be adjusted as needed\n",
        "\n",
        "    return {\n",
        "        \"Recall\": recall,\n",
        "        \"Passed_Requirement\": passed,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation on test set\n",
        "test_queries = query_data[\"query\"]\n",
        "test_relevants = query_data[\"corpusids\"]\n",
        "\n",
        "# Grade implementation\n",
        "results = evaluate(corpus_index, test_queries, test_relevants)\n",
        "print(f\"Evaluation results: {results}\")"
      ],
      "metadata": {
        "id": "aI-pek6ESO0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444fceb9-4e71-4057-dfbd-4abee7a0a83e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'Recall': 0.818425460636516, 'Passed_Requirement': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis and Discussion (10 points)\n",
        "\n",
        "Answer the following questions in a brief report below.\n",
        "\n",
        "1- What is the time complexity of your implemented `retrieve` function?\n",
        "\n",
        "2- Analyze failure cases where the gold passage is not found among the top-20 retrieved results. Identify and describe two distinct primary error types that contribute to these failures. For each error type, provide:\n",
        "- One representative example\n",
        "- A detailed explanation of the specific issue in that case"
      ],
      "metadata": {
        "id": "XVVX2y5nNjHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Your answers to above questions\n",
        "\n",
        "your_answer_1 = \"\"\"The time complexity is O(nd) over n corpus vectors of dimension d\"\"\"\n",
        "\n",
        "your_answer_2 = \"\"\"Truncation loss for long documents:The gold passage appears after the first 600\n",
        " tokens of a 2 000-token abstract, but our tokenizer truncates inputs to 512 tokens.\n",
        " By truncating, the core content carrying the gold answer was missing so its vector did not reflect the true relevance\"\"\"\n",
        "\n",
        "if your_answer_1 == \"\":\n",
        "  raise NotImplementedError()"
      ],
      "metadata": {
        "id": "QkDjtG7-D91Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "886fac0b20ff43f8a5cbd1a93c04b784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41faa1f09fd1483c965e60241911b3fd",
              "IPY_MODEL_91db3fc5d28c429da41e7e5ee9386173",
              "IPY_MODEL_21e14c142c5e4dba97d324c705935328"
            ],
            "layout": "IPY_MODEL_ce2889bf4b1a4aa189c093f04dbcb902"
          }
        },
        "41faa1f09fd1483c965e60241911b3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c4c5a64015749a7ae6e8bb04c89cd16",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3f856d29534a07a5cbb90f71e737f1",
            "value": "README.md: 100%"
          }
        },
        "91db3fc5d28c429da41e7e5ee9386173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae70a7760de4d6eabf3c0ae9e37434e",
            "max": 1472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64b46a1be54b4603bbc4147245726d99",
            "value": 1472
          }
        },
        "21e14c142c5e4dba97d324c705935328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703d0f1ee962441d942ff71070fb54ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0ae490d53b144740a3633a47067c74b2",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 132kB/s]"
          }
        },
        "ce2889bf4b1a4aa189c093f04dbcb902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4c5a64015749a7ae6e8bb04c89cd16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3f856d29534a07a5cbb90f71e737f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ae70a7760de4d6eabf3c0ae9e37434e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b46a1be54b4603bbc4147245726d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "703d0f1ee962441d942ff71070fb54ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae490d53b144740a3633a47067c74b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c0312f016e0428f827d292bd5bdd24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_903dc423b0a74aadba4f0876ef55962d",
              "IPY_MODEL_e8eb4c25117d4018b333def96410b0d0",
              "IPY_MODEL_1a5a83a6ade246d9b90e35109928b932"
            ],
            "layout": "IPY_MODEL_790c5eac3b8b4ae48ac4770d71f567b8"
          }
        },
        "903dc423b0a74aadba4f0876ef55962d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ef681a55ac4aceb011245fbb25b55d",
            "placeholder": "​",
            "style": "IPY_MODEL_088807a268a44a288022c9b80e6b44d2",
            "value": "full-00000-of-00001.parquet: 100%"
          }
        },
        "e8eb4c25117d4018b333def96410b0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4633afb64e424497bfad4ee9fc95a0",
            "max": 50621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2714233ef01847008e1ed94f4fdc2af9",
            "value": 50621
          }
        },
        "1a5a83a6ade246d9b90e35109928b932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7060139b316f482c8a88132010ee4de2",
            "placeholder": "​",
            "style": "IPY_MODEL_0db97938007c4e3ca6b77ee5d1743af9",
            "value": " 50.6k/50.6k [00:00&lt;00:00, 4.75MB/s]"
          }
        },
        "790c5eac3b8b4ae48ac4770d71f567b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ef681a55ac4aceb011245fbb25b55d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088807a268a44a288022c9b80e6b44d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b4633afb64e424497bfad4ee9fc95a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2714233ef01847008e1ed94f4fdc2af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7060139b316f482c8a88132010ee4de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db97938007c4e3ca6b77ee5d1743af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c07b39e3b8a244c98ba8f54ed2e8a773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49e385a947464971a167ec5893b78d3d",
              "IPY_MODEL_e5bce30fc9aa445ea1f9eff7fe3c8fa5",
              "IPY_MODEL_70216732fe60473a8118a79ea0dc2809"
            ],
            "layout": "IPY_MODEL_dd2c9297725449af900d1c86f1cc64e3"
          }
        },
        "49e385a947464971a167ec5893b78d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ed77c2289443c28ae98f8dd0a0d95b",
            "placeholder": "​",
            "style": "IPY_MODEL_3cb5580e7e36420cbd5583b27970d8c3",
            "value": "Generating full split: 100%"
          }
        },
        "e5bce30fc9aa445ea1f9eff7fe3c8fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3372f832d4684e5694186e07ee9f41db",
            "max": 597,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cfd471131a9480ca2f6a1f03cc58b4b",
            "value": 597
          }
        },
        "70216732fe60473a8118a79ea0dc2809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e92c506a124fb0916d5247fb6cb3dc",
            "placeholder": "​",
            "style": "IPY_MODEL_b5eabc6edad74232804292aa15c3a3e0",
            "value": " 597/597 [00:00&lt;00:00, 13209.19 examples/s]"
          }
        },
        "dd2c9297725449af900d1c86f1cc64e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ed77c2289443c28ae98f8dd0a0d95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb5580e7e36420cbd5583b27970d8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3372f832d4684e5694186e07ee9f41db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cfd471131a9480ca2f6a1f03cc58b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58e92c506a124fb0916d5247fb6cb3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5eabc6edad74232804292aa15c3a3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f69abd2b846f4e8dbfc6ebd1e2e6c2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b11d1f2675409b814f89447be1de0c",
              "IPY_MODEL_ce5a877830c54adcaf7208a61208f5ce",
              "IPY_MODEL_e350ee0ea4fc4578a69b66aa27b5815d"
            ],
            "layout": "IPY_MODEL_01685039017f432c9cc2e998769a5590"
          }
        },
        "e5b11d1f2675409b814f89447be1de0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba3b110223142208d26e0c582296df0",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1ca6c6e258475f825e7324400ef753",
            "value": "full-00000-of-00001.parquet: 100%"
          }
        },
        "ce5a877830c54adcaf7208a61208f5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6ff8bf536a415f9a518286240996fc",
            "max": 138895217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1c26d6705a3414fb20be3d85f0a61bb",
            "value": 138895217
          }
        },
        "e350ee0ea4fc4578a69b66aa27b5815d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0070bd83ae147c9a5bf2d7085aa4264",
            "placeholder": "​",
            "style": "IPY_MODEL_de2425ca8acd4eefb3f10eef0f7949b9",
            "value": " 139M/139M [00:00&lt;00:00, 589MB/s]"
          }
        },
        "01685039017f432c9cc2e998769a5590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba3b110223142208d26e0c582296df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1ca6c6e258475f825e7324400ef753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6ff8bf536a415f9a518286240996fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c26d6705a3414fb20be3d85f0a61bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0070bd83ae147c9a5bf2d7085aa4264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2425ca8acd4eefb3f10eef0f7949b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db0e190e4605464fa519bc7d104bacc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f9f95a4887e4b33916efd1dbc139990",
              "IPY_MODEL_501db4bd5d0742b6bdfc419aeb3ac876",
              "IPY_MODEL_826076e50ea2415dbbe4d72b64e75ce7"
            ],
            "layout": "IPY_MODEL_5dc49e781c8c40bb8db59e1f7194cb82"
          }
        },
        "6f9f95a4887e4b33916efd1dbc139990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600fc74f7603423cad92a6828ef6c1cb",
            "placeholder": "​",
            "style": "IPY_MODEL_65f738a262854af3b099bd24670ed6cb",
            "value": "Generating full split: 100%"
          }
        },
        "501db4bd5d0742b6bdfc419aeb3ac876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31a0fd3f486c46fb8a59c8bfab05ef07",
            "max": 6809,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b2239240b424226b4d78e929d56f48a",
            "value": 6809
          }
        },
        "826076e50ea2415dbbe4d72b64e75ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad12db5383d445899837c8beb9b41df",
            "placeholder": "​",
            "style": "IPY_MODEL_ce3d22f4dc7d49df9671f601a594d89d",
            "value": " 6809/6809 [00:01&lt;00:00, 5711.07 examples/s]"
          }
        },
        "5dc49e781c8c40bb8db59e1f7194cb82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600fc74f7603423cad92a6828ef6c1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f738a262854af3b099bd24670ed6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31a0fd3f486c46fb8a59c8bfab05ef07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2239240b424226b4d78e929d56f48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ad12db5383d445899837c8beb9b41df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3d22f4dc7d49df9671f601a594d89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d70c454fe9a46e7b80d833aeb8b7f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e99192fc13149b2b5b9dada0c4849fa",
              "IPY_MODEL_859dc71efe8849acb51b091de10e9805",
              "IPY_MODEL_2f4fbcd61d484060bd8937998069b399"
            ],
            "layout": "IPY_MODEL_02358bd7243246b3a0cfa285903aa5e9"
          }
        },
        "3e99192fc13149b2b5b9dada0c4849fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4384cc0312d74ce793bf1de884d06635",
            "placeholder": "​",
            "style": "IPY_MODEL_b79477e76a1a44f3bab9b6c891404908",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "859dc71efe8849acb51b091de10e9805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d5473f9165f4136ba676bc81a2a38d7",
            "max": 1381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b20a956d9774f549677d512aa7a6dd9",
            "value": 1381
          }
        },
        "2f4fbcd61d484060bd8937998069b399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89e2851a3624fa59897e7ae03e92c64",
            "placeholder": "​",
            "style": "IPY_MODEL_b35ca3f53e744718b35fc0e2fbaa79c2",
            "value": " 1.38k/1.38k [00:00&lt;00:00, 168kB/s]"
          }
        },
        "02358bd7243246b3a0cfa285903aa5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4384cc0312d74ce793bf1de884d06635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79477e76a1a44f3bab9b6c891404908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d5473f9165f4136ba676bc81a2a38d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b20a956d9774f549677d512aa7a6dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a89e2851a3624fa59897e7ae03e92c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35ca3f53e744718b35fc0e2fbaa79c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30009e0be0f404eb84a6d40c63b393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57928e9fffea47189efa6a7784b71f33",
              "IPY_MODEL_d267252d469e4809bdeeb8f8d61d9ee2",
              "IPY_MODEL_0fca6f4f3e47491aabcc62d32bb4f3dd"
            ],
            "layout": "IPY_MODEL_43fcc3ed59ff4fe588b900f23f40a93f"
          }
        },
        "57928e9fffea47189efa6a7784b71f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f726e131aab74cd4a90b89ef897d1eab",
            "placeholder": "​",
            "style": "IPY_MODEL_47c26844c2c4454ebf023cf8f148f917",
            "value": "vocab.txt: 100%"
          }
        },
        "d267252d469e4809bdeeb8f8d61d9ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12918d8dfe614a7789688927bb0e8af6",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2220f10efe0431da07265b82efb1ac1",
            "value": 231508
          }
        },
        "0fca6f4f3e47491aabcc62d32bb4f3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9108e803ebf449d8b8d6d98cadb3f566",
            "placeholder": "​",
            "style": "IPY_MODEL_36da8dc89a8649bca724876f2647e4f7",
            "value": " 232k/232k [00:00&lt;00:00, 20.7MB/s]"
          }
        },
        "43fcc3ed59ff4fe588b900f23f40a93f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f726e131aab74cd4a90b89ef897d1eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c26844c2c4454ebf023cf8f148f917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12918d8dfe614a7789688927bb0e8af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2220f10efe0431da07265b82efb1ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9108e803ebf449d8b8d6d98cadb3f566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36da8dc89a8649bca724876f2647e4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb8b316142ba42f7ac2b87d4dad2874d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0343ce9951e642ec81d6098f622b3a9b",
              "IPY_MODEL_d7e59042f83e41738ab2cbe3337f63f5",
              "IPY_MODEL_41ae86e17c7c4df0b476400975b74afc"
            ],
            "layout": "IPY_MODEL_ff2299f9da0d4367bbf891b0dadf6db8"
          }
        },
        "0343ce9951e642ec81d6098f622b3a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de538346e24449ab69a24acf0762429",
            "placeholder": "​",
            "style": "IPY_MODEL_69b920353f9a4e06905e10a989c8e442",
            "value": "tokenizer.json: 100%"
          }
        },
        "d7e59042f83e41738ab2cbe3337f63f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710ca86fc79a495393fc4e2066e90622",
            "max": 711649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e005087cd76c4d3f846dbfd4ec1e56d5",
            "value": 711649
          }
        },
        "41ae86e17c7c4df0b476400975b74afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2006aae016e45268d8d3427ba662cee",
            "placeholder": "​",
            "style": "IPY_MODEL_651a7a0242bf4a8d99e82a53e0351cc8",
            "value": " 712k/712k [00:00&lt;00:00, 1.12MB/s]"
          }
        },
        "ff2299f9da0d4367bbf891b0dadf6db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de538346e24449ab69a24acf0762429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b920353f9a4e06905e10a989c8e442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710ca86fc79a495393fc4e2066e90622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e005087cd76c4d3f846dbfd4ec1e56d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2006aae016e45268d8d3427ba662cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651a7a0242bf4a8d99e82a53e0351cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f2214864b2a4ea4b4033ae4f5723f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d522834ea7074fe59d9e0d394aaa9361",
              "IPY_MODEL_05fb22912eec43f696e470ab495cf565",
              "IPY_MODEL_0bfc424e7cb44a11b441d712350f2127"
            ],
            "layout": "IPY_MODEL_181392c6abab4fa5b03cca7c668c53b3"
          }
        },
        "d522834ea7074fe59d9e0d394aaa9361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02399f13e84c4e38aabbeb5124ff0635",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8c7d5aa1774ab88df502a4005995d0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "05fb22912eec43f696e470ab495cf565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118aeaf5ef2b4fee9b11b5a8103ddb3d",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bfc4bb75cd643cfb3f00eb30fb01267",
            "value": 695
          }
        },
        "0bfc424e7cb44a11b441d712350f2127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_630766a673734413b7f525c544b9fd61",
            "placeholder": "​",
            "style": "IPY_MODEL_82174f3de69144c9913e4be3f29c1075",
            "value": " 695/695 [00:00&lt;00:00, 68.0kB/s]"
          }
        },
        "181392c6abab4fa5b03cca7c668c53b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02399f13e84c4e38aabbeb5124ff0635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8c7d5aa1774ab88df502a4005995d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "118aeaf5ef2b4fee9b11b5a8103ddb3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bfc4bb75cd643cfb3f00eb30fb01267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "630766a673734413b7f525c544b9fd61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82174f3de69144c9913e4be3f29c1075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9c55dcaab0f428da74a096501d36f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c35c5508d054e0d8ebf5f9af4f12afb",
              "IPY_MODEL_2e9047aaa9ab4b6e99101b4084d49cec",
              "IPY_MODEL_9e25bda7b3934553a07e1fd52725ffde"
            ],
            "layout": "IPY_MODEL_d203acf8d29244ceb4afb97e941f6e8e"
          }
        },
        "7c35c5508d054e0d8ebf5f9af4f12afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae678fa439f44ff69d940f61a1508f6a",
            "placeholder": "​",
            "style": "IPY_MODEL_388af9942abc46c99a4c63c046741046",
            "value": "config.json: 100%"
          }
        },
        "2e9047aaa9ab4b6e99101b4084d49cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9758054106445168a28ce3fc1da0faf",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65702fb60b71410a96829926168f6d59",
            "value": 772
          }
        },
        "9e25bda7b3934553a07e1fd52725ffde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c912bbba6977417189d92836cc9e86e0",
            "placeholder": "​",
            "style": "IPY_MODEL_a3e122e22b074eceac451d429261c1db",
            "value": " 772/772 [00:00&lt;00:00, 65.6kB/s]"
          }
        },
        "d203acf8d29244ceb4afb97e941f6e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae678fa439f44ff69d940f61a1508f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388af9942abc46c99a4c63c046741046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9758054106445168a28ce3fc1da0faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65702fb60b71410a96829926168f6d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c912bbba6977417189d92836cc9e86e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e122e22b074eceac451d429261c1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6269d203444f1c9778e76556031696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c175b38a5f7b4123a710a451aa5b07e4",
              "IPY_MODEL_6a49a522b5da48c69ee7725d0d982528",
              "IPY_MODEL_716c6840e54e4b6da5c4d14e35edc5de"
            ],
            "layout": "IPY_MODEL_6bad71359a26408d91d4b096424da629"
          }
        },
        "c175b38a5f7b4123a710a451aa5b07e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_607e584345024c2ba19e252119b04480",
            "placeholder": "​",
            "style": "IPY_MODEL_dff6f145b72d47368617c655027ac566",
            "value": "model.safetensors: 100%"
          }
        },
        "6a49a522b5da48c69ee7725d0d982528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dae130973664dbeaa54e88e8cf8371b",
            "max": 435588776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b9478d9ba92411295527777a38c3e39",
            "value": 435588776
          }
        },
        "716c6840e54e4b6da5c4d14e35edc5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3f8150bd00040e5a9c8eb5b2e0e85d7",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5986557aa0408e9bf959c07deb6589",
            "value": " 436M/436M [00:00&lt;00:00, 588MB/s]"
          }
        },
        "6bad71359a26408d91d4b096424da629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607e584345024c2ba19e252119b04480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dff6f145b72d47368617c655027ac566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dae130973664dbeaa54e88e8cf8371b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9478d9ba92411295527777a38c3e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3f8150bd00040e5a9c8eb5b2e0e85d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5986557aa0408e9bf959c07deb6589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}