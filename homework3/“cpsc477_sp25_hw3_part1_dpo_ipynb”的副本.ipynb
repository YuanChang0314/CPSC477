{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnJjA5VQ5_df"
      },
      "source": [
        "# CPSC 477/577 Spring 2025, HW3\n",
        "## Part 1- Direct Preference Optimization\n",
        "\n",
        "Yale University  \n",
        "Spring 2025  \n",
        "Instructor: Arman Cohan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBvunjY6H6X"
      },
      "source": [
        "# Goal\n",
        "\n",
        "#### The goal of this homework assignemnt is to help students understand how to fine-tune language models with preference feedback using the Direct Preference Optimization (DPO) framework. You will also learn how to implement a training pipeline for language models.\n",
        "\n",
        "**Acknolwedgement** _The assignment is designed by TA Yilun Zhao and former TA Kejian Shi, with help and guidance from Arman Cohan and Yixin Liu.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tzZsUFg6Kli"
      },
      "source": [
        "### Submission Instructions\n",
        "\n",
        "Submit the notebook as a .ipynb file through GradeScope.\n",
        "\n",
        "Make sure that the notebook is running without any errors before submission. Remove any unnecessary outputs or additional `print` or debugging statements that you put in the code before submission.\n",
        "\n",
        "### Write your name and NetID below.\n",
        "\n",
        "**Name:**    Yuan Chang\n",
        "\n",
        "**NetID:**   yc2238\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRNt5RNemFOT"
      },
      "source": [
        "### Install and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COL-Xcy36Gz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "25637644-a982-4673-c2f2-508ecb889ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9c65e7c2bd72d1c829bcbd6ccfc37667ae6e8349772c2a1a41e3581e25ac95bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: xxhash, fsspec, dill, rouge-score, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 rouge-score-0.1.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets gdown rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWq_X2vy0EQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107ede9d-0188-41d4-dcd9-d9774b482269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "from rouge_score import rouge_scorer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from typing import Dict, Union, List, Tuple, Optional\n",
        "from transformers.models.deberta_v2.modeling_deberta_v2 import (\n",
        "    DebertaV2PreTrainedModel,\n",
        "    DebertaV2Model,\n",
        "    SequenceClassifierOutput\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlxdoJlW6fxX"
      },
      "source": [
        "### GPU requirement\n",
        "This notebook requires at least 15Gb of GPU memory (e.g. a T4 GPU on Google Colab).\n",
        "You are able to run the notebook on colab for free but you are also encouraged to use the Grace HPC cluster if you have issues with T4 GPUs. If you are using MacBook Pro with M1 chip or later, you can also try running on your own local machine using the `mps` device backend. We have provided the code for this below.\n",
        "\n",
        "If you want to use `mps` please follow installation instructions below:\n",
        "\n",
        "```\n",
        "# Only run this if you are using Apple Silicon M1 chip or later with 18Gb of RAM\n",
        "pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
        "```\n",
        "\n",
        "More information about installation:  ```https://developer.apple.com/metal/pytorch/```  \n",
        "\n",
        "### Using GPU in Colab\n",
        "PyTorch and other deep learning libraries are much faster using GPU acceleration. Similar to the previous assignment, we will use GPU runtime to train and evaluate models.\n",
        "\n",
        "Go to Runtime option on the top left\n",
        "Click Change runtime type\n",
        "Select \"GPU\" for Hardware accelerator\n",
        "Click SAVE button\n",
        "However, Colab limits the amount of time that you can use a free GPU. So you may wish to implement much of the assignment without the GPU. But note that you will have to run all cells again once you change the runtime type.\n",
        "\n",
        "Let's first verify which device you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmh088qX0ENU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97da5410-9641-46dd-e393-0cb726f6c77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPS not available because the current PyTorch install was not built with MPS enabled.\n",
            "Warning: You are using CPU. For better performance, use GPU.\n",
            "Pytorch version is:  2.6.0+cu124\n",
            "You are using:  cpu\n"
          ]
        }
      ],
      "source": [
        "# set the device\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "else:\n",
        "    if not torch.backends.mps.is_built():\n",
        "        print(\"MPS not available because the current PyTorch install was not \"\n",
        "              \"built with MPS enabled.\")\n",
        "    else:\n",
        "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
        "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"Warning: You are using CPU. For better performance, use GPU.\")\n",
        "print(\"Pytorch version is: \", torch.__version__)\n",
        "print(\"You are using: \", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ro9ir92bDcr"
      },
      "source": [
        "### Setting up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8VNN-OH0EJ-"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.enabled = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "elif torch.backends.mps.is_available():\n",
        "    torch.mps.manual_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXqJLk6l9jd"
      },
      "source": [
        "Setting up data directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMHqLYQ00EGh"
      },
      "outputs": [],
      "source": [
        "!mkdir -p cache\n",
        "!mkdir -p data\n",
        "!mkdir -p data/dpo_origin\n",
        "!mkdir -p data/dpo\n",
        "!mkdir -p data/sft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tiwyy3UbIlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66cac59-3cd7-4f1e-9d68-899d8c4233c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15BpDzxPRGW8cpIbVheJbbKPBDbp5LQdV\n",
            "To: /content/dpo_data.zip\n",
            "\r  0% 0.00/2.58M [00:00<?, ?B/s]\r100% 2.58M/2.58M [00:00<00:00, 177MB/s]\n",
            "Archive:  dpo_data.zip\n",
            "  inflating: data/dpo_origin/train.jsonl  \n",
            "  inflating: data/dpo_origin/.DS_Store  \n",
            "  inflating: data/dpo_origin/val.jsonl  \n",
            "  inflating: data/sft/test.jsonl     \n"
          ]
        }
      ],
      "source": [
        "!gdown \"https://drive.google.com/uc?id=15BpDzxPRGW8cpIbVheJbbKPBDbp5LQdV\" -O dpo_data.zip\n",
        "!unzip -o dpo_data.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKwcS_4nbZJL"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGFP2BEUngKb"
      },
      "source": [
        "In this assignment, you will explore and implement the Direct Preference Optimization (DPO) algorithm for fine-tuning language models. DPO is a powerful technique that leverages preference data to guide the model towards generating more desirable outputs. By comparing the model's generated responses with expert (human-written or strong-llm-written) references, DPO aims to align the model's behavior with user preferences.\n",
        "\n",
        "We will provide you with an SFT model (reference model), which is a [GPT-2-small](https://huggingface.co/openai-community/gpt2) (124M parameters) fine-tuned on the famous [tulu-v2-sft-mixture](https://huggingface.co/datasets/allenai/tulu-v2-sft-mixture) dataset.\n",
        "\n",
        "\n",
        "We have further trained this reference model using DPO for a certain number of iterations, resulting in an instructor's version of the DPO model. The DPO data chosen is the AI2 [UltraFeedback](https://huggingface.co/datasets/allenai/ultrafeedback_binarized_cleaned) dataset, which will be provided to you via `gdown`. The dataset is annotated by GPT-4, a powerful model that has undergone heavy alignment tuning. So we expect the data to be of high quality.\n",
        "\n",
        "Your task is to build upon the provided DPO model and implement the training loop and loss function to further fine-tune the model using an additional set of training examples from the same dataset (UltraFeedback). You will be provided with the necessary code templates and guidelines to complete the implementation.\n",
        "\n",
        "After successfully fine-tuning the model, you will evaluate and compare the performance of three models:\n",
        "\n",
        "1. The instructor's gpt2-SFT model\n",
        "2. The instructor's DPO model\n",
        "3. Your further fine-tuned DPO model\n",
        "\n",
        "We hope you will gain insights into the effectiveness of DPO in improving the model's performance and aligning its outputs with human preferences. Although, leveraging the full potential of DPO requires a large amount of preference data, large models, and extensive computational resources, which is beyond the scope of this assignment.\n",
        "\n",
        "We encourage you to actively engage with the provided materials, ask questions, and explore the concepts thoroughly.\n",
        "\n",
        "You may find the following material useful, among many others:\n",
        "\n",
        "* [The DPO paper](https://arxiv.org/abs/2305.18290)\n",
        "* [A HuggingFace blog post](https://huggingface.co/blog/pref-tuning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbvsZsaxXLjc"
      },
      "source": [
        "## DPO Recap\n",
        "\n",
        "\n",
        "Recall that DPO bypasses the conventional reinforcement learning (RL) reward modeling phase in NLP (e.g., the [PPO algorithm](https://arxiv.org/abs/1707.06347)), by directly optimizing the policy language model using pairwise preference data.\n",
        "\n",
        "Note: Following the notation in the original [paper](https://arxiv.org/pdf/2305.18290.pdf), we use $y_w$ and $y_l$ to denote the `chosen` or `preferred` and the `rejected` or `dispreferred` completion amongst a pair of responses ($y_1$, $y_2$), respectively.\n",
        "\n",
        "\n",
        "Within the framework of RLHF (Reinforcement Learning From Human Feedback), DPO's pipeline involves:\n",
        "\n",
        "\n",
        "\n",
        "1. Sample responses $y_1, y_2 \\sim \\pi_{\\text {ref }}(\\cdot \\mid x)$ from the model for given input prompts $x$. Then, we get human preferences to label $y_w$ and $y_l$, where $y_w > y_l \\mid x$. This process results in an offline dataset of preferences, $\\mathcal{D}=\\left\\{x^{(i)}, y_w^{(i)}, y_l^{(i)}\\right\\}$.\n",
        "\n",
        "2. Optimize the policy (model) $\\pi_\\theta$ by minimizing the DPO loss $\\mathcal{L}_{\\mathrm{DPO}}$ for a given reference model $\\pi_{\\text {ref }}$, $\\mathcal{D}$, and $\\beta$, which is a hyperparameter that controls the deviation from $\\pi_{\\text {ref }}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlQs1qwvjBYw"
      },
      "source": [
        "## Prompting the base and SFT models\n",
        "\n",
        "#### Load the raw `gpt2` model (the smallest version, 124M parameters) and prompt it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNALqErqjBYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "13c309ce925642a195749ba9b5139b38",
            "3b6bba9706bb451893912b4bc2dad18b",
            "ac38a5b95b0a4466828d8be87b96ec6e",
            "656470a38f5745ff8981dc2b58911e2c",
            "50b78d7f4fe748f8a7d934589511199d",
            "ac6df29ec22e4e53a0fd6d75bf2e94b4",
            "d1552abbedf84ffea7622bea0dfa68ef",
            "2fecaf92b2ee4208a749d8239cc57c4a",
            "6390eb7d405d425abcabc0e15008e654",
            "604b727fe88b4edc9d02d748f6befa10",
            "2d1ec0436b25459e8236751b9f8c3d2f",
            "922f882880ac4c3c8f57f2bef471864b",
            "dda7dd34479a4cc289b141584c1bf478",
            "834cffbf67654c5da8d1271fd7e08dd3",
            "84b71fd967af46a1826224cca3fadf78",
            "ea9412f13f814c8b97febbbf4c4a6362",
            "109fed2523bd414fa0f23e4d21d1c786",
            "7a576e4d062e4d46b9ad1d8b7042af52",
            "fa7fac67ed3c465e9d1dad39878d9c4a",
            "d117219398b14288be6531c11f3a352a",
            "a6e342e629ab488b8ffa78cf7bfcafca",
            "511913fc78bf411e9958a44ba5e6657c",
            "6fe1babf454c47cb90fcc195085c87a2",
            "9a801a44da1e44f6b02e0745865df7a1",
            "86ab738c35c545d99ed8b4ac5e7581da",
            "89d1502bedbd4839bd9eb00fc3132cef",
            "8e17ec8b15ef427291b52336faecfe7a",
            "faa5cb22f56e4ca6b64e36981969af21",
            "be47362e1c104674a1ce6852aa300103",
            "565135e46aae49ca9750f00527a1e800",
            "472f791eceae40238491e9d0dbaca354",
            "0acca70e9f2d4a5e94fae7577971a298",
            "639b36c90df74193b2ece56d6bd57b04",
            "72bc4ccbc37d4e0fa7fbb529960d4949",
            "93533b123aa44386adf609a0a68ebdb0",
            "91b2cc60799642669794f9d8bf7281e1",
            "6bc190d4a89d4d55a6129cf1964befd5",
            "865173e685f34693af8fc53141cf0540",
            "33ecef39a7234d26a7606e0aaa4ebac1",
            "502d54457481475dab502cb8a4868121",
            "bd19ae7ccfcd470b9840af0d14886b18",
            "d74358e28e554603b23f401e6b60c278",
            "4c33f0c39b674627a8d19fc640ab81f5",
            "f42ac9b691e44d8f91a28779a49d435d",
            "71d50995ffee4c028b53b104693e3ef6",
            "f37cb54f46ef478f8272271d1c80ed8b",
            "ab6056ab7be849858ebc6a1d98416311",
            "1fb431d1410543188edee142a8469038",
            "8e857e434ac24b09941038f381a6685e",
            "3507c3d609f74c2aa38962bef09f9ad0",
            "14a801bead57438784f9ad3c97b290f3",
            "769c58d9a41941c08bde97a5ddc83c16",
            "4e067f878a4747aa8adff137c8d525b9",
            "9b3bd824ec1e44a2b4d1f26d2f4b7928",
            "8706b37a767b4e0490341a8d650dde65",
            "9cb53f93d06a43c99a96c66f6075dbcc",
            "f89b3b9926274542ba7a100b17cffda0",
            "92440828eacb4d8297d7ecc1f5d91c14",
            "d7f4e24963fb4b7b8cce5947778d8ecf",
            "902f793467df423292182668322a7b9c",
            "6be4a9cebe0a42dea30dd8fc28d3e566",
            "b06e408ad1ca465086ebfbd21cb60ae3",
            "875d9e81c1c94bb0b4c76467f5365077",
            "e36906551c9043c69913e90102e8b6f8",
            "31902cd39aef4280918458971f64deca",
            "35543e63134944c091e871c2e4760309",
            "bcbf9b10ecb6424f8f7fd03834f58a14",
            "4af6fff7cbe743dfb406c2ddadee7800",
            "0a986efcd64e489a977f841e01781f61",
            "5476cf66bc714ba981d60a0e4c99c980",
            "e6da138704b44f2ab50174d5579e709f",
            "1d4b6cb98533499f821eeb96fa6cd234",
            "e75a03cac300428ca72720177613492a",
            "e99dd91967e44a629ff53d174683be15",
            "d5a42f2f68d740618c96eed57d9ac751",
            "567378cbb25545aaae5673de9aa2452a",
            "fa4f397614cc49ff98de3ee8db9a6a80",
            "914a092605454f5b85b2b2c1a3187630",
            "c8559af622a34e19b22ebe88b7eccba3",
            "83e8035c60024ef88a2159a8ac20699e",
            "0793038799bb41808518355711e47479",
            "8f2e6ec4fcbc4acdb16ef3f87767ff2f",
            "68a609724bea494eab7eb9382f65bdfe",
            "e663da1939544c729a5b47112f4813ab",
            "31d354b20944484bb12974a7cfdd83e8",
            "05331e0684de4fcd8e6c584a688cee6c",
            "6786c5f785b14d84aefdecc5e59caf74",
            "4fc051da5a284325be0d69d09b60e61a"
          ]
        },
        "outputId": "8fbd40c9-0ed7-446f-9fff-3d66efb82c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13c309ce925642a195749ba9b5139b38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "922f882880ac4c3c8f57f2bef471864b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fe1babf454c47cb90fcc195085c87a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72bc4ccbc37d4e0fa7fbb529960d4949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71d50995ffee4c028b53b104693e3ef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cb53f93d06a43c99a96c66f6075dbcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcbf9b10ecb6424f8f7fd03834f58a14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "914a092605454f5b85b2b2c1a3187630"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "raw_model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')  # load the tokenizer\n",
        "raw_model = AutoModelForCausalLM.from_pretrained(raw_model_name).to(DEVICE)\n",
        "\n",
        "prompt = \"Q: Give me some options for healthy foods. \\nA: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A83lI5bjb2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed69a624-e9f3-474e-8564-97be62d05c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Give me some options for healthy foods. \n",
            "A:  I'm not sure if I can give you a list of all the options I have. \n",
            "Q:  What are some of the things you like about eating healthy? \n",
            "A:  I like to eat healthy.\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "output = raw_model.generate(input_ids,\n",
        "                            max_length=64,\n",
        "                            pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# TODO: decode the output\n",
        "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo2k-13D4skc"
      },
      "source": [
        "#### Load our SFT model and make it say something"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzwnxxm4H3Eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7dac8f2f0d6f45ab9aea1de469c87e4a",
            "d9cd8230543241deb35655f4e3df777a",
            "9c6a3a96483344d1b2f44a789a34a8e6",
            "29c7fb552be244c6a00842c3c9e029a1",
            "71e41bd3cff743d88ab79d8e02a0c6f1",
            "8ee2c09caabe4a1e83844e51cf3cdc38",
            "494be213b16e489e8216e33b561efa88",
            "a6b7ddec0e4d46bca2b96f494be95258",
            "f341b60f7545434389f6bdfa3a403a88",
            "6a015b7e60654a3dbe457634790ee6c4",
            "6a4f05bf5ee240058135c3f5ef5e5a2b",
            "ddccbf4d430348378f2fdc216e1d780d",
            "01655f7e78754dcf9dd643483c282182",
            "5ab3287800a347ceb6d45809623fbab8",
            "a7ffbe705b6042d18411e1b4c912aeec",
            "874d3835eaa949ce83bb87cab5ff9a39",
            "ff54cfdd785e484bb6853511c524b80e",
            "f1d2a653c0c24686a398c571cdcc0e14",
            "c7107ebccd3146b5bd4366053f79b3af",
            "60b0f919d96a49fca7a037689b0105a9",
            "899c2bcee1c849c7afde15beca5085f6",
            "4ae3961f264c40079022e3f3b2b91845",
            "9e5f6e5b48224885b0485ad6bd9e3c70",
            "57a4f59bd72b4cbd9855d4405ca60093",
            "37ba13dd3a2d48efb8cbcdbfd6a07ad9",
            "7cd4c3078e2e4b4e958b04ef3e9bbbad",
            "9fd1c020dbca4875af2ca6be3002d928",
            "eddb5bd5988b48c18392afdd2b65ba94",
            "5824ca39f78241eca0a8b7087e0af7de",
            "859f03fae0b240868e0466d60d2d3581",
            "6349ecf35f594fd3966c2db448c49b75",
            "4c3004e326374e1a83ee11ae80d7076f",
            "9dec09bf8ab048a9be72945f7ed76083"
          ]
        },
        "outputId": "d997df63-b2f7-43d3-d74a-bd3d6d8d3b01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/907 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dac8f2f0d6f45ab9aea1de469c87e4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddccbf4d430348378f2fdc216e1d780d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e5f6e5b48224885b0485ad6bd9e3c70"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_sft_name = \"kejian/gpt2-instruct-tulu2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')  # load the tokenizer\n",
        "model_sft = AutoModelForCausalLM.from_pretrained(model_sft_name).to(DEVICE)  # load the reference model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoZkWh8C5KIP"
      },
      "source": [
        "Recall that SFT models generally are trained to respond to prompts (or instructions) and they are better at this compared with the base models.\n",
        "In SFT, the data is transformed to include the instructions such as the following format:\n",
        "\n",
        "\n",
        "```\n",
        "Instruction: {input}.strip()\n",
        "Response: {output}\n",
        "```\n",
        "We should accordingly format our prompt in the same fashion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk4mZss30D4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd20b9d-4a6d-463d-9e84-a856bfca4ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction: Give me some options for healthy foods.\n",
            "Response: \n",
            "1. Choose a healthy food source: Eating a healthy food source can help you feel more healthy and feel more connected to your body. Here are some options:\n",
            "1. Choose a healthy food source: Eating a healthy food source can help\n"
          ]
        }
      ],
      "source": [
        "input = \"Give me some options for healthy foods.  \"\n",
        "formatted_input = f\"Instruction: {input.strip()}\\nResponse: \"\n",
        "\n",
        "input_ids = tokenizer.encode(formatted_input, return_tensors=\"pt\").to(DEVICE)\n",
        "output = model_sft.generate(input_ids,\n",
        "                            max_length=64,\n",
        "                            pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# TODO: decode the output\n",
        "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfvRGeHcbpbI"
      },
      "source": [
        "#### Question 1 - How does the output of the SFT model differ from the base model (1 ~ 2 sentences)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCqz2OLqMuow"
      },
      "outputs": [],
      "source": [
        "response = \"gpt response is question answer based while sft is giving the answer sequencially\" # TODO: Write your answer here\n",
        "\n",
        "assert response != \"\", \"Please write your answer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh7YqlfnkqDr"
      },
      "source": [
        "Chances are you prefer the instruction-tuned model over the base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxVPDqKKMzx7"
      },
      "source": [
        "## Define data classes and collators\n",
        "\n",
        "To train models in Pytorch, we need to first define and implement the data pipeline. The data pipeline consists of a dataset class (that is inherited from the Pytorch Dataset class). The dataset class is responsible for loading the data and returning the data samples. The data samples are then passed to a collator, which is responsible for batching the data samples and converting them into a batch of tensors.\n",
        "\n",
        "Concretely, the dataset class should implement the following methods:  \n",
        "`__len__`: returns the number of samples in the dataset  \n",
        "`__getitem__`: returns a sample from the dataset  \n",
        "\n",
        "Optionally we can implement a `collator` function that does additional preprocessing, batching, padding, etc. that is applied to the samples before they are passed to the model. The collator function is used by the Pytorch DataLoader class to create batches of data samples.\n",
        "\n",
        "We provide the classes and functions to you. Please read the code carefully and then run the following cell. You shoul familiarize yourself with how to write Dataset classes for a model.\n",
        "\n",
        "#### In later section of the notebook, you will implement a `DPOGPTDataset` class and a collator function for training your model.\n",
        "\n",
        "If you haven't trained a model before, we encourage you to carefully examing the code in the following cell and understand how the data pipeline is implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGCGEPRd2fxI"
      },
      "outputs": [],
      "source": [
        "class SFTGPTDataset(Dataset):\n",
        "    def __init__(self, data, model_type, max_len=1024, is_test=False):\n",
        "        \"\"\" data format: article, abstract, [(candidiate_i, score_i)] \"\"\"\n",
        "        self.data = data\n",
        "        self.tok = AutoTokenizer.from_pretrained(model_type, verbose=False)\n",
        "        self.tok.pad_token = self.tok.eos_token\n",
        "        self.tok.pad_token_id = self.tok.eos_token_id\n",
        "        self.max_len = max_len\n",
        "        self.is_test = is_test\n",
        "        self.num = len(self.data)\n",
        "        self.SRC_MARKER = \"Instruction: \"\n",
        "        self.TGT_MARKER = \"\\nResponse: \"\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        src_txt = self.SRC_MARKER + data[\"instruction\"].strip() + self.TGT_MARKER\n",
        "        data[\"instruction\"] = src_txt\n",
        "        src = self.tok([src_txt], return_tensors=\"pt\", padding=\"longest\", truncation=False)\n",
        "        src_input_ids = src[\"input_ids\"]\n",
        "        src_input_ids = src_input_ids.squeeze(0)\n",
        "        text = src_txt + data[\"response\"].strip()\n",
        "        encoded = self.tok([text], return_tensors=\"pt\", padding=\"longest\", truncation=False)\n",
        "        input_ids = encoded[\"input_ids\"]\n",
        "        input_ids = input_ids.squeeze(0)\n",
        "        assert input_ids.size(0) <= self.max_len - 1\n",
        "        # add eos token\n",
        "        input_ids = torch.cat([input_ids, input_ids.new_ones(1) * self.tok.eos_token_id])\n",
        "        # we only need to train on the target part\n",
        "        masks = torch.zeros_like(input_ids)\n",
        "        masks[src_input_ids.size(0):] = 1\n",
        "        if self.is_test:\n",
        "            result = {\n",
        "                \"input_ids\": src_input_ids,\n",
        "                \"masks\": masks,\n",
        "            }\n",
        "        else:\n",
        "            result = {\n",
        "                \"input_ids\": input_ids,\n",
        "                \"masks\": masks,\n",
        "                }\n",
        "        if self.is_test:\n",
        "            result[\"data\"] = data\n",
        "        return result\n",
        "\n",
        "\n",
        "def collate_base_gpt(batch, pad_token_id, is_test=False):\n",
        "    def pad(X, padding, max_len=-1):\n",
        "        if max_len < 0:\n",
        "            max_len = max(x.size(0) for x in X)\n",
        "        result = torch.ones(len(X), max_len, dtype=X[0].dtype) * padding\n",
        "        attention_mask = torch.zeros(len(X), max_len, dtype=X[0].dtype)\n",
        "        for (i, x) in enumerate(X):\n",
        "            result[i, -x.size(0):] = x\n",
        "            attention_mask[i, -x.size(0):] = 1\n",
        "        return result, attention_mask\n",
        "\n",
        "    input_ids, attention_mask = pad([x[\"input_ids\"] for x in batch], pad_token_id)\n",
        "    masks, _ = pad([x[\"masks\"] for x in batch], 0)\n",
        "    if is_test:\n",
        "        data = [x[\"data\"] for x in batch]\n",
        "    result = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"masks\": masks,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        }\n",
        "    if is_test:\n",
        "        result[\"data\"] = data\n",
        "    return result\n",
        "\n",
        "\n",
        "class BaseDPOGPTDataset(Dataset):\n",
        "    def __init__(self, data, model_type, max_len=1024, is_test=False):\n",
        "        \"\"\" data format: article, abstract, [(candidiate_i, score_i)] \"\"\"\n",
        "        if isinstance(data, str):\n",
        "            with open(data) as f:\n",
        "                self.data = [json.loads(x) for x in f]\n",
        "        else:\n",
        "            self.data = data\n",
        "        self.tok = AutoTokenizer.from_pretrained(model_type, verbose=False)\n",
        "        self.tok.pad_token = self.tok.eos_token\n",
        "        self.tok.pad_token_id = self.tok.eos_token_id\n",
        "        self.max_len = max_len\n",
        "        self.is_test = is_test\n",
        "        self.num = len(self.data)\n",
        "        self.SRC_MARKER = \"Instruction: \"\n",
        "        self.TGT_MARKER = \"\\nResponse: \"\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num\n",
        "\n",
        "    def encode(self, src_len, text):\n",
        "        encoded = self.tok([text], return_tensors=\"pt\", padding=\"longest\", truncation=False)\n",
        "        input_ids = encoded[\"input_ids\"]\n",
        "        input_ids = input_ids.squeeze(0)\n",
        "        assert input_ids.size(0) <= self.max_len - 1\n",
        "        # add eos token\n",
        "        # if not self.is_test:\n",
        "        input_ids = torch.cat([input_ids, input_ids.new_ones(1) * self.tok.eos_token_id])\n",
        "        # we only need to keep the target part\n",
        "        masks = torch.zeros_like(input_ids)\n",
        "        masks[src_len:] = 1\n",
        "        return input_ids, masks\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        src_txt = self.SRC_MARKER + data[\"instruction\"].strip() + self.TGT_MARKER\n",
        "        data[\"raw_instruction\"] = data[\"instruction\"]\n",
        "        data[\"instruction\"] = src_txt\n",
        "        src = self.tok([src_txt], return_tensors=\"pt\", padding=\"longest\", truncation=False)\n",
        "        src_input_ids = src[\"input_ids\"]\n",
        "        src_input_ids = src_input_ids.squeeze(0)\n",
        "        chosen_input_ids, chosen_masks = self.encode(src_input_ids.size(0), src_txt + data[\"chosen\"].strip())\n",
        "        rejected_input_ids, rejected_masks = self.encode(src_input_ids.size(0), src_txt + data[\"rejected\"].strip())\n",
        "        result = {\n",
        "            \"chosen_input_ids\": chosen_input_ids,\n",
        "            \"chosen_masks\": chosen_masks,\n",
        "            \"rejected_input_ids\": rejected_input_ids,\n",
        "            \"rejected_masks\": rejected_masks,\n",
        "            }\n",
        "        if self.is_test:\n",
        "            result[\"data\"] = data\n",
        "            result[\"src_input_ids\"] = src_input_ids\n",
        "        return result\n",
        "\n",
        "\n",
        "def collate_base_dpo_gpt(batch, pad_token_id, is_test=False):\n",
        "    def pad(X, padding, max_len=-1, pad_side=\"left\"):\n",
        "        assert pad_side in [\"left\", \"right\"]\n",
        "        if max_len < 0:\n",
        "            max_len = max(x.size(0) for x in X)\n",
        "        result = torch.ones(len(X), max_len, dtype=X[0].dtype) * padding\n",
        "        attention_mask = torch.zeros(len(X), max_len, dtype=X[0].dtype)\n",
        "        for i, x in enumerate(X):\n",
        "            if pad_side == \"left\":\n",
        "                result[i, -x.size(0) :] = x\n",
        "                attention_mask[i, -x.size(0) :] = 1\n",
        "            else:\n",
        "                result[i, : x.size(0)] = x\n",
        "                attention_mask[i, : x.size(0)] = 1\n",
        "        return result, attention_mask\n",
        "\n",
        "    # pad chosen\n",
        "    chosen_input_ids, chosen_attention_mask = pad(\n",
        "        [x[\"chosen_input_ids\"] for x in batch], pad_token_id, pad_side=\"left\"\n",
        "    )\n",
        "    chosen_masks, _ = pad([x[\"chosen_masks\"] for x in batch], 0, pad_side=\"left\")\n",
        "\n",
        "    # pad rejected\n",
        "    rejected_input_ids, rejected_attention_mask = pad(\n",
        "        [x[\"rejected_input_ids\"] for x in batch], pad_token_id, pad_side=\"left\"\n",
        "    )\n",
        "    rejected_masks, _ = pad([x[\"rejected_masks\"] for x in batch], 0, pad_side=\"left\")\n",
        "\n",
        "    # concatenate\n",
        "    input_ids = torch.unbind(chosen_input_ids) + torch.unbind(rejected_input_ids)\n",
        "    attention_mask = torch.unbind(chosen_attention_mask) + torch.unbind(rejected_attention_mask)\n",
        "    masks = torch.unbind(chosen_masks) + torch.unbind(rejected_masks)\n",
        "\n",
        "    # right pad now\n",
        "    input_ids, _attention_mask = pad(input_ids, pad_token_id, pad_side=\"right\")\n",
        "    attention_mask, _ = pad(attention_mask, 0, pad_side=\"right\")\n",
        "    attention_mask = attention_mask * _attention_mask\n",
        "    masks, _ = pad(masks, 0, pad_side=\"right\")\n",
        "\n",
        "    result = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"masks\": masks,\n",
        "        \"attention_mask\": attention_mask,\n",
        "    }\n",
        "\n",
        "    if is_test:\n",
        "        result[\"data\"] = [x[\"data\"] for x in batch]\n",
        "        src_input_ids, src_input_mask = pad([x[\"src_input_ids\"] for x in batch], pad_token_id, pad_side=\"left\")\n",
        "        result[\"src_input_ids\"] = src_input_ids\n",
        "        result[\"src_input_mask\"] = src_input_mask\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld62ABSZbpbJ"
      },
      "source": [
        "## Question 2 - Given the provided code, answer the following questions:\n",
        "\n",
        "Q2.1 The `collate_base_gpt` and `collate_base_dpo_gpt` functions implement custom padding for batches of data. Describe how padding is applied to the input IDs and masks. What does the pad_side argument control in the collate_base_dpo_gpt function, and why might this be important?\n",
        "\n",
        "`TODO: the padding is applied by left padding. It takes the longest term of the input sentence and pad every tensor to that length with the model's pad_token_id when padding input_ids, and 0 when padding the binary masks.\n",
        "\n",
        "Q2.2 In the context of this code, what is the purpose of the attention mask (attention_mask) and how is it different from the masks (masks) used in the dataset classes?\n",
        "\n",
        "`TODO: attention mask is to tell the model which parameter is the one that the attention module should focus and which is padding, the mask is to tell the model where to calculate the loss, to let the model know to calculate the loss to the response.\n",
        "\n",
        "Q2.3 How does the output of the `__getitem__` method in the BaseDPOGPTDataset class change when `is_test` is set to `True`? What additional information is included in the result, and why might this be useful for testing?\n",
        "\n",
        "`TODO: When the istest be set to true, it add example's original text and  prompt to the dataset, makes it able to test the performance of the model.\n",
        "\n",
        "Q2.4 How do the dataset classes handle inputs of varying lengths, especially in terms of padding and truncation? Discuss the importance of dynamic input handling in the context of NLP models.\n",
        "\n",
        "`TODO: Truncation is set to false in our setting, padding is set to pad all the input to the maximum length in this batch. For sft is right padding while dpo is left padding. Those dynamic input handling allows the model to accurate and efficiently training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJhk8ZSkDelW"
      },
      "source": [
        "## Generate logits using reference (SFT) model:\n",
        "\n",
        "Generating logits is an important part of the DPO algorithm. We use the SFT model as a reference policy to generate the logits (log probabilities) of the chosen and rejected responses.\n",
        "\n",
        "The `compute_likelihood` function below will handle this step. It loads the SFT model, computes the logits for the chosen and rejected responses, and saves the results along with other relevant information.\n",
        "\n",
        "Finish the `#TODO`s and proceed to the following cells.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "913UaW02DAS2"
      },
      "outputs": [],
      "source": [
        "def compute_likelihood(model, tokenizer, device, src_dir, tgt_dir, batch_size=8, num_workers=2, max_len=1024):\n",
        "    \"\"\"\n",
        "    Compute the model-predicted likelihood for the chosen and rejected responses.\n",
        "\n",
        "    Args:\n",
        "        model (AutoModelForCausalLM): The reference model.\n",
        "        tokenizer (AutoTokenizer): The tokenizer associated with the model.\n",
        "        device (torch.device): The device to run the model on.\n",
        "        src_dir (str): The directory containing the source data.\n",
        "        tgt_dir (str): The directory to save the processed data.\n",
        "        batch_size (int): The batch size for data loading (default: 8).\n",
        "        num_workers (int): The number of worker processes for data loading (default: 4).\n",
        "        max_len (int): The maximum sequence length (default: 1024).\n",
        "\n",
        "    Steps:\n",
        "        1. Load the tokenizer and the pre-trained SFT model.\n",
        "        2. Load the dataset and create a DataLoader.\n",
        "        3. Iterate over the batches and compute the logits for the chosen and rejected responses.\n",
        "        4. Save the computed likelihoods along with other relevant information.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    dataset = load_dataset(\"json\", data_files=src_dir)[\"train\"]\n",
        "\n",
        "    dataset = BaseDPOGPTDataset(\n",
        "        dataset,\n",
        "        model_type=model.config.model_type,\n",
        "        max_len=max_len,\n",
        "        is_test=True,\n",
        "    )\n",
        "    collate_fn = partial(\n",
        "        collate_base_dpo_gpt, pad_token_id=tokenizer.pad_token_id, is_test=True\n",
        "    )\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with open(tgt_dir, \"w\") as f:\n",
        "            for batch in tqdm(dataloader, desc=\"Computing likelihoods\"):\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                # Compute the model output\n",
        "                output = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    output_hidden_states=False\n",
        "                )\n",
        "\n",
        "                output = output[0]\n",
        "                output = output[:, :-1]  # truncate last logit\n",
        "                labels = input_ids[:, 1:]  # shift labels\n",
        "\n",
        "                ### TODO: Compute the logits: 1 line\n",
        "\n",
        "\n",
        "                logits = torch.log_softmax(output, dim=-1)\n",
        "\n",
        "                logits = logits.gather(2, labels.unsqueeze(2)).squeeze(2) # GIVEN TO STUDENTS\n",
        "\n",
        "                ### TODO: Mask the prompt tokens and computing \\\n",
        "                ### the log probabilities only for the completion tokens ~3 lines\n",
        "                mask = batch[\"masks\"].to(device)[:, 1:]\n",
        "                logits = logits * mask\n",
        "                num_tokens = mask.sum(dim=1) # TODO: Complete this line # HIDE FROM STUDENTS\n",
        "\n",
        "                batch_size = logits.size(0) // 2\n",
        "                pos_logits, neg_logits = logits[:batch_size], logits[batch_size:]\n",
        "                pos_num_tokens, neg_num_tokens = num_tokens[:batch_size], num_tokens[batch_size:]\n",
        "\n",
        "                # Save the computed likelihoods along with other relevant information\n",
        "                for i in range(batch_size):\n",
        "                    data = batch[\"data\"][i]\n",
        "                    data[\"instruction\"] = data[\"raw_instruction\"]\n",
        "                    del data[\"raw_instruction\"]\n",
        "                    # TODO: Assigning values to proper keys - 4 lines\n",
        "                    # i.e. data['key'] = value\n",
        "                    data[\"chosen_log_likelihood\"]   = pos_logits[i].sum().item()\n",
        "                    data[\"rejected_log_likelihood\"] = neg_logits[i].sum().item()\n",
        "                    data[\"chosen_num_tokens\"]       = pos_num_tokens[i].item()\n",
        "                    data[\"rejected_num_tokens\"]     = neg_num_tokens[i].item()\n",
        "\n",
        "                    print(json.dumps(data), file=f, flush=True) # keep this line as it is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A6Hr4V9IF8p"
      },
      "source": [
        "#### Question 3: Why do we want to mask out the prompt part? What would change in the DPO loss if we do not mask out the prompt part?\n",
        "\n",
        "`TODO: We mask the prompt so that the loss is only for the response part. If we do not mask out the prompr the loss will be lower than the real value and waste the compute resourse\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNOvscXwWcpw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "648f1b68c7ab40acbcfd127c7a22ff4a",
            "6b56170f220645e58889bd05aa98aca2",
            "d6b684570ad5485aa51e3f05b792203f",
            "a4f98eb3cb5847aeb8bad32af172c782",
            "c447f7918da04a2d91e5e9ec18de47ed",
            "228f028aaf5b4db48b47ee9017e8b640",
            "ce783c984b0c47999f1b7fbcd871a3e0",
            "2a1cbd8ba7d846b8b3f0ea58f168a48d",
            "268c83ce865f46c5ac41ba12a121bd47",
            "ed2c6edea81c4574b05d823f742e4aea",
            "731a634afed94e74ad56765b7ce7766f"
          ]
        },
        "outputId": "ac1ab797-66c0-45b3-e023-e060bc243b3d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "648f1b68c7ab40acbcfd127c7a22ff4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing likelihoods:  38%|███▊      | 770/2000 [1:11:19<1:53:56,  5.56s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a67985328757>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msrc_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data/dpo_origin/{split}.jsonl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtgt_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data/dpo/{split}.jsonl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcompute_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_sft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-54ac5871000d>\u001b[0m in \u001b[0;36mcompute_likelihood\u001b[0;34m(model, tokenizer, device, src_dir, tgt_dir, batch_size, num_workers, max_len)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# Compute the model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 output = model(\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for split in [\"train\",\"val\"]:\n",
        "    src_dir = f\"data/dpo_origin/{split}.jsonl\"\n",
        "    tgt_dir = f\"data/dpo/{split}.jsonl\"\n",
        "    compute_likelihood(model_sft, tokenizer, DEVICE, src_dir, tgt_dir, batch_size=1, num_workers=2, max_len=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKlSmZJMWdwP"
      },
      "source": [
        "### Implementing DPO loss\n",
        "\n",
        "Recall DPO loss from the [paper](https://arxiv.org/pdf/2305.18290.pdf):\n",
        "\n",
        "Recalling the concept of DPO loss, the formula is given by\n",
        "$$\n",
        "\\mathcal{L}_{\\mathrm{DPO}}\\left(\\pi_\\theta ; \\pi_{\\mathrm{ref}}\\right)=-\\mathbb{E}_{\\left(x, y_w, y_l\\right) \\sim \\mathcal{D}}\\left[\\log \\sigma\\left(\\beta \\log \\frac{\\pi_\\theta\\left(y_w \\mid x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_w \\mid x\\right)}-\\beta \\log \\frac{\\pi_\\theta\\left(y_l \\mid x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_l \\mid x\\right)}\\right)\\right]\n",
        "$$\n",
        "Here, $\\sigma$ denotes the logistic function, $\\mathbb{E}$ is the expectation, $\\log \\frac{\\pi_\\theta\\left(y_w \\mid x\\right)}{\\pi_{\\text {ref }}\\left(y_w \\mid x\\right)}$ is the logarithm of the ratio of the probability of the chosen/preferred response $y_w$ according to the policy parameterized by $\\theta$ compared to the reference policy, and finally, $\\log \\frac{\\pi_\\theta\\left(y_l \\mid x\\right)}{\\pi_{\\text {ref }}\\left(y_l \\mid x\\right)}$ denotes the logarithm of the same probability ratio but for the dispreferred outcome $y_l$. The objective is to increase the likelihood of the chosen/preferred responses $y_w$ and decrease that of the rejected/dispreferred response $y_l$.\n",
        "\n",
        "Complete the code for `compute_dpo_loss()`. Note in the function signature, “chosen” means \"preferred\" and “rejected” means \"dispreferred\" completions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYmoU4Faz_Ec"
      },
      "outputs": [],
      "source": [
        "def compute_dpo_loss(policy_chosen_logps, policy_rejected_logps,\n",
        "                     reference_chosen_logps, reference_rejected_logps,\n",
        "                     beta = 0.1):\n",
        "\n",
        "    \"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\n",
        "\n",
        "    Args:\n",
        "        policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
        "        policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
        "        reference_chosen_logps: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\n",
        "        reference_rejected_logps: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\n",
        "        beta: Temperature parameter for the DPO loss\n",
        "\n",
        "    Returns:\n",
        "        A tuple of three tensors: (losses, chosen_rewards, rejected_rewards).\n",
        "        The losses tensor contains the DPO loss for each example in the batch.\n",
        "        The chosen_rewards and rejected_rewards tensors contain the rewards for the chosen and rejected responses, respectively.\n",
        "    \"\"\"\n",
        "    # Hint: Use F.logsigmoid()\n",
        "\n",
        "    # TODO: Implement the DPO loss computation\n",
        "    chosen_rewards  = policy_chosen_logps   - reference_chosen_logps\n",
        "    rejected_rewards = policy_rejected_logps - reference_rejected_logps\n",
        "    score_diff = beta * (chosen_rewards - rejected_rewards)\n",
        "    losses = -F.logsigmoid(score_diff)\n",
        "\n",
        "    return losses, chosen_rewards, rejected_rewards\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS_jrbiPLL23"
      },
      "source": [
        "#### Now, let's load the initial DPO model:\n",
        "\n",
        "Training the DPO model from scratch is computationally expensive. So, we provide you with an initial DPO model that has been trained starting from an SFT model additionally trained for a certain number of iterations on the UltraFeedback dataset using the DPO loss.\n",
        "\n",
        "You will further fine-tune this model on another 2k examples from the same dataset using DPO.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSYXbAUNbbKc"
      },
      "outputs": [],
      "source": [
        "dpo_model_name = \"kejian/gpt2-tulu2-DPO\"\n",
        "dpo_model = AutoModelForCausalLM.from_pretrained(dpo_model_name).to(DEVICE)  # load the initial DPO model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g_LKcQIAHha"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thokmiGGhRtK"
      },
      "source": [
        "Define the testing loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thiuc5NTmbxk"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, beta, device):\n",
        "    model.eval()\n",
        "    all_loss = 0\n",
        "    batch_cnt = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            input_ids = batch[\"input_ids\"]\n",
        "            attention_mask = batch[\"attention_mask\"]\n",
        "\n",
        "            output = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                output_hidden_states=False\n",
        "            )\n",
        "            output = output[0]\n",
        "            output = output[:, :-1]  # truncate last logit\n",
        "            labels = input_ids[:, 1:]  # shift labels\n",
        "            output = output.to(torch.float32)\n",
        "\n",
        "            # TODO: Compute the logits and mask the prompt parts; 4 ~ 6 lines\n",
        "            # This is the same as what you did for compute_likelihood(); You can copy over what you\n",
        "            logits = torch.log_softmax(output, dim=-1)\n",
        "            logits = logits.gather(2, labels.unsqueeze(2)).squeeze(2)\n",
        "            mask = batch[\"masks\"].to(device)[:, 1:]\n",
        "            logits = logits * mask\n",
        "            num_tokens = mask.sum(dim=1)\n",
        "            batch_size = logits.size(0) // 2\n",
        "            pos_logits, neg_logits = logits[:batch_size], logits[batch_size:]\n",
        "            pos_ref_logits = batch[\"chosen_logprob\"]\n",
        "            neg_ref_logits = batch[\"rejected_logprob\"]\n",
        "            loss, _, _ = compute_dpo_loss(pos_logits, neg_logits, pos_ref_logits, neg_ref_logits, beta)\n",
        "            loss = loss.mean()\n",
        "            all_loss += loss.item()\n",
        "            batch_cnt += 1\n",
        "\n",
        "    loss = all_loss / batch_cnt\n",
        "    model.train()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQpdeYmobpbQ"
      },
      "source": [
        "### Creating `DPOGPTDataset` class and the `collate_fn` pf dataloaders for DPO training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deF7vWYmbpbQ"
      },
      "outputs": [],
      "source": [
        "class DPOGPTDataset(BaseDPOGPTDataset):\n",
        "    \"\"\"\n",
        "    Dataset class for DPO (Direct Preference Optimization) training.\n",
        "\n",
        "    This class inherits from the BaseDPOGPTDataset class and adds functionality specific to DPO training.\n",
        "\n",
        "    TODO: Implement the __getitem__ method to retrieve the chosen and rejected log probabilities for each data point.\n",
        "    Hint: Use the superclass's __getitem__ method to get the base result and add something.\n",
        "    Hint: Look at run_dpo() below to see what is needed from a batch.\n",
        "    \"\"\"\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        # TODO: Implement this function\n",
        "        item = super().__getitem__(idx)\n",
        "        data = self.data[idx]\n",
        "        item[\"chosen_logprob\"] = torch.tensor(data[\"chosen_log_likelihood\"])\n",
        "        item[\"rejected_logprob\"] = torch.tensor(data[\"rejected_log_likelihood\"])\n",
        "        return item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def collate_dpo_gpt(batch, pad_token_id, is_test=False):\n",
        "    \"\"\"\n",
        "    This function collates a batch of data points and prepares them for DPO training.\n",
        "\n",
        "    TODO: Implement the collate_dpo_gpt function to collate the chosen and rejected log probabilities for each batch.\n",
        "    Hint: Use the collate_base_dpo_gpt function from the base class to get the base results and add something.\n",
        "    You should need no more than 5 lines of code.\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    result = collate_base_dpo_gpt(batch, pad_token_id, is_test)\n",
        "    result[\"chosen_logprob\"] = torch.stack([x[\"chosen_logprob\"] for x in batch])\n",
        "    result[\"rejected_logprob\"] = torch.stack([x[\"rejected_logprob\"] for x in batch])\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4uqpxnObpbQ"
      },
      "source": [
        "### The main training loop:\n",
        "\n",
        "The code below defines the main training loop for the DPO model.\n",
        "Read the following code carefully, run the cell, and then answer the following questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gl3aTVwEcRn"
      },
      "outputs": [],
      "source": [
        "def run_dpo(model, dataloader, val_dataloader, optimizer, device, epochs=1, accumulate_step=4,\n",
        "            report_freq=10, eval_interval=-1, max_lr=2e-3, warmup_steps=1000, beta=0.1, grad_norm=0):\n",
        "    \"\"\"\n",
        "    Run Direct Preference Optimization (DPO) training.\n",
        "\n",
        "    Args:\n",
        "        model (AutoModelForCausalLM): The i DPO model to be fine-tuned.\n",
        "        dataloader (DataLoader): The data loader for the training dataset.\n",
        "        val_dataloader (DataLoader): The data loader for the validation dataset.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer for training.\n",
        "        device (torch.device): The device to run the model on.\n",
        "        epochs (int): The number of epochs to train (default: 1).\n",
        "        accumulate_step (int): The number of steps to accumulate gradients (default: 4).\n",
        "        report_freq (int): The frequency of reporting training progress (default: 10).\n",
        "        eval_interval (int): The interval for performing evaluation (default: -1, no evaluation).\n",
        "        max_lr (float): The maximum learning rate (default: 2e-3).\n",
        "        warmup_steps (int): The number of warmup steps (default: 1000).\n",
        "        beta (float): The beta value for DPO loss (default: 0.1).\n",
        "\n",
        "    Returns:\n",
        "        AutoModelForCausalLM: The dpo-tuned model.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    all_step_cnt = 0\n",
        "    minimum_loss = 1e5\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        step_cnt = 0\n",
        "        epoch_step = 0\n",
        "        avg_loss = 0\n",
        "\n",
        "        for i, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                step_cnt += 1\n",
        "\n",
        "                input_ids = batch[\"input_ids\"]\n",
        "                attention_mask = batch[\"attention_mask\"]\n",
        "\n",
        "                # TODO: Compute the model output; The model should return the logits (not the hidden states)\n",
        "\n",
        "                output = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    output_hidden_states=False\n",
        "                )\n",
        "\n",
        "\n",
        "                output = output[0]\n",
        "                output = output[:, :-1]  # truncate last logit\n",
        "                labels = input_ids[:, 1:]  # shift labels\n",
        "\n",
        "                # TODO: Compute the logits and mask the prompt parts; 4 ~ 6 lines\n",
        "                # This is the same as what you did for compute_likelihood() and test(); You can copy over what you had\n",
        "                logits = torch.log_softmax(output, dim=-1)\n",
        "                logits = logits.gather(2, labels.unsqueeze(2)).squeeze(2)\n",
        "                mask = batch[\"masks\"].to(device)[:, 1:]\n",
        "                logits = logits * mask\n",
        "                num_tokens = mask.sum(dim=1)\n",
        "\n",
        "                batch_size = logits.size(0) // 2\n",
        "                pos_logits, neg_logits = logits[:batch_size], logits[batch_size:]\n",
        "                pos_ref_logits = batch[\"chosen_logprob\"]\n",
        "                neg_ref_logits = batch[\"rejected_logprob\"]\n",
        "\n",
        "                # Compute DPO loss\n",
        "                loss, _, _ = compute_dpo_loss(pos_logits, neg_logits, pos_ref_logits, neg_ref_logits, beta)\n",
        "                loss = loss.mean()\n",
        "                loss = loss / accumulate_step\n",
        "                avg_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                if step_cnt == accumulate_step:\n",
        "                    # updating\n",
        "                    if grad_norm > 0:\n",
        "                        nn.utils.clip_grad_norm_(model.parameters(), grad_norm)\n",
        "                    step_cnt = 0\n",
        "                    epoch_step += 1\n",
        "                    all_step_cnt += 1\n",
        "                    # adjust learning rate\n",
        "                    lr = max_lr * min(all_step_cnt ** (-0.5), all_step_cnt * (warmup_steps ** (-1.5)))\n",
        "                    for param_group in optimizer.param_groups:\n",
        "                        param_group['lr'] = lr\n",
        "                    # TODO: Perform gradient update\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                if epoch_step % report_freq == 0 and step_cnt == 0:\n",
        "                    # Report training progress\n",
        "                    print(f\"Epoch {epoch+1}/{epochs} | Batch {epoch_step} | Avg Loss: {avg_loss / report_freq:.6f}\")\n",
        "                    avg_loss = 0\n",
        "\n",
        "                del loss, output\n",
        "                # Validation\n",
        "                if eval_interval > 0 and all_step_cnt % eval_interval == 0 and all_step_cnt > 0 and step_cnt == 0 or (i == len(dataloader) - 1):\n",
        "                    val_loss = test(val_dataloader, model, beta, device)\n",
        "                    print(f\"Validation Loss: {val_loss:.6f}\")\n",
        "                    if val_loss < minimum_loss:\n",
        "                        minimum_loss = val_loss\n",
        "                        print(\"best val loss - epoch: %d\"%(epoch))\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3_YWqVSbpbQ"
      },
      "source": [
        "### Question 4: Given the provided code, answer the following questions:\n",
        "\n",
        "Q4.1 Explain the purpose and the process of gradient accumulation in the run_dpo function. Why does the function divide the loss by accumulate_step before calling loss.backward(), and how does this approach affect the learning rate adjustment within the loop?\n",
        "\n",
        "`TODO: Your answer here`\n",
        "\n",
        "Q4.2 Describe the purpose of the optimizer.zero_grad() function in the run_dpo function.\n",
        "\n",
        "`TODO: Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOzamLK_vk-p"
      },
      "source": [
        "Before we kick off training, we might need to clear up some space for GPU, especially if you are one T4 GPU on colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k60pi7Eqvksh"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "raw_model.to('cpu')\n",
        "model_sft.to('cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utz0Nbs3owws"
      },
      "source": [
        "Now you will define Pytorch dataloaders that will be used to load the training and testing data into the model. A Pytorch DataLoader is an iterator that provides a way to iterate over the dataset in batches. It gets as input a Pytorch Dataset (which you defined above), and optionally a collator function that is used to preprocess and batch the samples before they are passed to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DghoEasCowTL"
      },
      "outputs": [],
      "source": [
        "collate_fn = partial(collate_dpo_gpt, pad_token_id=tokenizer.pad_token_id, is_test=False)\n",
        "\n",
        "train_data = load_dataset(\"json\", data_files=\"data/dpo/train.jsonl\")[\"train\"]\n",
        "val_data = load_dataset(\"json\", data_files=\"data/dpo/val.jsonl\")[\"train\"]\n",
        "\n",
        "batch_size = 1\n",
        "max_len = 1024\n",
        "is_test=False\n",
        "\n",
        "# Replace None with your code\n",
        "# Hint: Pass variables to a DPOGPTDataset constructor\n",
        "train_set = DPOGPTDataset(train_data, dpo_model.config.model_type, max_len, is_test)\n",
        "val_set = DPOGPTDataset(val_data, dpo_model.config.model_type, max_len, is_test)\n",
        "\n",
        "# Replace None with your code\n",
        "dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
        "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Y1P1qxD-LC"
      },
      "source": [
        "Note that the variance of the following DPO traning is high. You might see surprising results in the Evaluation section below.\n",
        "We suggest you to conduct a few restarts and explore the resulting model quality.\n",
        "\n",
        "#### Kicking off training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdc5yRloq-uk"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(dpo_model.parameters())\n",
        "\n",
        "# Define the number of epochs and other hyperparameters\n",
        "# Recall that dataloaders have batch_size=1\n",
        "\n",
        "epochs = 1\n",
        "accumulate_step = 8 # Total effective batch size is 1 * 8 = 8\n",
        "report_freq = 100\n",
        "eval_interval = 500\n",
        "max_lr = 1e-3\n",
        "warmup_steps = 70\n",
        "beta = 0.1\n",
        "\n",
        "# Call the run_dpo function\n",
        "dpo_model_student = run_dpo(\n",
        "    model=dpo_model,\n",
        "    dataloader=dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    epochs=epochs,\n",
        "    accumulate_step=accumulate_step,\n",
        "    report_freq=report_freq,\n",
        "    eval_interval=eval_interval,\n",
        "    max_lr=max_lr,\n",
        "    warmup_steps=warmup_steps,\n",
        "    beta=beta\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyqeCbzllGT8"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Next, we will evaluate the performance of three models: the pre-trained SFT model, the initial DPO model, and your fine-tuned DPO model. The evaluation process aims to assess the quality of the generated responses and compare them with expert references.\n",
        "\n",
        "#### Evaluation Dataset\n",
        "We will use the `sft/test.jsonl`, a held-out part from the TULUv2 SFT dataset for evaluation. It contains a set of instructions and corresponding human-written responses. Feel free to explore this data by yourself.\n",
        "\n",
        "#### Evaluation Metrics\n",
        "We will use the following metrics to evaluate the models:\n",
        "\n",
        "1. **ROUGE Scores**: We've seen ROUGE in previous assignments.\n",
        "2. **Pairwise Comparison**: We will use the PairRM (Pairwise Reward Model) to compare the generated responses with the human-written references. PairRM is a model that takes an instruction and a pair of output candidates as input and outputs a score for each candidate to measure their relative quality.\n",
        "\n",
        "#### Evaluation Process\n",
        "The evaluation process consists of the following steps:\n",
        "\n",
        "1. **Response Generation**: For each model (SFT, instructor's DPO, and student's DPO), we will generate responses for the instructions in the `sft/test.jsonl` dataset.\n",
        "\n",
        "2. **ROUGE Score Calculation**: We will calculate the ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L) between the generated responses and the corresponding human-written references.\n",
        "\n",
        "3. **Pairwise Comparison**: Using the PairRM model, we will compare each generated response with its corresponding human-written reference. PairRM will output a score indicating which response is preferred. We will calculate the **win rate**, which represents the percentage of generated responses that are preferred over the human-written references.\n",
        "\n",
        "4. **Result Analysis**: We will analyze the evaluation results to assess the performance of each model. The ROUGE scores and win rates will provide insights into the quality of the generated responses and how well they align with human preferences.\n",
        "\n",
        "#### PairRM (Pairwise Reward Model)\n",
        "We will use a reward model that based on the **DeBERTa-v3-large** architecture and has been trained on a diverse collection of human-preference datasets. The reward model takes an instruction and a pair of output candidates as input and outputs a score for each candidate, indicating their relative quality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7nlzK4Ju0Qs"
      },
      "outputs": [],
      "source": [
        "# Adapted from https://github.com/yuchenlin/LLM-Blender/blob/main/llm_blender/pair_ranker/pairrm.py\n",
        "class DebertaV2PairRM(DebertaV2PreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.n_tasks = config.n_tasks\n",
        "        self.drop_out = config.drop_out\n",
        "\n",
        "        # LM\n",
        "        self.pretrained_model = DebertaV2Model(config)\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        self.sep_token_id = config.sep_token_id # to add\n",
        "        self.source_prefix_id = config.source_prefix_id # to add\n",
        "        self.cand_prefix_id = config.cand_prefix_id\n",
        "        self.cand1_prefix_id = config.cand1_prefix_id\n",
        "        self.cand2_prefix_id = config.cand2_prefix_id\n",
        "\n",
        "        self.head_layer = nn.Sequential(\n",
        "            nn.Dropout(self.drop_out),\n",
        "            nn.Linear(2*self.hidden_size, 1*self.hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(self.drop_out),\n",
        "            nn.Linear(1 * self.hidden_size, self.n_tasks),\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        #  <source_prefix_id>...<sep><cand1_prefix_id>...<sep><cand2_prefix_id> ... <sep>\n",
        "        assert all([self.source_prefix_id in input_ids[i] for i in range(input_ids.shape[0])]), \"<source> id not in input_ids\"\n",
        "        assert all([self.cand1_prefix_id in input_ids[i] for i in range(input_ids.shape[0])]), \"<candidate1> id not in input_ids\"\n",
        "        assert all([self.cand2_prefix_id in input_ids[i] for i in range(input_ids.shape[0])]), \"<candidate2> id not in input_ids\"\n",
        "\n",
        "        keep_column_mask = attention_mask.ne(0).any(dim=0)\n",
        "        input_ids = input_ids[:, keep_column_mask]\n",
        "        attention_mask = attention_mask[:, keep_column_mask]\n",
        "        outputs = self.pretrained_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=return_dict,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        encs = outputs.hidden_states[-1]\n",
        "        source_idxs = torch.where(input_ids == self.source_prefix_id)\n",
        "        source_encs = encs[source_idxs[0], source_idxs[1], :]\n",
        "        cand1_idxs = torch.where(input_ids == self.cand1_prefix_id)\n",
        "        cand1_encs = encs[cand1_idxs[0], cand1_idxs[1], :]\n",
        "        cand2_idxs = torch.where(input_ids == self.cand2_prefix_id)\n",
        "        cand2_encs = encs[cand2_idxs[0], cand2_idxs[1], :]\n",
        "\n",
        "        # reduce\n",
        "        source_cand1_encs = torch.cat([source_encs, cand1_encs], dim=-1)\n",
        "        source_cand2_encs = torch.cat([source_encs, cand2_encs], dim=-1)\n",
        "        left_pred_scores = self.head_layer(source_cand1_encs)\n",
        "        right_pred_scores = self.head_layer(source_cand2_encs)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.compute_loss(left_pred_scores, right_pred_scores, labels)\n",
        "\n",
        "\n",
        "        preds = (left_pred_scores - right_pred_scores).mean(dim=-1)\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss, logits=preds,\n",
        "            hidden_states=outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=outputs.attentions\n",
        "        )\n",
        "\n",
        "    def compute_loss(self, left_pred_scores, right_pred_scores, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            left_pred_scores: [n_candidates, n_task]\n",
        "            right_pred_scores: [n_candidates, n_task]\n",
        "            labels: [n_candidates, n_task], 1/0/-1 for left/right/both is better\n",
        "        \"\"\"\n",
        "\n",
        "        device = left_pred_scores.device\n",
        "        loss = torch.tensor(0.0).to(left_pred_scores.device)\n",
        "\n",
        "        dif_scores = labels\n",
        "        left_pred_scores = left_pred_scores * dif_scores.sign()\n",
        "        right_pred_scores = - right_pred_scores * dif_scores.sign()\n",
        "        cls_loss = torch.tensor(0.0, device=device)\n",
        "        cls_loss += - torch.log(torch.sigmoid(left_pred_scores+right_pred_scores)).mean()\n",
        "        loss += cls_loss\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJONtTEQJXNu"
      },
      "source": [
        "### Generating Model Outputs\n",
        "\n",
        "In this step, we will use the inference() function to generate responses from each model (SFT, instructor's DPO model, and your DPO model) for the instructions in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soPuDoL-0vO7"
      },
      "outputs": [],
      "source": [
        "def inference(model, tokenizer, data_path, output_path, device, batch_size=4, gen_max_len=512, gen_min_len=10, max_len=1024, num_beams=1, length_penalty=1.0):\n",
        "    model.eval()\n",
        "    data = load_dataset(\"json\", data_files=data_path)[\"train\"]\n",
        "    dataset = SFTGPTDataset(data, model.config.model_type, max_len, is_test=True)\n",
        "    collate_fn = partial(collate_base_gpt, pad_token_id=tokenizer.pad_token_id, is_test=True)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeLsum\"], use_stemmer=True, split_summaries=True)\n",
        "    rouge1, rouge2, rougeLsum = 0, 0, 0\n",
        "    length = 0\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(dataloader, desc=\"Generating outputs\"):\n",
        "                text_id = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                src_len = text_id.shape[1]\n",
        "                summaries = model.generate(\n",
        "                    input_ids=text_id,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_length=min(gen_max_len + src_len, max_len),\n",
        "                    min_length=min(gen_min_len + src_len, max_len),\n",
        "                    num_beams=num_beams,\n",
        "                    length_penalty=length_penalty,\n",
        "                    early_stopping=True,\n",
        "                )\n",
        "                dec = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
        "                for hypothesis, d in zip(dec, batch[\"data\"]):\n",
        "                    hypothesis = hypothesis[len(d[\"instruction\"]):].strip()\n",
        "                    scores = scorer.score(d[\"response\"], hypothesis)\n",
        "                    rouge1 += scores[\"rouge1\"].fmeasure\n",
        "                    rouge2 += scores[\"rouge2\"].fmeasure\n",
        "                    rougeLsum += scores[\"rougeLsum\"].fmeasure\n",
        "                    length += len(tokenizer.encode(hypothesis))\n",
        "                    result = {\n",
        "                        \"instruction\": d[\"instruction\"],\n",
        "                        \"reference\": d[\"response\"],\n",
        "                        \"hypothesis\": hypothesis,\n",
        "                        \"rouge1\": scores[\"rouge1\"].fmeasure,\n",
        "                        \"rouge2\": scores[\"rouge2\"].fmeasure,\n",
        "                        \"rougeLsum\": scores[\"rougeLsum\"].fmeasure,\n",
        "                        \"length\": len(tokenizer.encode(hypothesis)),\n",
        "                    }\n",
        "                    f.write(json.dumps(result) + \"\\n\")\n",
        "\n",
        "    rouge1 /= len(dataset)\n",
        "    rouge2 /= len(dataset)\n",
        "    rougeLsum /= len(dataset)\n",
        "    rouge1 *= 100\n",
        "    rouge2 *= 100\n",
        "    rougeLsum *= 100\n",
        "    length /= len(dataset)\n",
        "    print(f\"Rouge1: {rouge1:.2f}, Rouge2: {rouge2:.2f}, RougeLsum: {rougeLsum:.2f}, Length: {length:.2f}\")\n",
        "    return rouge1, rouge2, rougeLsum\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtJtl_qIJuYR"
      },
      "source": [
        "### Pairwise Comparison using PairRM\n",
        "In this step, we will use the pairwise_compare() function to compare the generated responses from each model with the human-written references.\n",
        "\n",
        "The function returns the win rate, which serves as an evaluation metric for the model's performance in generating responses that align with human preferences. Read the code below and run the cell, then answer the following questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ37WkF9Jhlq"
      },
      "outputs": [],
      "source": [
        "def pairwise_compare(data_path, output_path, device, batch_size=1):\n",
        "    pairrm = DebertaV2PairRM.from_pretrained(\"llm-blender/PairRM-hf\").to(device).eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained('llm-blender/PairRM-hf')\n",
        "    source_prefix = \"<|source|>\"\n",
        "    cand1_prefix = \"<|candidate1|>\"\n",
        "    cand2_prefix = \"<|candidate2|>\"\n",
        "\n",
        "    with open(data_path) as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "\n",
        "    def tokenize_pair(sources:List[str], candidate1s:List[str], candidate2s:List[str], source_max_length=960, candidate_max_length=460):\n",
        "        ids = []\n",
        "        assert len(sources) == len(candidate1s) == len(candidate2s)\n",
        "        max_length = source_max_length + 2 * candidate_max_length\n",
        "        for i in range(len(sources)):\n",
        "            source_ids = tokenizer.encode(source_prefix + sources[i], max_length=source_max_length, truncation=True)\n",
        "            candidate_max_length = (max_length - len(source_ids)) // 2\n",
        "            candidate1_ids = tokenizer.encode(cand1_prefix + candidate1s[i], max_length=candidate_max_length, truncation=True)\n",
        "            candidate2_ids = tokenizer.encode(cand2_prefix + candidate2s[i], max_length=candidate_max_length, truncation=True)\n",
        "            ids.append(source_ids + candidate1_ids + candidate2_ids)\n",
        "        encodings = tokenizer.pad({\"input_ids\": ids}, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length)\n",
        "        return encodings\n",
        "\n",
        "    win = 0\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for batch_start in tqdm(range(0, len(data), batch_size), desc=\"Comparing outputs\"):\n",
        "            batch_end = batch_start + batch_size\n",
        "            batch_data = data[batch_start:batch_end]\n",
        "\n",
        "            inputs = [d[\"instruction\"] for d in batch_data]\n",
        "            candidates_A = [d[\"hypothesis\"] for d in batch_data]\n",
        "            candidates_B = [d[\"reference\"] for d in batch_data]\n",
        "\n",
        "            encodings = tokenize_pair(inputs, candidates_A, candidates_B)\n",
        "            encodings = {k:v.to(device) for k,v in encodings.items()}\n",
        "\n",
        "            outputs = pairrm(**encodings)\n",
        "            comparison_results = outputs.logits > 0\n",
        "            comparison_results = comparison_results.cpu().numpy().tolist()\n",
        "\n",
        "            for i, d in enumerate(batch_data):\n",
        "                d[\"comparison_result\"] = comparison_results[i]\n",
        "                f.write(json.dumps(d) + \"\\n\")\n",
        "                if comparison_results[i]:\n",
        "                    win += 1\n",
        "\n",
        "    win_rate = win / len(data)\n",
        "    print(f\"Win rate: {win_rate:.2f}\")\n",
        "    return win_rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-KEk1KHbpbR"
      },
      "source": [
        "### Question 5: Given the provided code, answer the following questions:\n",
        "\n",
        "Q5.1 Describe how the pairwise_compare function determines the \"win\" cases between two candidates (referred to as candidates_A and candidates_B in the code) for each piece of input data.\n",
        "\n",
        "`TODO: Your answer here`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVYQCOMszG-F"
      },
      "outputs": [],
      "source": [
        "dpo_model = AutoModelForCausalLM.from_pretrained(\"kejian/gpt2-tulu2-DPO\").to('cpu') # load the initial DPO model again but to CPU.\n",
        "dpo_model_student.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "raw_model.to('cpu')\n",
        "model_sft.to('cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "uVtZgVovYc38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7Zd-43CJi1R"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "def evaluate_models(models, tokenizer, test_data_path, device, batch_size=4, cls_batch_size=1):\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "        output_path = f\"{model_name}_outputs.jsonl\"\n",
        "        score_path = f\"{model_name}_scores.jsonl\"\n",
        "\n",
        "        model.to(device)\n",
        "        rouge1, rouge2, rougeLsum = inference(model, tokenizer, test_data_path, output_path, device, batch_size)\n",
        "        print(f\"{model_name} Rouge Scores - Rouge1: {rouge1:.2f}, Rouge2: {rouge2:.2f}, RougeLsum: {rougeLsum:.2f}\")\n",
        "\n",
        "        model.to('cpu')\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        win_rate = pairwise_compare(output_path, score_path, device, cls_batch_size)\n",
        "        print(f\"{model_name} Win Rate: {win_rate:.2f}\")\n",
        "\n",
        "\n",
        "models = {\n",
        "    # \"RAW\": raw_model,\n",
        "    \"SFT\": model_sft,\n",
        "    \"DPO_Instructor\": dpo_model,\n",
        "    \"DPO_Student\": dpo_model_student\n",
        "}\n",
        "\n",
        "test_data_path = \"data/sft/test.jsonl\"\n",
        "batch_size = 4\n",
        "cls_batch_size = 1 # for the DeBERTa-large 0.4B\n",
        "\n",
        "evaluate_models(models, tokenizer, test_data_path, DEVICE, batch_size, cls_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ptmJg8ybpbR"
      },
      "source": [
        "#### Question 6:\n",
        "\n",
        "Please provide a description of the results obtained. What were your initial expectations? How did the empirical outcomes compare to these expectations? Attempt to explain the reasons behind your observations.\n",
        "\n",
        "\n",
        "Prompt your `dpo_model_student` and compare its responses with the SFT model. Don't forget to use the SFT prompt format (No explanations needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HjSvrNIBpaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6jW5ZHabpbS"
      },
      "source": [
        "#### Question 7:  \n",
        "\n",
        "What’s the purpose of using $\\sigma$, the logistic function, in the DPO loss?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic function σ is used to convert the difference in model log-probabilities into a probability in [0,1] that the “chosen” output is preferred. This smooth mapping stabilizes training by providing well-behaved gradients and a natural probabilistic interpretation for pairwise preference signals."
      ],
      "metadata": {
        "id": "dy5oy9xFBj7q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO1IBbm50zZq"
      },
      "source": [
        "### References\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "@misc{cui2023ultrafeedback,\n",
        "      title={UltraFeedback: Boosting Language Models with High-quality Feedback},\n",
        "      author={Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Wei Zhu and Yuan Ni and Guotong Xie and Zhiyuan Liu and Maosong Sun},\n",
        "      year={2023},\n",
        "      eprint={2310.01377},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.CL}\n",
        "}\n",
        "\n",
        "@misc{rafailov2023direct,\n",
        "      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},\n",
        "      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},\n",
        "      year={2023},\n",
        "      eprint={2305.18290},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.LG}\n",
        "}\n",
        "\n",
        "@misc{ivison2023camels,\n",
        "      title={Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2},\n",
        "      author={Hamish Ivison and Yizhong Wang and Valentina Pyatkin and Nathan Lambert and Matthew Peters and Pradeep Dasigi and Joel Jang and David Wadden and Noah A. Smith and Iz Beltagy and Hannaneh Hajishirzi},\n",
        "      year={2023},\n",
        "      eprint={2311.10702},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.CL}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRGiYFRQbpbS"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13c309ce925642a195749ba9b5139b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b6bba9706bb451893912b4bc2dad18b",
              "IPY_MODEL_ac38a5b95b0a4466828d8be87b96ec6e",
              "IPY_MODEL_656470a38f5745ff8981dc2b58911e2c"
            ],
            "layout": "IPY_MODEL_50b78d7f4fe748f8a7d934589511199d"
          }
        },
        "3b6bba9706bb451893912b4bc2dad18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6df29ec22e4e53a0fd6d75bf2e94b4",
            "placeholder": "​",
            "style": "IPY_MODEL_d1552abbedf84ffea7622bea0dfa68ef",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ac38a5b95b0a4466828d8be87b96ec6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fecaf92b2ee4208a749d8239cc57c4a",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6390eb7d405d425abcabc0e15008e654",
            "value": 26
          }
        },
        "656470a38f5745ff8981dc2b58911e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604b727fe88b4edc9d02d748f6befa10",
            "placeholder": "​",
            "style": "IPY_MODEL_2d1ec0436b25459e8236751b9f8c3d2f",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.13kB/s]"
          }
        },
        "50b78d7f4fe748f8a7d934589511199d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac6df29ec22e4e53a0fd6d75bf2e94b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1552abbedf84ffea7622bea0dfa68ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fecaf92b2ee4208a749d8239cc57c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6390eb7d405d425abcabc0e15008e654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "604b727fe88b4edc9d02d748f6befa10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1ec0436b25459e8236751b9f8c3d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "922f882880ac4c3c8f57f2bef471864b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dda7dd34479a4cc289b141584c1bf478",
              "IPY_MODEL_834cffbf67654c5da8d1271fd7e08dd3",
              "IPY_MODEL_84b71fd967af46a1826224cca3fadf78"
            ],
            "layout": "IPY_MODEL_ea9412f13f814c8b97febbbf4c4a6362"
          }
        },
        "dda7dd34479a4cc289b141584c1bf478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109fed2523bd414fa0f23e4d21d1c786",
            "placeholder": "​",
            "style": "IPY_MODEL_7a576e4d062e4d46b9ad1d8b7042af52",
            "value": "config.json: 100%"
          }
        },
        "834cffbf67654c5da8d1271fd7e08dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7fac67ed3c465e9d1dad39878d9c4a",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d117219398b14288be6531c11f3a352a",
            "value": 665
          }
        },
        "84b71fd967af46a1826224cca3fadf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e342e629ab488b8ffa78cf7bfcafca",
            "placeholder": "​",
            "style": "IPY_MODEL_511913fc78bf411e9958a44ba5e6657c",
            "value": " 665/665 [00:00&lt;00:00, 60.3kB/s]"
          }
        },
        "ea9412f13f814c8b97febbbf4c4a6362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109fed2523bd414fa0f23e4d21d1c786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a576e4d062e4d46b9ad1d8b7042af52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7fac67ed3c465e9d1dad39878d9c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d117219398b14288be6531c11f3a352a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6e342e629ab488b8ffa78cf7bfcafca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511913fc78bf411e9958a44ba5e6657c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fe1babf454c47cb90fcc195085c87a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a801a44da1e44f6b02e0745865df7a1",
              "IPY_MODEL_86ab738c35c545d99ed8b4ac5e7581da",
              "IPY_MODEL_89d1502bedbd4839bd9eb00fc3132cef"
            ],
            "layout": "IPY_MODEL_8e17ec8b15ef427291b52336faecfe7a"
          }
        },
        "9a801a44da1e44f6b02e0745865df7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa5cb22f56e4ca6b64e36981969af21",
            "placeholder": "​",
            "style": "IPY_MODEL_be47362e1c104674a1ce6852aa300103",
            "value": "vocab.json: 100%"
          }
        },
        "86ab738c35c545d99ed8b4ac5e7581da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565135e46aae49ca9750f00527a1e800",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_472f791eceae40238491e9d0dbaca354",
            "value": 1042301
          }
        },
        "89d1502bedbd4839bd9eb00fc3132cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0acca70e9f2d4a5e94fae7577971a298",
            "placeholder": "​",
            "style": "IPY_MODEL_639b36c90df74193b2ece56d6bd57b04",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "8e17ec8b15ef427291b52336faecfe7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa5cb22f56e4ca6b64e36981969af21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be47362e1c104674a1ce6852aa300103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565135e46aae49ca9750f00527a1e800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472f791eceae40238491e9d0dbaca354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0acca70e9f2d4a5e94fae7577971a298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "639b36c90df74193b2ece56d6bd57b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72bc4ccbc37d4e0fa7fbb529960d4949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93533b123aa44386adf609a0a68ebdb0",
              "IPY_MODEL_91b2cc60799642669794f9d8bf7281e1",
              "IPY_MODEL_6bc190d4a89d4d55a6129cf1964befd5"
            ],
            "layout": "IPY_MODEL_865173e685f34693af8fc53141cf0540"
          }
        },
        "93533b123aa44386adf609a0a68ebdb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ecef39a7234d26a7606e0aaa4ebac1",
            "placeholder": "​",
            "style": "IPY_MODEL_502d54457481475dab502cb8a4868121",
            "value": "merges.txt: 100%"
          }
        },
        "91b2cc60799642669794f9d8bf7281e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd19ae7ccfcd470b9840af0d14886b18",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d74358e28e554603b23f401e6b60c278",
            "value": 456318
          }
        },
        "6bc190d4a89d4d55a6129cf1964befd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c33f0c39b674627a8d19fc640ab81f5",
            "placeholder": "​",
            "style": "IPY_MODEL_f42ac9b691e44d8f91a28779a49d435d",
            "value": " 456k/456k [00:00&lt;00:00, 8.52MB/s]"
          }
        },
        "865173e685f34693af8fc53141cf0540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ecef39a7234d26a7606e0aaa4ebac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502d54457481475dab502cb8a4868121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd19ae7ccfcd470b9840af0d14886b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74358e28e554603b23f401e6b60c278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c33f0c39b674627a8d19fc640ab81f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42ac9b691e44d8f91a28779a49d435d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71d50995ffee4c028b53b104693e3ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f37cb54f46ef478f8272271d1c80ed8b",
              "IPY_MODEL_ab6056ab7be849858ebc6a1d98416311",
              "IPY_MODEL_1fb431d1410543188edee142a8469038"
            ],
            "layout": "IPY_MODEL_8e857e434ac24b09941038f381a6685e"
          }
        },
        "f37cb54f46ef478f8272271d1c80ed8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3507c3d609f74c2aa38962bef09f9ad0",
            "placeholder": "​",
            "style": "IPY_MODEL_14a801bead57438784f9ad3c97b290f3",
            "value": "tokenizer.json: 100%"
          }
        },
        "ab6056ab7be849858ebc6a1d98416311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769c58d9a41941c08bde97a5ddc83c16",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e067f878a4747aa8adff137c8d525b9",
            "value": 1355256
          }
        },
        "1fb431d1410543188edee142a8469038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3bd824ec1e44a2b4d1f26d2f4b7928",
            "placeholder": "​",
            "style": "IPY_MODEL_8706b37a767b4e0490341a8d650dde65",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 17.4MB/s]"
          }
        },
        "8e857e434ac24b09941038f381a6685e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3507c3d609f74c2aa38962bef09f9ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a801bead57438784f9ad3c97b290f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769c58d9a41941c08bde97a5ddc83c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e067f878a4747aa8adff137c8d525b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b3bd824ec1e44a2b4d1f26d2f4b7928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8706b37a767b4e0490341a8d650dde65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cb53f93d06a43c99a96c66f6075dbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f89b3b9926274542ba7a100b17cffda0",
              "IPY_MODEL_92440828eacb4d8297d7ecc1f5d91c14",
              "IPY_MODEL_d7f4e24963fb4b7b8cce5947778d8ecf"
            ],
            "layout": "IPY_MODEL_902f793467df423292182668322a7b9c"
          }
        },
        "f89b3b9926274542ba7a100b17cffda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6be4a9cebe0a42dea30dd8fc28d3e566",
            "placeholder": "​",
            "style": "IPY_MODEL_b06e408ad1ca465086ebfbd21cb60ae3",
            "value": "config.json: 100%"
          }
        },
        "92440828eacb4d8297d7ecc1f5d91c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875d9e81c1c94bb0b4c76467f5365077",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e36906551c9043c69913e90102e8b6f8",
            "value": 665
          }
        },
        "d7f4e24963fb4b7b8cce5947778d8ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31902cd39aef4280918458971f64deca",
            "placeholder": "​",
            "style": "IPY_MODEL_35543e63134944c091e871c2e4760309",
            "value": " 665/665 [00:00&lt;00:00, 58.5kB/s]"
          }
        },
        "902f793467df423292182668322a7b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be4a9cebe0a42dea30dd8fc28d3e566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06e408ad1ca465086ebfbd21cb60ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "875d9e81c1c94bb0b4c76467f5365077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36906551c9043c69913e90102e8b6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31902cd39aef4280918458971f64deca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35543e63134944c091e871c2e4760309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcbf9b10ecb6424f8f7fd03834f58a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4af6fff7cbe743dfb406c2ddadee7800",
              "IPY_MODEL_0a986efcd64e489a977f841e01781f61",
              "IPY_MODEL_5476cf66bc714ba981d60a0e4c99c980"
            ],
            "layout": "IPY_MODEL_e6da138704b44f2ab50174d5579e709f"
          }
        },
        "4af6fff7cbe743dfb406c2ddadee7800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4b6cb98533499f821eeb96fa6cd234",
            "placeholder": "​",
            "style": "IPY_MODEL_e75a03cac300428ca72720177613492a",
            "value": "model.safetensors: 100%"
          }
        },
        "0a986efcd64e489a977f841e01781f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e99dd91967e44a629ff53d174683be15",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5a42f2f68d740618c96eed57d9ac751",
            "value": 548105171
          }
        },
        "5476cf66bc714ba981d60a0e4c99c980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567378cbb25545aaae5673de9aa2452a",
            "placeholder": "​",
            "style": "IPY_MODEL_fa4f397614cc49ff98de3ee8db9a6a80",
            "value": " 548M/548M [00:06&lt;00:00, 42.2MB/s]"
          }
        },
        "e6da138704b44f2ab50174d5579e709f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4b6cb98533499f821eeb96fa6cd234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75a03cac300428ca72720177613492a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e99dd91967e44a629ff53d174683be15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a42f2f68d740618c96eed57d9ac751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "567378cbb25545aaae5673de9aa2452a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4f397614cc49ff98de3ee8db9a6a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "914a092605454f5b85b2b2c1a3187630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8559af622a34e19b22ebe88b7eccba3",
              "IPY_MODEL_83e8035c60024ef88a2159a8ac20699e",
              "IPY_MODEL_0793038799bb41808518355711e47479"
            ],
            "layout": "IPY_MODEL_8f2e6ec4fcbc4acdb16ef3f87767ff2f"
          }
        },
        "c8559af622a34e19b22ebe88b7eccba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a609724bea494eab7eb9382f65bdfe",
            "placeholder": "​",
            "style": "IPY_MODEL_e663da1939544c729a5b47112f4813ab",
            "value": "generation_config.json: 100%"
          }
        },
        "83e8035c60024ef88a2159a8ac20699e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d354b20944484bb12974a7cfdd83e8",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05331e0684de4fcd8e6c584a688cee6c",
            "value": 124
          }
        },
        "0793038799bb41808518355711e47479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6786c5f785b14d84aefdecc5e59caf74",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc051da5a284325be0d69d09b60e61a",
            "value": " 124/124 [00:00&lt;00:00, 10.2kB/s]"
          }
        },
        "8f2e6ec4fcbc4acdb16ef3f87767ff2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a609724bea494eab7eb9382f65bdfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e663da1939544c729a5b47112f4813ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31d354b20944484bb12974a7cfdd83e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05331e0684de4fcd8e6c584a688cee6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6786c5f785b14d84aefdecc5e59caf74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc051da5a284325be0d69d09b60e61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dac8f2f0d6f45ab9aea1de469c87e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9cd8230543241deb35655f4e3df777a",
              "IPY_MODEL_9c6a3a96483344d1b2f44a789a34a8e6",
              "IPY_MODEL_29c7fb552be244c6a00842c3c9e029a1"
            ],
            "layout": "IPY_MODEL_71e41bd3cff743d88ab79d8e02a0c6f1"
          }
        },
        "d9cd8230543241deb35655f4e3df777a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee2c09caabe4a1e83844e51cf3cdc38",
            "placeholder": "​",
            "style": "IPY_MODEL_494be213b16e489e8216e33b561efa88",
            "value": "config.json: 100%"
          }
        },
        "9c6a3a96483344d1b2f44a789a34a8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b7ddec0e4d46bca2b96f494be95258",
            "max": 907,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f341b60f7545434389f6bdfa3a403a88",
            "value": 907
          }
        },
        "29c7fb552be244c6a00842c3c9e029a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a015b7e60654a3dbe457634790ee6c4",
            "placeholder": "​",
            "style": "IPY_MODEL_6a4f05bf5ee240058135c3f5ef5e5a2b",
            "value": " 907/907 [00:00&lt;00:00, 69.8kB/s]"
          }
        },
        "71e41bd3cff743d88ab79d8e02a0c6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee2c09caabe4a1e83844e51cf3cdc38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494be213b16e489e8216e33b561efa88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b7ddec0e4d46bca2b96f494be95258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f341b60f7545434389f6bdfa3a403a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a015b7e60654a3dbe457634790ee6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a4f05bf5ee240058135c3f5ef5e5a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddccbf4d430348378f2fdc216e1d780d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01655f7e78754dcf9dd643483c282182",
              "IPY_MODEL_5ab3287800a347ceb6d45809623fbab8",
              "IPY_MODEL_a7ffbe705b6042d18411e1b4c912aeec"
            ],
            "layout": "IPY_MODEL_874d3835eaa949ce83bb87cab5ff9a39"
          }
        },
        "01655f7e78754dcf9dd643483c282182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff54cfdd785e484bb6853511c524b80e",
            "placeholder": "​",
            "style": "IPY_MODEL_f1d2a653c0c24686a398c571cdcc0e14",
            "value": "model.safetensors: 100%"
          }
        },
        "5ab3287800a347ceb6d45809623fbab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7107ebccd3146b5bd4366053f79b3af",
            "max": 497774208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b0f919d96a49fca7a037689b0105a9",
            "value": 497774208
          }
        },
        "a7ffbe705b6042d18411e1b4c912aeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899c2bcee1c849c7afde15beca5085f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4ae3961f264c40079022e3f3b2b91845",
            "value": " 498M/498M [00:06&lt;00:00, 39.2MB/s]"
          }
        },
        "874d3835eaa949ce83bb87cab5ff9a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff54cfdd785e484bb6853511c524b80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d2a653c0c24686a398c571cdcc0e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7107ebccd3146b5bd4366053f79b3af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b0f919d96a49fca7a037689b0105a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "899c2bcee1c849c7afde15beca5085f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae3961f264c40079022e3f3b2b91845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e5f6e5b48224885b0485ad6bd9e3c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57a4f59bd72b4cbd9855d4405ca60093",
              "IPY_MODEL_37ba13dd3a2d48efb8cbcdbfd6a07ad9",
              "IPY_MODEL_7cd4c3078e2e4b4e958b04ef3e9bbbad"
            ],
            "layout": "IPY_MODEL_9fd1c020dbca4875af2ca6be3002d928"
          }
        },
        "57a4f59bd72b4cbd9855d4405ca60093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eddb5bd5988b48c18392afdd2b65ba94",
            "placeholder": "​",
            "style": "IPY_MODEL_5824ca39f78241eca0a8b7087e0af7de",
            "value": "generation_config.json: 100%"
          }
        },
        "37ba13dd3a2d48efb8cbcdbfd6a07ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_859f03fae0b240868e0466d60d2d3581",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6349ecf35f594fd3966c2db448c49b75",
            "value": 119
          }
        },
        "7cd4c3078e2e4b4e958b04ef3e9bbbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3004e326374e1a83ee11ae80d7076f",
            "placeholder": "​",
            "style": "IPY_MODEL_9dec09bf8ab048a9be72945f7ed76083",
            "value": " 119/119 [00:00&lt;00:00, 7.30kB/s]"
          }
        },
        "9fd1c020dbca4875af2ca6be3002d928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eddb5bd5988b48c18392afdd2b65ba94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5824ca39f78241eca0a8b7087e0af7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "859f03fae0b240868e0466d60d2d3581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6349ecf35f594fd3966c2db448c49b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c3004e326374e1a83ee11ae80d7076f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dec09bf8ab048a9be72945f7ed76083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "648f1b68c7ab40acbcfd127c7a22ff4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b56170f220645e58889bd05aa98aca2",
              "IPY_MODEL_d6b684570ad5485aa51e3f05b792203f",
              "IPY_MODEL_a4f98eb3cb5847aeb8bad32af172c782"
            ],
            "layout": "IPY_MODEL_c447f7918da04a2d91e5e9ec18de47ed"
          }
        },
        "6b56170f220645e58889bd05aa98aca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228f028aaf5b4db48b47ee9017e8b640",
            "placeholder": "​",
            "style": "IPY_MODEL_ce783c984b0c47999f1b7fbcd871a3e0",
            "value": "Generating train split: "
          }
        },
        "d6b684570ad5485aa51e3f05b792203f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a1cbd8ba7d846b8b3f0ea58f168a48d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_268c83ce865f46c5ac41ba12a121bd47",
            "value": 1
          }
        },
        "a4f98eb3cb5847aeb8bad32af172c782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed2c6edea81c4574b05d823f742e4aea",
            "placeholder": "​",
            "style": "IPY_MODEL_731a634afed94e74ad56765b7ce7766f",
            "value": " 2000/0 [00:00&lt;00:00, 21546.65 examples/s]"
          }
        },
        "c447f7918da04a2d91e5e9ec18de47ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228f028aaf5b4db48b47ee9017e8b640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce783c984b0c47999f1b7fbcd871a3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a1cbd8ba7d846b8b3f0ea58f168a48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "268c83ce865f46c5ac41ba12a121bd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed2c6edea81c4574b05d823f742e4aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "731a634afed94e74ad56765b7ce7766f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}